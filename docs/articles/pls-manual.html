<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction to the pls Package â€¢ pls</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to the pls Package">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pls</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.9-0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/pls-manual.html">Introduction to the pls Package</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/khliland/pls/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Introduction to the pls Package</h1>
                        <h4 data-toc-skip class="author">BjÃ¸rn-Helge
Mevik</h4>
                        <h4 data-toc-skip class="author">Ron
Wehrens</h4>
                        <h4 data-toc-skip class="author">Kristian Hovde
Liland</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/khliland/pls/blob/HEAD/vignettes/pls-manual.Rmd" class="external-link"><code>vignettes/pls-manual.Rmd</code></a></small>
      <div class="d-none name"><code>pls-manual.Rmd</code></div>
    </div>

    
    
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Attaching package: 'pls'</span></span></code></pre>
<pre><code><span><span class="co">## The following object is masked from 'package:stats':</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##     loadings</span></span></code></pre>
<div class="section level2">
<h2 id="abstract">Abstract<a class="anchor" aria-label="anchor" href="#abstract"></a>
</h2>
<p>The <strong>pls</strong> package implements Principal Component
Regression (PCR) and Partial Least Squares Regression (PLSR) in
<strong>R</strong>, and is freely available from the CRAN website,
licensed under the Gnu General Public License (GPL).</p>
<p>The user interface is modelled after the traditional formula
interface, as exemplified by <code>lm</code>. This was done so that
people used to <strong>R</strong> would not have to learn yet another
interface, and also because we believe the formula interface is a good
way of working interactively with models. It thus has methods for
generic functions like <code>predict</code>, <code>update</code> and
<code>coef</code>. It also has more specialised functions like
<code>scores</code>, <code>loadings</code> and <code>RMSEP</code>, and a
flexible cross-validation system. Visual inspection and assessment is
important in chemometrics, and the <strong>pls</strong> package has a
number of plot functions for plotting scores, loadings, predictions,
coefficients and RMSEP estimates.</p>
<p>The package implements PCR and several algorithms for PLSR. The
design is modular, so that it should be easy to use the underlying
algorithms in other functions. It is our hope that the package will
serve well both for interactive data analysis and as a building block
for other functions or packages using PLSR or PCR.</p>
<p>We will here describe the package and how it is used for data
analysis, as well as how it can be used as a part of other packages.
Also included is a section about formulas and data frames, for people
not used to the <strong>R</strong> modelling idioms.</p>
</div>
<div class="section level2">
<h2 id="introduction">1 Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette is meant as an introduction to the <strong>pls</strong>
package. It is based on the paper â€˜The pls Package: Principal Component
and Partial Least Squares Regression in Râ€™, published in <em>Journal of
Statistical Software</em> <span class="citation">(Mevik and Wehrens
2007)</span>, but has been extended to reflect further developments in
the package. The PLSR methodology is shortly described in Section 2.
Section 3 presents an example session, to get an overview of the
package. In Section 4 we describe formulas and data frames (as they are
used in <strong>pls</strong>). Users familiar with formulas and data
frames in <strong>R</strong> can skip this section on first reading.
Fitting of models is described in Section 5, and cross-validatory choice
of components is discussed in Section 6. Next, inspecting and plotting
models is described (Section 7), followed by a section on predicting
future observations (Section 8). Finally, Section 9 covers more advanced
topics such as parallel computing, setting options, using the underlying
functions directly, and implementation details.</p>
</div>
<div class="section level2">
<h2 id="theory">2 Theory<a class="anchor" aria-label="anchor" href="#theory"></a>
</h2>
<p>Multivariate regression methods like Principal Component Regression
(PCR) and Partial Least Squares Regression (PLSR) enjoy large popularity
in a wide range of fields, including the natural sciences. The main
reason is that they have been designed to confront the situation that
there are many, possibly correlated, predictor variables, and relatively
few samplesâ€”a situation that is common, especially in chemistry where
developments in spectroscopy since the seventies have revolutionised
chemical analysis. In fact, the origin of PLSR lies in chemistry (see,
e.g., <span class="citation">(Wold 2001; H. Martens 2001)</span>). The
field of <em>near-infrared</em> (NIR) spectroscopy, with its highly
overlapping lines and difficult to interpret overtones, would not have
existed but for a method to obtain quantitative information from the
spectra. Also other fields have benefited greatly from multivariate
regression methods like PLSR and PCR. In medicinal chemistry, for
example, one likes to derive molecular properties from the molecular
structure. Most of these Quantitative Structure-Activity Relations
(QSAR, and also Quantitative Structure-Property Relations, QSPR), and in
particular, Comparative Molecular Field Analysis (ComFA) <span class="citation">(Cramer, Patterson, and Bunce 1988)</span>, use PLSR.
Other applications range from statistical process control <span class="citation">(Kresta, MacGregor, and Marlin 1991)</span> to tumour
classification <span class="citation">(Nguyen and Rocke 2002)</span> to
spatial analysis in brain images <span class="citation">(McIntosh et al.
1996)</span> to marketing <span class="citation">(Fornell and Bookstein
1982)</span>.</p>
<p>In the usual multiple linear regression (MLR) context, the
least-squares solution for</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ˜</mi><mo>=</mo><mi>ğ—</mi><mi>ğ</mi><mo>+</mo><mi>Î•</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{Y} = \mathbf{X}\mathbf{B} + \Epsilon
\end{equation}</annotation></semantics></math></p>
<p>is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ</mi><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ—</mi><mi>T</mi></msup><mi>ğ—</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ—</mi><mi>T</mi></msup><mi>ğ˜</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{B} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}
\label{eq:lsq}
\end{equation}</annotation></semantics></math></p>
<p>The problem often is that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ğ—</mi><mi>T</mi></msup><mi>ğ—</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}^T \mathbf{X}</annotation></semantics></math>
is singular, either because the number of variables (columns) in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
exceeds the number of objects (rows), or because of collinearities. Both
PCR and PLSR circumvent this by decomposing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
into orthogonal scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ“</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>
and loadings
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ</mi><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ—</mi><mo>=</mo><mi>ğ“</mi><msup><mi>ğ</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{X} = \mathbf{T} \mathbf{P}^T
\end{equation}</annotation></semantics></math></p>
<p>and regressing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
not on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
itself but on the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
columns of the scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ“</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>.
In PCR, the scores are given by the left singular vectors of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>,
multiplied with the corresponding singular values, and the loadings are
the right singular vectors of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>.
This, however, only takes into account information about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>,
and therefore may be suboptimal for prediction purposes. PLSR aims to
incorporate information on both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
in the definition of the scores and loadings. In fact, for one specific
version of PLSR, called SIMPLS <span class="citation">(Jong
1993)</span>, it can be shown that the scores and loadings are chosen in
such a way to describe as much as possible of the <em>covariance</em>
between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>,
where PCR concentrates on the <em>variance</em> of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>.
Other PLSR algorithms give identical results to SIMPLS in the case of
one
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
variable, but deviate slightly for the multivariate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
case ; the differences are not likely to be important in practice.</p>
<div class="section level3">
<h3 id="algorithms">2.1 Algorithms<a class="anchor" aria-label="anchor" href="#algorithms"></a>
</h3>
<p>In PCR, we approximate the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
matrix by the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
Principal Components (PCs), usually obtained from the singular value
decomposition (SVD):</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ—</mi><mo>=</mo><msub><mover><mi>ğ—</mi><mo accent="true">Ìƒ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo>+</mo><msub><mi>Î•</mi><mi>X</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ğ”</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msub><mi>ğƒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mi>ğ•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msubsup><mo>+</mo><msub><mi>Î•</mi><mi>X</mi></msub><mo>=</mo><msub><mi>ğ“</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></msub><msubsup><mi>ğ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>T</mi></msubsup><mo>+</mo><msub><mi>Î•</mi><mi>X</mi></msub></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{X} = \tilde{\mathbf{X}}_{(a)} + \Epsilon_X
    = (\mathbf{U}_{(a)} \mathbf{D}_{(a)} ) \mathbf{V}^T_{(a)} + \Epsilon_X
    = \mathbf{T}_{(a)} \mathbf{P}_{(a)}^T + \Epsilon_X
\end{equation}</annotation></semantics></math></p>
<p>Next, we regress
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
on the scores, which leads to regression coefficients</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ</mi><mo>=</mo><mi>ğ</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ“</mi><mi>T</mi></msup><mi>ğ“</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ“</mi><mi>T</mi></msup><mi>ğ˜</mi><mo>=</mo><mi>ğ•</mi><msup><mi>ğƒ</mi><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ”</mi><mi>T</mi></msup><mi>ğ˜</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{B} = \mathbf{P} (\mathbf{T}^T \mathbf{T})^{-1} \mathbf{T}^T \mathbf{Y}
    = \mathbf{V} \mathbf{D}^{-1} \mathbf{U}^T \mathbf{Y}
\end{equation}</annotation></semantics></math></p>
<p>where the subscripts
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
have been dropped for clarity. For PLSR, the components, called Latent
Variables (LVs) in this context, are obtained iteratively. One starts
with the SVD of the crossproduct matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ’</mi><mo>=</mo><msup><mi>ğ—</mi><mi>T</mi></msup><mi>ğ˜</mi></mrow><annotation encoding="application/x-tex">\mathbf{S} = \mathbf{X}^T \mathbf{Y}</annotation></semantics></math>,
thereby including information on variation in both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>,
and on the correlation between them. The first left and right singular
vectors,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>,
are used as weight vectors for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>,
respectively, to obtain scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>u</mi><annotation encoding="application/x-tex">u</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mi>ğ—</mi><mi>w</mi><mo>=</mo><mi>ğ„</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
t = \mathbf{X} w = \mathbf{E} w
\end{equation}</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mi>ğ˜</mi><mi>q</mi><mo>=</mo><mi>ğ…</mi><mi>q</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
u = \mathbf{Y} q = \mathbf{F} q
\end{equation}</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ„</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ…</mi><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math>
are initialised as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>,
respectively. The X scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
are often normalised:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mi>t</mi><mi>/</mi><msqrt><mrow><msup><mi>t</mi><mi>T</mi></msup><mi>t</mi></mrow></msqrt></mrow><annotation encoding="application/x-tex">\begin{equation}
t =  t / \sqrt{t^Tt}
\end{equation}</annotation></semantics></math></p>
<p>The Y scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>u</mi><annotation encoding="application/x-tex">u</annotation></semantics></math>
are not actually necessary in the regression but are often saved for
interpretation purposes. Next, X and Y loadings are obtained by
regressing against the <em>same</em> vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><msup><mi>ğ„</mi><mi>T</mi></msup><mi>t</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\label{eq:plspt}
p = \mathbf{E}^T t
\end{equation}</annotation></semantics></math><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>=</mo><msup><mi>ğ…</mi><mi>T</mi></msup><mi>t</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
\label{eq:plsqt}
q = \mathbf{F}^T t
\end{equation}</annotation></semantics></math></p>
<p>Finally, the data matrices are â€˜deflatedâ€™: the information related to
this latent variable, in the form of the outer products
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msup><mi>p</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">t p^T</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msup><mi>q</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">t q^T</annotation></semantics></math>,
is subtracted from the (current) data matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ„</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ…</mi><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math>.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ„</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>ğ„</mi><mi>n</mi></msub><mo>âˆ’</mo><mi>t</mi><msup><mi>p</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{E}_{n+1} = \mathbf{E}_n - t p^T
\end{equation}</annotation></semantics></math><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ…</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>ğ…</mi><mi>n</mi></msub><mo>âˆ’</mo><mi>t</mi><msup><mi>q</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{F}_{n+1} = \mathbf{F}_n - t q^T
\end{equation}</annotation></semantics></math></p>
<p>The estimation of the next component then can start from the SVD of
the crossproduct matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>ğ„</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>ğ…</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{E}_{n+1}^T\mathbf{F}_{n+1}</annotation></semantics></math>.
After every iteration, vectors
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>w</mi><annotation encoding="application/x-tex">w</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>
are saved as columns in matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ–</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ“</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ</mi><annotation encoding="application/x-tex">\mathbf{P}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ</mi><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math>,
respectively. One complication is that columns of matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ–</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math>
can not be compared directly: they are derived from successively
deflated matrices
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ„</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ…</mi><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math>.
It has been shown that an alternative way to represent the weights, in
such a way that all columns relate to the original
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
matrix, is given by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ‘</mi><mo>=</mo><mi>ğ–</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ</mi><mi>T</mi></msup><mi>ğ–</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{R} = \mathbf{W} (\mathbf{P}^T \mathbf{W})^{-1}
\end{equation}</annotation></semantics></math></p>
<p>Now, we are in the same position as in the PCR case: instead of
regressing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>,
we use scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ“</mi><annotation encoding="application/x-tex">\mathbf{T}</annotation></semantics></math>
to calculate the regression coefficients, and later convert these back
to the realm of the original variables by pre-multiplying with matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘</mi><annotation encoding="application/x-tex">\mathbf{R}</annotation></semantics></math>
(since
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ“</mi><mo>=</mo><mi>ğ—</mi><mi>ğ‘</mi></mrow><annotation encoding="application/x-tex">\mathbf{T} = \mathbf{X} \mathbf{R}</annotation></semantics></math>):</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ</mi><mo>=</mo><mi>ğ‘</mi><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ“</mi><mi>T</mi></msup><mi>ğ“</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ“</mi><mi>T</mi></msup><mi>ğ˜</mi><mo>=</mo><mi>ğ‘</mi><msup><mi>ğ“</mi><mi>T</mi></msup><mi>ğ˜</mi><mo>=</mo><mi>ğ‘</mi><msup><mi>ğ</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\begin{equation}
\mathbf{B} = \mathbf{R} (\mathbf{T}^T \mathbf{T})^{-1} \mathbf{T}^T \mathbf{Y}
    = \mathbf{R} \mathbf{T}^T \mathbf{Y}
    = \mathbf{R} \mathbf{Q}^T
\end{equation}</annotation></semantics></math></p>
<p>Again, here, only the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
components are used. How many components are optimal has to be
determined, usually by cross-validation.</p>
<p>Many alternative formulations can be found in literature. It has been
shown, for instance, that only one of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
needs to be deflated ; alternatively, one can directly deflate the
crossproduct matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ’</mi><annotation encoding="application/x-tex">\mathbf{S}</annotation></semantics></math>
(as is done in SIMPLS, for example). Moreover, there are many equivalent
ways of scaling. In the example above, the scores
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
have been normalised, but one can also choose to introduce normalisation
at another point in the algorithm. Unfortunately, this can make it
difficult to directly compare the scores and loadings of different PLSR
implementations.</p>
</div>
<div class="section level3">
<h3 id="on-the-use-of-plsr-and-pcr">2.2 On the use of PLSR and PCR<a class="anchor" aria-label="anchor" href="#on-the-use-of-plsr-and-pcr"></a>
</h3>
<p>In theory, PLSR should have an advantage over PCR. One could imagine
a situation where a minor component in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
is highly correlated with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
; not selecting enough components would then lead to very bad
predictions. In PLSR, such a component would be automatically present in
the first LV. In practice, however, there is hardly any difference
between the use of PLSR and PCR ; in most situations, the methods
achieve similar prediction accuracies, although PLSR usually needs fewer
latent variables than PCR. Put the other way around: with the same
number of latent variables, PLSR will cover more of the variation in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
and PCR will cover more of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>.
In turn, both behave very similar to ridge regression <span class="citation">(Frank and Friedman 1993)</span>.</p>
<p>It can also be shown that both PCR and PLSR behave as shrinkage
methods <span class="citation">(Hastie, Tibshirani, and Friedman
2001)</span>, although in some cases PLSR seems to increase the variance
of individual regression coefficients, one possible explanation of why
PLSR is not always better than PCR.</p>
</div>
</div>
<div class="section level2">
<h2 id="example-session">3 Example session<a class="anchor" aria-label="anchor" href="#example-session"></a>
</h2>
<p>In this section we will walk through an example session, to get an
overview of the package. To be able to use the package, one first has to
load it:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/khliland/pls" class="external-link">pls</a></span><span class="op">)</span></span></code></pre></div>
<p>This prints a message telling that the package has been attached, and
that the package implements a function <code>loadings</code> that masks
a function of the same name in package <strong>stats</strong>. (The
output of the commands have in some cases been suppressed to save
space.)</p>
<p>Four example data sets are included in <strong>pls</strong>:</p>
<ul>
<li>
<strong><code>yarn</code></strong>: A data set with 28 near-infrared
spectra (<code>NIR</code>) of PET yarns, measured at 268 wavelengths, as
predictors, and density as response (<code>density</code>) <span class="citation">(Swierenga et al. 1999)</span>. The data set also
includes a logical variable <code>train</code> which can be used to
split the data into a training data set of size 21 and test data set of
size 7. See <code><a href="../reference/yarn.html">?yarn</a></code> for details.</li>
<li>
<strong><code>oliveoil</code></strong>: A data set with 5 quality
measurements (<code>chemical</code>) and 6 panel sensory panel variables
(<code>sensory</code>) made on 16 olive oil samples <span class="citation">(Massart et al. 1998)</span>. See
<code><a href="../reference/oliveoil.html">?oliveoil</a></code> for details.</li>
<li>
<strong><code>gasoline</code></strong>: A data set consisting of
octane number (<code>octane</code>) and NIR spectra (<code>NIR</code>)
of 60 gasoline samples <span class="citation">(Kalivas 1997)</span>.
Each NIR spectrum consists of 401 diffuse reflectance measurements from
900 to 1700 nm. See <code><a href="../reference/gasoline.html">?gasoline</a></code> for details.</li>
<li>
<strong><code>mayonnaise</code></strong>: A data set consisting of
oil type (<code>oil.type</code>), experimental design
(<code>design</code>), train-test split (<code>train</code>) and NIR
spectra (<code>NIR</code>) of 162 mayonnaise samples <span class="citation">(Indahl et al. 1999)</span>. Each NIR spectrum consists
of 351 measurements from 1100 to 2500 nm. See
<code><a href="../reference/mayonnaise.html">?mayonnaise</a></code>for details.</li>
</ul>
<p>These will be used in the examples that follow. To use the data sets,
they must first be loaded:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">yarn</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">oliveoil</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">gasoline</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">mayonnaise</span><span class="op">)</span></span></code></pre></div>
<p>For the rest of the paper, it will be assumed that the package and
the data sets have been loaded as above. Also, all examples are run with
<code>options(digits = 4)</code>.</p>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-NIR-1.png" class="r-plt" alt="Gasoline NIR spectra" width="700"><p class="caption">
Gasoline NIR spectra
</p>
</div>
<p>In this section, we will do a PLSR on the <code>gasoline</code> data
to illustrate the use of <strong>pls</strong>. The spectra are shown in
Figure 1. We first divide the data set into train and test data
sets:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gasTrain</span> <span class="op">&lt;-</span> <span class="va">gasoline</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span>,<span class="op">]</span></span>
<span><span class="va">gasTest</span> <span class="op">&lt;-</span> <span class="va">gasoline</span><span class="op">[</span><span class="fl">51</span><span class="op">:</span><span class="fl">60</span>,<span class="op">]</span></span></code></pre></div>
<p>A typical way of fitting a PLSR model is</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gas1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">octane</span> <span class="op">~</span> <span class="va">NIR</span>, ncomp <span class="op">=</span> <span class="fl">10</span>, data <span class="op">=</span> <span class="va">gasTrain</span>, validation <span class="op">=</span> <span class="st">"LOO"</span><span class="op">)</span></span></code></pre></div>
<p>This fits a model with 10 components, and includes
<em>leave-one-out</em> (LOO) cross-validated predictions <span class="citation">(Lachenbruch and Mickey 1968)</span>. We can get an
overview of the fit and validation results with the <code>summary</code>
method:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">gas1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Data:    X dimension: 50 401 </span></span>
<span><span class="co">##  Y dimension: 50 1</span></span>
<span><span class="co">## Fit method: kernelpls</span></span>
<span><span class="co">## Number of components considered: 10</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## VALIDATION: RMSEP</span></span>
<span><span class="co">## Cross-validated using 50 leave-one-out segments.</span></span>
<span><span class="co">##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps</span></span>
<span><span class="co">## CV           1.545    1.357   0.2966   0.2524   0.2476   0.2398   0.2319</span></span>
<span><span class="co">## adjCV        1.545    1.356   0.2947   0.2521   0.2478   0.2388   0.2313</span></span>
<span><span class="co">##        7 comps  8 comps  9 comps  10 comps</span></span>
<span><span class="co">## CV      0.2386   0.2316   0.2449    0.2673</span></span>
<span><span class="co">## adjCV   0.2377   0.2308   0.2438    0.2657</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## TRAINING: % variance explained</span></span>
<span><span class="co">##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps</span></span>
<span><span class="co">## X         78.17    85.58    93.41    96.06    96.94    97.89    98.38    98.85</span></span>
<span><span class="co">## octane    29.39    96.85    97.89    98.26    98.86    98.96    99.09    99.16</span></span>
<span><span class="co">##         9 comps  10 comps</span></span>
<span><span class="co">## X         99.02     99.19</span></span>
<span><span class="co">## octane    99.28     99.39</span></span></code></pre>
<p>The validation results here are <em>Root Mean Squared Error of
Prediction</em> (RMSEP). There are two cross-validation estimates:
<code>CV</code> is the ordinary CV estimate, and <code>adjCV</code> is a
bias-corrected CV estimate <span class="citation">(Mevik and Cederkvist
2004)</span>. (For a LOO CV, there is virtually no difference) .</p>
<p>It is often simpler to judge the RMSEPs by plotting them:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="../reference/mvrVal.html">RMSEP</a></span><span class="op">(</span><span class="va">gas1</span><span class="op">)</span>, legendpos <span class="op">=</span> <span class="st">"topright"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-RMSEP-1.png" class="r-plt" alt="Cross-validated RMSEP curves for the gasoline data" width="700"><p class="caption">
Cross-validated RMSEP curves for the gasoline data
</p>
</div>
<p>This plots the estimated RMSEPs as functions of the number of
components (Figure 2). The <code>legendpos</code> argument adds a legend
at the indicated position. Two components seem to be enough. This gives
an RMSEP of 0.297.</p>
<p>As mentioned in the introduction, the main practical difference
between PCR and PLSR is that PCR often needs more components than PLSR
to achieve the same prediction error. On this data set, PCR would need
three components to achieve the same RMSEP. Once the number of
components has been chosen, one can inspect different aspects of the fit
by plotting predictions, scores, loadings, etc. The default plot is a
prediction plot:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gas1</span>, ncomp <span class="op">=</span> <span class="fl">2</span>, asp <span class="op">=</span> <span class="fl">1</span>, line <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-cvpreds-1.png" class="r-plt" alt="Cross-validated predictions for the gasoline data" width="336"><p class="caption">
Cross-validated predictions for the gasoline data
</p>
</div>
<p>This shows the cross-validated predictions with two components versus
measured values (Figure 3). We have chosen an aspect ratio of 1, and to
draw a target line. The points follow the target line quite nicely, and
there is no indication of a curvature or other anomalies. Other plots
can be selected with the argument <code>plottype</code>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gas1</span>, plottype <span class="op">=</span> <span class="st">"scores"</span>, comps <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-scores-1.png" class="r-plt" alt="Score plot for the gasoline data" width="700"><p class="caption">
Score plot for the gasoline data
</p>
</div>
<p>This gives a pairwise plot of the score values for the three first
components (Figure 4). Score plots are often used to look for patterns,
groups or outliers in the data. (For instance, plotting the two first
components for a model built on the <code>yarn</code> dataset clearly
indicates the experimental design of that data.) In this example, there
is no clear indication of grouping or outliers. The numbers in
parentheses after the component labels are the relative amount of X
variance explained by each component. The explained variances can be
extracted explicitly with</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/coef.mvr.html">explvar</a></span><span class="op">(</span><span class="va">gas1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  Comp 1  Comp 2  Comp 3  Comp 4  Comp 5  Comp 6  Comp 7  Comp 8  Comp 9 Comp 10 </span></span>
<span><span class="co">## 78.1708  7.4122  7.8242  2.6578  0.8768  0.9466  0.4922  0.4723  0.1688  0.1694</span></span></code></pre>
<p>The loading plot (Figure 5) is much used for interpretation purposes,
for instance to look for known spectral peaks or profiles:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">0.3</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gas1</span>, <span class="st">"loadings"</span>, comps <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, legendpos <span class="op">=</span> <span class="st">"topleft"</span>,</span>
<span>     labels <span class="op">=</span> <span class="st">"numbers"</span>, xlab <span class="op">=</span> <span class="st">"nm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-loadings-1.png" class="r-plt" alt="Loading plot for the gasoline data" width="700"><p class="caption">
Loading plot for the gasoline data
</p>
</div>
<p>The <code>labels = "numbers"</code> argument makes the plot function
try to interpret the variable names as numbers, and use them as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
axis labels. Score and loading plots also have their own plotting
functions, <code>scoreplot</code> and <code>loadingplot</code>, which
have more options for plotting scores and loadings, respectively. For
instance, <code>scoreplot</code>and its companion extractor
<code>scores</code> has the same argument as <code>RMSEP/MSEP/R2</code>
called <code>estimate</code>, which can be used to plot cross-validated
scores or test data scores, e.g.,</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">par.old</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/scoreplot.html">scoreplot</a></span><span class="op">(</span><span class="va">gas1</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/scoreplot.html">scoreplot</a></span><span class="op">(</span><span class="va">gas1</span>, estimate<span class="op">=</span><span class="st">"CV"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-scores-cv-1.png" class="r-plt" alt="Calibrated and cross-validated score plots for the gasoline data" width="480"><p class="caption">
Calibrated and cross-validated score plots for the gasoline data
</p>
</div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span><span class="va">par.old</span><span class="op">)</span></span></code></pre></div>
<p>A fitted model is often used to predict the response values of new
observations. The following predicts the responses for the ten
observations in <code>gasTest</code>, using two components:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">gas1</span>, ncomp <span class="op">=</span> <span class="fl">2</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## , , 2 comps</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##    octane</span></span>
<span><span class="co">## 51  87.94</span></span>
<span><span class="co">## 52  87.25</span></span>
<span><span class="co">## 53  88.16</span></span>
<span><span class="co">## 54  84.97</span></span>
<span><span class="co">## 55  85.15</span></span>
<span><span class="co">## 56  84.51</span></span>
<span><span class="co">## 57  87.56</span></span>
<span><span class="co">## 58  86.85</span></span>
<span><span class="co">## 59  89.19</span></span>
<span><span class="co">## 60  87.09</span></span></code></pre>
<p>Because we know the true response values for these samples, we can
calculate the test set RMSEP:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/mvrVal.html">RMSEP</a></span><span class="op">(</span><span class="va">gas1</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps  </span></span>
<span><span class="co">##      1.5369       1.1696       0.2445       0.2341       0.3287       0.2780  </span></span>
<span><span class="co">##     6 comps      7 comps      8 comps      9 comps     10 comps  </span></span>
<span><span class="co">##      0.2703       0.3301       0.3571       0.4090       0.6116</span></span></code></pre>
<p>For two components, we get 0.244, which is quite close to the
cross-validated estimate above (0.297).</p>
</div>
<div class="section level2">
<h2 id="formulas-and-data-frames">4 Formulas and data frames<a class="anchor" aria-label="anchor" href="#formulas-and-data-frames"></a>
</h2>
<p>The <strong>pls</strong> package has a formula interface that works
like the formula interface in <strong>R</strong>â€™s standard
<code>lm</code> functions, in most ways. This section gives a short
description of formulas and data frames as they apply to
<strong>pls</strong>. More information on formulas can be found in the
<code>lm</code> help file, in Chapter 11 of â€˜An Introduction to Râ€™, and
in Chapter 2 of â€˜The White Bookâ€™ <span class="citation">(Chambers and
Hastie 1992)</span>. These are good reads for anyone wanting to
understand how <strong>R</strong> works with formulas, and the user is
strongly advised to read them.</p>
<div class="section level3">
<h3 id="formulas">4.1 Formulas<a class="anchor" aria-label="anchor" href="#formulas"></a>
</h3>
<p>A <em>formula</em> consists of a <em>left hand side</em> (lhs), a
tilde (<code>~</code>), and a <em>right hand side</em> (rhs). The lhs
consists of a single term, representing the response(s). The rhs
consists of one or more terms separated by <code>+</code>, representing
the regressor(s). For instance, in the formula
<code>a ~ b + c + d</code>, <code>a</code> is the response, and
<code>b</code>, <code>c</code>, and <code>d</code> are the regressors.
The intercept is handled automatically, and need not be specified in the
formula. Each term represents a matrix, a numeric vector or a factor (a
factor should not be used as the response). If the response term is a
matrix, a multi-response model is fit. In <strong>pls</strong>, the
right hand side quite often consists of a single term, representing a
matrix regressor: <code>y ~ X</code>. It is also possible to specify
transformations of the variables. For instance,
<code>log(y) ~ msc(Z)</code> specifies a regression of the logarithm of
<code>y</code> onto <code>Z</code> after <code>Z</code> has been
transformed by <em>Multiplicative Scatter (or Signal) Correction</em>
(MSC) <span class="citation">(Geladi, MacDougall, and Martens
1985)</span>, a pre-treatment that is very common in infrared
spectroscopy. If the transformations contain symbols that are
interpreted in the formula handling, e.g., <code>+</code>,
<code>*</code> or <code>^</code>, the terms should be protected with the
<code><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I()</a></code> function, like this: <code>y ~ x1 + I(x2 + x3)</code>.
This specifies <em>two</em> regressors: <code>x1</code>, and the sum of
<code>x2</code> and <code>x3</code>.</p>
</div>
<div class="section level3">
<h3 id="data-frames">4.2 Data frames<a class="anchor" aria-label="anchor" href="#data-frames"></a>
</h3>
<p>The fit functions first look for the specified variables in a
supplied data frame, and it is advisable to collect all variables there.
This makes it easier to know what data has been used for fitting, to
keep different variants of the data around, and to predict new data. To
create a data frame, one can use the <code>data.frame</code> function:
if <code>v1</code>, <code>v2</code> and <code>v3</code> are factors or
numeric vectors,
<code>mydata &lt;- data.frame(y = v1, a = v2, b = v3)</code> will result
in a data frame with variables named <code>y</code>, <code>a</code> and
<code>b</code>. PLSR and PCR are often used with a matrix as the single
predictor term (especially when one is working with spectroscopic data).
Also, multi-response models require a matrix as the response term. If
<code>Z</code> is a matrix, it has to be protected by the â€˜protect
functionâ€™ <code><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I()</a></code> in calls to <code>data.frame</code>:
<code>mydata &lt;- data.frame(..., Z = I(Z))</code>. Otherwise, it will
be split into separate variables for each column, and there will be no
variable called <code>Z</code> in the data frame, so we cannot use
<code>Z</code> in the formula. One can also add the matrix to an
existing data frame:</p>
<pre><code>&gt; mydata &lt;- data.frame(...)
&gt; mydata$Z &lt;- Z</code></pre>
<p>This will also prevent <code>Z</code> from being split into separate
variables. Finally, one can use <code>cbind</code> to combine vectors
and matrices into matrices on the fly in the formula. This is most
useful for the response, e.g., <code>cbind(y1, y2) ~ X</code>. Variables
in a data frame can be accessed with the <code>$</code> operator, e.g.,
<code>mydata$y</code>. However, the <strong>pls</strong> functions
access the variables automatically, so the user should never use
<code>$</code> in formulas.</p>
</div>
</div>
<div class="section level2">
<h2 id="fitting-models">5 Fitting models<a class="anchor" aria-label="anchor" href="#fitting-models"></a>
</h2>
<p>The main functions for fitting models are <code>pcr</code> and
<code>plsr</code>. (They are simply wrappers for the function
<code>mvr</code>, selecting the appropriate fit algorithm) . We will use
<code>plsr</code> in the examples in this section, but everything could
have been done with <code>pcr</code> (or <code>mvr</code>). In its
simplest form, the function call for fitting models is
<code>plsr(formula, ncomp, data)</code> (where <code>plsr</code> can be
substituted with <code>pcr</code> or <code>mvr</code>). The argument
<code>formula</code> is a formula as described above, <code>ncomp</code>
is the number of components one wishes to fit, and <code>data</code> is
the data frame containing the variables to use in the model. The
function returns a fitted model (an object of class <code>"mvr"</code>)
which can be inspected (Section 7) or used for predicting new
observations (Section 8). For instance:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dens1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">density</span> <span class="op">~</span> <span class="va">NIR</span>, ncomp <span class="op">=</span> <span class="fl">5</span>, data <span class="op">=</span> <span class="va">yarn</span><span class="op">)</span></span></code></pre></div>
<p>If the response term of the formula is a matrix, a multi-response
model is fit, e.g.,:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">oliveoil</span><span class="op">$</span><span class="va">sensory</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 16  6</span></span></code></pre>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">sensory</span> <span class="op">~</span> <span class="va">chemical</span>, data <span class="op">=</span> <span class="va">oliveoil</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Partial least squares regression, fitted with the kernel algorithm.</span></span>
<span><span class="co">## Call:</span></span>
<span><span class="co">## pls::plsr(formula = sensory ~ chemical, data = oliveoil)</span></span></code></pre>
<p>(As we see, the <code>print</code> method simply tells us what type
of model this is, and how the fit function was called.)</p>
<p>The argument <code>ncomp</code> is optional. If it is missing, the
maximal possible number of components are used. Also <code>data</code>
is optional, and if it is missing, the variables specified in the
formula is searched for in the global environment (the userâ€™s
workspace). Usually, it is preferable to keep the variables in data
frames, but it can sometimes be convenient to have them in the global
environment. If the variables reside in a data frame,
e.g.Â <code>yarn</code>, <em>do not</em> be tempted to use formulas like
<code>yarn$density ~ yarn$NIR</code>! Use <code>density ~ NIR</code> and
specify the data frame with <code>data = yarn</code> as above. There are
facilities for working interactively with models. To use only part of
the samples in a data set, for instance the first 20, one can use
arguments <code>subset = 1:20</code> or <code>data = yarn[1:20,]</code>.
Also, if one wants to try different alternatives of the model, one can
use the function <code>update</code>. For instance</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">trainind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">yarn</span><span class="op">$</span><span class="va">train</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">dens2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">dens1</span>, subset <span class="op">=</span> <span class="va">trainind</span><span class="op">)</span></span></code></pre></div>
<p>will refit the model <code>dens1</code> using only the observations
which are marked as <code>TRUE</code> in <code>yarn$train</code>,
and</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dens3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">dens1</span>, ncomp <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>will change the number of components to 10. Other arguments, such as
<code>formula</code>, can also be changed with <code>update</code>. This
can save a bit of typing when working interactively with models (but it
doesnâ€™t save computing time; the model is refitted each time). In
general, the reader is referred to â€˜The White Bookâ€™ <span class="citation">(Chambers and Hastie 1992)</span> or â€˜An Introduction
to Râ€™ for more information about fitting and working with models in
<strong>R</strong>.</p>
<p>Missing data can sometimes be a problem. The PLSR and PCR algorithms
currently implemented in <strong>pls</strong> do not handle missing
values intrinsically, so observations with missing values must be
removed. This can be done with the <code>na.action</code> argument. With
<code>na.action = na.omit</code> (the default), any observation with
missing values will be removed from the model completely. With
<code>na.action = na.exclude</code>, they will be removed from the
fitting process, but included as <code>NA</code>s in the residuals and
fitted values. If you want an explicit error when there are missing
values in the data, use <code>na.action = na.fail</code>. The default
<code>na.action</code> can be set with <code><a href="https://rdrr.io/r/base/options.html" class="external-link">options()</a></code>, e.g.,
<code>options(na.action = quote(na.fail))</code>.</p>
<p>Standardisation and other pre-treatments of predictor variables are
often called for. In <strong>pls</strong>, the predictor variables are
always centered, as a part of the fit algorithm. Scaling can be
requested with the <code>scale</code> argument. If <code>scale</code> is
<code>TRUE</code>, each variable is standardised by dividing it by its
standard deviation, and if <code>scale</code> is a numeric vector, each
variable is divided by the corresponding number. For instance, this will
fit a model with standardised chemical measurements:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">olive1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">sensory</span> <span class="op">~</span> <span class="va">chemical</span>, scale <span class="op">=</span> <span class="cn">TRUE</span>, data <span class="op">=</span> <span class="va">oliveoil</span><span class="op">)</span></span></code></pre></div>
<p>As mentioned earlier, MSC <span class="citation">(Geladi, MacDougall,
and Martens 1985)</span> is implemented in <strong>pls</strong> as a
function <code>msc</code> that can be used in formulas:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gas2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">octane</span> <span class="op">~</span> <span class="fu"><a href="../reference/msc.html">msc</a></span><span class="op">(</span><span class="va">NIR</span><span class="op">)</span>, ncomp <span class="op">=</span> <span class="fl">10</span>, data <span class="op">=</span> <span class="va">gasTrain</span><span class="op">)</span></span></code></pre></div>
<p>This scatter corrects <code>NIR</code> prior to the fitting, and
arranges for new spectra to be automatically scatter corrected (using
the same reference spectrum as when fitting) in
<code>predict</code>:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">gas2</span>, ncomp <span class="op">=</span> <span class="fl">3</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">)</span></span></code></pre></div>
<p>There are other arguments that can be given in the fit call:
<code>validation</code> is for selecting validation, and
<code>...</code> is for sending arguments to the underlying functions,
notably the cross-validation function <code>mvrCv</code>. For the other
arguments, see <code><a href="../reference/mvr.html">?mvr</a></code>.</p>
</div>
<div class="section level2">
<h2 id="choosing-the-number-of-components-with-cross-validation">6 Choosing the number of components with cross-validation<a class="anchor" aria-label="anchor" href="#choosing-the-number-of-components-with-cross-validation"></a>
</h2>
<p>Cross-validation, commonly used to determine the optimal number of
components to take into account, is controlled by the
<code>validation</code> argument in the modelling functions
(<code>mvr</code>, <code>plsr</code> and <code>pcr</code>). The default
value is <code>"none"</code>. Supplying a value of <code>"CV"</code> or
<code>"LOO"</code> will cause the modelling procedure to call
<code>mvrCv</code> to perform cross-validation; <code>"LOO"</code>
provides leave-one-out cross-validation, whereas <code>"CV"</code>
divides the data into segments. Default is to use ten segments, randomly
selected, but also segments of consecutive objects or interleaved
segments (sometimes also referred to as â€˜Venetian blindsâ€™) are possible
through the use of the argument <code>segment.type</code>. One can also
specify the segments explicitly with the argument <code>segments</code>;
see <code><a href="../reference/mvrCv.html">?mvrCv</a></code> for details. When validation is performed in
this way, the model will contain an element comprising information on
the out-of-bag predictions (in the form of predicted values, as well as
MSEP and R2 values). As a reference, the MSEP error using no components
at all is calculated as well. The validation results can be visualised
using the <code>plottype = "validation"</code> argument of the standard
plotting function. An example is shown in Figure 2 for the gasoline
data; typically, one would select a number of components after which the
cross-validation error does not show a significant decrease. The
decision on how many components to retain will to some extent always be
subjective. However, especially when building large numbers of models
(e.g., in simulation studies), it can be crucial to have a consistent
strategy on how to choose the â€œoptimalâ€ number of components. Two such
strategies have been implemented in function <code>selectNcomp</code>.
The first is based on the so-called one-sigma heuristic <span class="citation">(Hastie, Friedman, and Tibshirani 2013)</span> and
consists of choosing the model with fewest components that is still less
than one standard error away from the overall best model. The second
strategy employs a permutation approach, and basically tests whether
adding a new component is beneficial at all <span class="citation">(Voet
1994)</span>. It is implemented backwards, again taking the global
minimum in the crossvalidation curve as a starting point, and assessing
models with fewer and fewer components: as long as no significant
deterioration in performance is found (by default on the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.01</annotation></semantics></math>
level), the algorithm continues to remove components. Applying the
function is quite straightforward:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ncomp.onesigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/selectNcomp.html">selectNcomp</a></span><span class="op">(</span><span class="va">gas2</span>, method <span class="op">=</span> <span class="st">"onesigma"</span>, plot <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                              ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.18</span>, <span class="fl">.6</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ncomp.permut</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/selectNcomp.html">selectNcomp</a></span><span class="op">(</span><span class="va">gas2</span>, method <span class="op">=</span> <span class="st">"randomization"</span>, plot <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                            ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.18</span>, <span class="fl">.6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>This leads to the plots in Figure 6 â€“ note that graphical arguments
can be supplied to customize the plots. In both cases, the global
minimum of the crossvalidation curve is indicated with gray dotted
lines, and the suggestion for the optimal number of components with a
vertical blue dashed line. The left plot shows the width of the
one-sigma intervals on which the suggestion is based ; the right plot
indicates which models have been assessed by the permutation approach
through the large blue circles. The two criteria do not always agree (as
in this case) but usually are quite close.</p>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-NComp-1.png" class="r-plt" alt="The two strategies for suggesting optimal model dimensions: the left plot shows the one-sigma strategy, the right plot the permutation strategy." width="960"><p class="caption">
The two strategies for suggesting optimal model dimensions: the left
plot shows the one-sigma strategy, the right plot the permutation
strategy.
</p>
</div>
<p>When a pre-treatment that depends on the composition of the training
set is applied, the cross-validation procedure as described above is not
optimal, in the sense that the cross-validation errors are biased
downward. As long as the only purpose is to select the optimal number of
components, this bias may not be very important, but it is not too
difficult to avoid it. The modelling functions have an argument
<code>scale</code> that can be used for auto-scaling per segment.
However, more elaborate methods such as MSC need explicit handling per
segment. For this, the function <code>crossval</code> is available. It
takes an <code>mvr</code> object and performs the cross-validation as it
should be done: applying the pre-treatment for each segment. The results
can be shown in a plot (which looks very similar to Figure 2) or
summarised in numbers.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gas2.cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/crossval.html">crossval</a></span><span class="op">(</span><span class="va">gas2</span>, segments <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="../reference/mvrVal.html">MSEP</a></span><span class="op">(</span><span class="va">gas2.cv</span><span class="op">)</span>, legendpos<span class="op">=</span><span class="st">"topright"</span><span class="op">)</span></span></code></pre></div>
<p><img src="pls-manual_files/figure-html/crossval-1.png" class="r-plt" width="700" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">gas2.cv</span>, what <span class="op">=</span> <span class="st">"validation"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Data:    X dimension: 50 401 </span></span>
<span><span class="co">##  Y dimension: 50 1</span></span>
<span><span class="co">## Fit method: kernelpls</span></span>
<span><span class="co">## Number of components considered: 10</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## VALIDATION: RMSEP</span></span>
<span><span class="co">## Cross-validated using 10 random segments.</span></span>
<span><span class="co">##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps</span></span>
<span><span class="co">## CV           1.545    1.319   0.2754   0.2614   0.2630   0.2546   0.2636</span></span>
<span><span class="co">## adjCV        1.545    1.316   0.2745   0.2601   0.2582   0.2500   0.2571</span></span>
<span><span class="co">##        7 comps  8 comps  9 comps  10 comps</span></span>
<span><span class="co">## CV      0.2671   0.2794   0.3098    0.3250</span></span>
<span><span class="co">## adjCV   0.2605   0.2713   0.2986    0.3119</span></span></code></pre>
<p>Applying MSC in this case leads to nearly identical cross-validation
estimates of prediction error. When the scaling does not depend on the
division of the data into segments (e.g., log-scaling), functions
<code>crossval</code> and <code>mvrCv</code> give the same results ;
however, <code>crossval</code> is much slower.</p>
<p>Cross-validation can be computationally demanding (especially when
using the function <code>crossval</code>). Therefore, both
<code>mvrCv</code> and <code>crossval</code> can perform the
calculations in parallel on a multi-core machine or on several machines.
How to do this is described in Section 9.2.</p>
</div>
<div class="section level2">
<h2 id="inspecting-fitted-models">7 Inspecting fitted models<a class="anchor" aria-label="anchor" href="#inspecting-fitted-models"></a>
</h2>
<p>A closer look at the fitted model may reveal interesting agreements
or disagreements with what is known about the relations between X and Y.
Several functions are implemented in <strong>pls</strong> for plotting,
extracting and summarising model components.</p>
<div class="section level3">
<h3 id="plotting">7.1 Plotting<a class="anchor" aria-label="anchor" href="#plotting"></a>
</h3>
<p>One can access all plotting functions through the
<code>"plottype"</code> argument of the <code>plot</code> method for
<code>mvr</code> objects. This is simply a wrapper function calling the
actual plot functions; the latter are available to the user as well. The
default plot is a prediction plot (<code>predplot</code>), showing
predicted versus measured values. Test set predictions are used if a
test set is supplied with the <code>newdata</code> argument. Otherwise,
if the model was built using cross-validation, the cross-validated
predictions are used, otherwise the predictions for the training set.
This can be overridden with the <code>which</code> argument. An example
of this type of plot can be seen in Figure 3. An optional argument can
be used to indicate how many components should be included in the
prediction. To assess how many components are optimal, a validation plot
(<code>validationplot</code>) can be used such as the one shown in
Figure 2; this shows a measure of prediction performance (either RMSEP,
MSEP, or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>)
against the number of components. Usually, one takes the first local
minimum rather than the absolute minimum in the curve, to avoid
over-fitting. The regression coefficients can be visualised using
<code>plottype = "coef"</code> in the <code>plot</code> method, or
directly through function <code>coefplot</code>. This allows
simultaneous plotting of the regression vectors for several different
numbers of components at once. The regression vectors for the
<code>gasoline</code> data set using MSC are shown in Figure 7 using the
command</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">gas1</span>, plottype <span class="op">=</span> <span class="st">"coef"</span>, ncomp<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, legendpos <span class="op">=</span> <span class="st">"bottomleft"</span>,</span>
<span>     labels <span class="op">=</span> <span class="st">"numbers"</span>, xlab <span class="op">=</span> <span class="st">"nm"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-gascoefs-1.png" class="r-plt" alt="Regression coefficients for the gasoline data" width="700"><p class="caption">
Regression coefficients for the gasoline data
</p>
</div>
<p>Note that the coefficients for two components and three components
are similar. This is because the third component contributes little to
the predictions. The RMSEPs (see Figure 2) and predictions (see Section
8) for two and three components are quite similar. Scores and loadings
can be plotted using functions <code>scoreplot</code> (an example is
shown in Figure 4) and <code>loadingplot</code> (in Figure 5),
respectively. One can indicate the number of components with the
<code>comps</code> argument ; if more than two components are given,
plotting the scores will give a pairs plot, otherwise a scatter plot.
For <code>loadingplot</code>, the default is to use line plots.</p>
<p>Finally, a â€˜correlation loadingsâ€™ plot (function
<code>corrplot</code>, or <code>plottype = "correlation"</code> in
<code>plot</code>) shows the correlations between each variable and the
selected components (see Figure 8). These plots are scatter plots of two
sets of scores with concentric circles of radii given by
<code>radii</code>. Each point corresponds to an X variable. The squared
distance between the point and the origin equals the fraction of the
variance of the variable explained by the components in the panel. The
default values for <code>radii</code> correspond to 50% and 100%
explained variance, respectively.</p>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-corrplot-1.png" class="r-plt" alt="Correlation loadings plot for the gasoline data" width="336"><p class="caption">
Correlation loadings plot for the gasoline data
</p>
</div>
<p>The plot functions accept most of the ordinary plot parameters, such
as <code>col</code> and <code>pch</code>. If the model has several
responses or one selects more than one model size,
e.g.Â <code>ncomp = 4:6</code>, in some plot functions (notably
prediction plots (see below), validation plots and coefficient plots)
the plot window will be divided and one plot will be shown for each
combination of response and model size. The number of rows and columns
are chosen automatically, but can be specified explicitly with arguments
<code>nRows</code> and <code>nCols</code>. If there are more plots than
fit the plot window, one will be asked to press return to see the rest
of the plots.</p>
</div>
<div class="section level3">
<h3 id="extraction">7.2 Extraction<a class="anchor" aria-label="anchor" href="#extraction"></a>
</h3>
<p>Regression coefficients can be extracted using the generic function
<code>coef</code>; the function takes several arguments, indicating the
number of components to take into account, and whether the intercept is
needed (default is <code>FALSE</code>). Scores and loadings can be
extracted using functions <code>scores</code> and <code>loadings</code>
for X, and <code>Yscores</code> and <code>Yloadings</code> for Y. These
also return the percentage of variance explained as attributes. In PLSR,
weights can be extracted using the function
<code>loading.weights</code>. When applied to a PCR model, the function
returns <code>NULL</code>. Note that commands like
<code>plot(scores(gas1))</code> are perfectly correct, and lead to
exactly the same plots as using <code>scoreplot</code>. The
<code>vcov</code> function can be used to get the covariance matrix of
<code>pcr</code> models, e.g., for uncertainty plotting (see
<code><a href="../reference/vcov.mvr.html">?vcov.mvr</a></code>).</p>
</div>
<div class="section level3">
<h3 id="summaries">7.3 Summaries<a class="anchor" aria-label="anchor" href="#summaries"></a>
</h3>
<p>The <code>print</code> method for an object of class
<code>"mvr"</code> shows the regression type used, perhaps indicating
the form of validation employed, and shows the function call. The
<code>summary</code> method gives more information: it also shows the
amount of variance explained by the model (for all choices of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>,
the number of latent variables). The <code>summary</code> method has an
additional argument (<code>what</code>) to be able to focus on the
training phase or validation phase, respectively. Default is to print
both types of information.</p>
</div>
</div>
<div class="section level2">
<h2 id="predicting-new-observations">8 Predicting new observations<a class="anchor" aria-label="anchor" href="#predicting-new-observations"></a>
</h2>
<p>Fitted models are often used to predict future observations, and
<strong>pls</strong> implements a <code>predict</code> method for PLSR
and PCR models. The most common way of calling this function is
<code>predict(mymod, ncomp = myncomp, newdata = mynewdata)</code>, where
<code>mymod</code> is a fitted model, <code>myncomp</code> specifies the
model size(s) to use, and <code>mynewdata</code> is a data frame with
new X observations. The data frame can also contain response
measurements for the new observations, which can be used to compare the
predicted values to the measured ones, or to estimate the overall
prediction ability of the model. If <code>newdata</code> is missing,
<code>predict</code> uses the data used to fit the model, i.e., it
returns fitted values. If the argument <code>ncomp</code> is missing,
<code>predict</code> returns predictions for models with 1 component, 2
components,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>â€¦</mi><annotation encoding="application/x-tex">\ldots</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
components, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>
is the number of components used when fitting the model. Otherwise, the
model size(s) listed in <code>ncomp</code> are used. For instance, to
get predictions from the model built in Section 3, with two and three
components, one would use</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">gas1</span>, ncomp <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">3</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## , , 2 comps</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##    octane</span></span>
<span><span class="co">## 51  87.94</span></span>
<span><span class="co">## 52  87.25</span></span>
<span><span class="co">## 53  88.16</span></span>
<span><span class="co">## 54  84.97</span></span>
<span><span class="co">## 55  85.15</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## , , 3 comps</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##    octane</span></span>
<span><span class="co">## 51  87.95</span></span>
<span><span class="co">## 52  87.30</span></span>
<span><span class="co">## 53  88.21</span></span>
<span><span class="co">## 54  84.87</span></span>
<span><span class="co">## 55  85.24</span></span></code></pre>
<p>(We predict only the five first test observations, to save space.)
The predictions with two and three components are quite similar. This
could be expected, given that the regression vectors (Figure 7) as well
as the estimated RMSEPs for the two model sizes were similar. One can
also specify explicitly which components to use when predicting. This is
done by specifying the components in the argument <code>comps</code>.
(If both <code>ncomp</code> and <code>comps</code> are specified,
<code>comps</code> takes precedence over <code>ncomp</code>.) For
instance, to get predictions from a model with only component 2, one can
use</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">gas1</span>, comps <span class="op">=</span> <span class="fl">2</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    octane</span></span>
<span><span class="co">## 51  87.53</span></span>
<span><span class="co">## 52  86.30</span></span>
<span><span class="co">## 53  87.35</span></span>
<span><span class="co">## 54  85.82</span></span>
<span><span class="co">## 55  85.32</span></span></code></pre>
<p>The results are different from the predictions with two components
(i.e., components one and two) above. (The intercept is always included
in the predictions. It can be removed by subtracting
<code>mymod$Ymeans</code> from the predicted values.)</p>
<p>The <code>predict</code> method returns a three-dimensional array, in
which the entry
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(i,j,k)</annotation></semantics></math>
is the predicted value for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
and model size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.
Note that singleton dimensions are not dropped, so predicting five
observations for a uni-response model with <code>ncomp = 3</code> gives
an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>Ã—</mo><mn>1</mn><mo>Ã—</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">5 \times 1 \times 1</annotation></semantics></math>
array, not a vector of length five. This is to make it easier to
distinguish between predictions from models with one response and
predictions with one model size. (When using the <code>comps</code>
argument, the last dimension is dropped, because the predictions are
always from a single model.) One can drop the singleton dimensions
explicitly by using <code>drop(predict(...))</code>:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/drop.html" class="external-link">drop</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">gas1</span>, ncomp <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">3</span>, newdata <span class="op">=</span> <span class="va">gasTest</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    2 comps 3 comps</span></span>
<span><span class="co">## 51   87.94   87.95</span></span>
<span><span class="co">## 52   87.25   87.30</span></span>
<span><span class="co">## 53   88.16   88.21</span></span>
<span><span class="co">## 54   84.97   84.87</span></span>
<span><span class="co">## 55   85.15   85.24</span></span></code></pre>
<p>Missing values in <code>newdata</code> are propagated to
<code>NA</code>s in the predicted response, by default. This can be
changed with the <code>na.action</code> argument. See
<code><a href="https://rdrr.io/r/stats/na.fail.html" class="external-link">?na.omit</a></code> for details. The <code>newdata</code> does not
have to be a data frame. Recognising the fact that the right hand side
of PLSR and PCR formulas very often are a single matrix term, the
<code>predict</code> method allows one to use a matrix as
<code>newdata</code>, so instead of</p>
<pre><code><span><span class="va">newdataframe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">newmatrix</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">...</span>, newdata <span class="op">=</span> <span class="va">newdataframe</span><span class="op">)</span></span></code></pre>
<p>one can simply say</p>
<pre><code><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">...</span>, newdata <span class="op">=</span> <span class="va">newmatrix</span><span class="op">)</span></span></code></pre>
<p>However, there are a couple of caveats: First, this <em>only</em>
works in <code>predict</code>. Other functions that take a
<code>newdata</code> argument (such as <code>RMSEP</code>) must have a
data frame (because they also need the response values). Second, when
<code>newdata</code> is a data frame, <code>predict</code> is able to
perform more tests on the supplied data, such as the dimensions and
types of variables. Third, with the exception of scaling (specified with
the <code>scale</code> argument when fitting the model), any
transformations or coding of factors and interactions have to be
performed manually if <code>newdata</code> is a matrix. It is often
interesting to predict scores from new observations, instead of response
values. This can be done by specifying the argument
<code>type = "scores"</code> in <code>predict</code>. One will then get
a matrix with the scores corresponding to the components specified in
<code>comps</code> (<code>ncomp</code> is accepted as a synonym for
<code>comps</code> when predicting scores). Predictions can be plotted
with the function <code>predplot</code>. This function is generic, and
can also be used for plotting predictions from other types of models,
such as <code>lm</code>. Typically, <code>predplot</code> is called like
this:</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/predplot.html">predplot</a></span><span class="op">(</span><span class="va">gas1</span>, ncomp <span class="op">=</span> <span class="fl">2</span>, newdata <span class="op">=</span> <span class="va">gasTest</span>, asp <span class="op">=</span> <span class="fl">1</span>, line <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="pls-manual_files/figure-html/fig-testPreds-1.png" class="r-plt" alt="Test set predictions" width="336"><p class="caption">
Test set predictions
</p>
</div>
<p>This plots predicted (with 2 components) versus measured response
values. (Note that <code>newdata</code> must be a data frame with both X
and Y variables.)</p>
</div>
<div class="section level2">
<h2 id="further-topics">9 Further topics<a class="anchor" aria-label="anchor" href="#further-topics"></a>
</h2>
<p>This section presents a couple of slightly technical topics for more
advanced use of the package.</p>
<div class="section level3">
<h3 id="selecting-fit-algorithms">9.1 Selecting fit algorithms<a class="anchor" aria-label="anchor" href="#selecting-fit-algorithms"></a>
</h3>
<p>There are several PLSR algorithms, and the <strong>pls</strong>
package currently implements three of them: the kernel algorithm for
tall matrices (many observations, few variables) <span class="citation">(Dayal and MacGregor 1997)</span>, the classic
orthogonal scores algorithm (A.K.A. NIPALS algorithm) <span class="citation">(Harald Martens and NÃ¦s 1989)</span> and the SIMPLS
algorithm <span class="citation">(Jong 1993)</span>. The kernel and
orthogonal scores algorithms produce the same results (the kernel
algorithm being the fastest of them for most problems). SIMPLS produces
the same fit for single-response models, but slightly different results
for multi-response models. It is also usually faster than the NIPALS
algorithm.</p>
<p>The factory default is to use the kernel algorithm. One can specify a
different algorithm with the <code>method</code> argument; i.e.,
<code>method = "oscorespls"</code>. If oneâ€™s personal taste of
algorithms does not coincide with the defaults in <strong>pls</strong>,
it can be quite tedious (and error prone) having to write
e.g.Â <code>method = "oscorespls"</code> every time (even though it can
be shortened to e.g.Â <code>me = "o"</code> due to partial matching).
Therefore, the defaults can be changed, with the function
<code>pls.options</code>. Called without arguments, it returns the
current settings as a named list:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pls.options.html">pls.options</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## $mvralg</span></span>
<span><span class="co">## [1] "kernelpls"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $plsralg</span></span>
<span><span class="co">## [1] "kernelpls"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $cpplsalg</span></span>
<span><span class="co">## [1] "cppls"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $pcralg</span></span>
<span><span class="co">## [1] "svdpc"</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $parallel</span></span>
<span><span class="co">## NULL</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $w.tol</span></span>
<span><span class="co">## [1] 2.22e-16</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $X.tol</span></span>
<span><span class="co">## [1] 1e-12</span></span></code></pre>
<p>The options specify the default fit algorithm of <code>mvr</code>,
<code>plsr</code>, and <code>pcr</code>. To return only a specific
option, one can use <code>pls.options("plsralg")</code>. To change the
default PLSR algorithm for the rest of the session, one can use,
e.g.:</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pls.options.html">pls.options</a></span><span class="op">(</span>plsralg <span class="op">=</span> <span class="st">"oscorespls"</span><span class="op">)</span></span></code></pre></div>
<p>Note that changes to the options only last until <strong>R</strong>
exits. (Earlier versions of <strong>pls</strong> stored the changes in
the global environment so they could be saved and restored, but current
CRAN policies do not allow this.)</p>
<div class="section level4">
<h4 id="additional-responses-and-focused-loadings">9.1.1 Additional responses and focused loadings<a class="anchor" aria-label="anchor" href="#additional-responses-and-focused-loadings"></a>
</h4>
<p>One of the alternative PLS algorithm is called Canonical (Powered)
Partial Least Squares and is available as <code>cppls</code> when
fitting. It uses canonical correlation for the loading calculations. For
single response regression models, this coincides with the standard
algorihms, while fore multiresponse and dummy-coded responses (or their
combination), this criterion is more aggressive, typically leading to
more parsimonious models and sometimes better prediction performance.
The use of canonical correlation also opens for additional responses
used when fitting, but not when predicting. These are enabled throught
the extra argument <code>Y.add</code>. Weighting of samples is also
possible using the <code>weights</code>argument. Finally, focused
loading weights can be enabled or forced throught the
<code>lower</code>and <code>upper</code>arguments (see the example in
<code><a href="../reference/mvr.html">?cppls</a></code> and <span class="citation">(Indahl, Liland, and NÃ¦s
2009)</span>)</p>
</div>
<div class="section level4">
<h4 id="missing-data-handling">9.1.2 Missing data handling<a class="anchor" aria-label="anchor" href="#missing-data-handling"></a>
</h4>
<p>When data are missing completely at random (MCAR), algorithms
<code>nipals</code>and <code>nipalspc</code> can be used in place of the
standard algorithms. These omit the missing values without dropping
observations or variables, calculating loading weights, scores and
loadings through an iterative process called NIPALS.</p>
</div>
</div>
<div class="section level3">
<h3 id="parallel-cross-validation">9.2 Parallel cross-validation<a class="anchor" aria-label="anchor" href="#parallel-cross-validation"></a>
</h3>
<p>Cross-validation is a computationally demanding procedure. A new
model has to be fitted for each segment. The underlying fit functions
have been optimised, and the implementation of cross-validation that is
used when specifying the <code>validation</code> argument to
<code>mvr</code> tries to avoid any unneeded calculations (and
house-keeping things like the formula handling, which can be
surprisingly expensive). Even so, cross-validation can take a long time,
for models with large matrices, many components or many segments. By
default, the cross-validation calculations in <strong>pls</strong> is
performed serially, on one CPU (core). (In the following, we will use
â€˜CPUâ€™ to denote both CPUs and cores.)</p>
<p>Since version 2.14.0, <strong>R</strong> has shipped with a package
<strong>parallel</strong> for running calculations in parallel, on
multi-CPU machines or on several machines. The <strong>pls</strong>
package can use the facilities of <strong>parallel</strong> to run the
cross-validations in parallel. The <strong>parallel</strong> package has
several ways of running calculations in parallel, and not all of them
are available on all systems. Therefore, the support in
<strong>pls</strong> is quite general, so one can select the ways that
work well on the given system. To specify how to run calculations in
parallel, one sets the option <code>parallel</code> in
<code>pls.options</code>. After setting the option, one simply runs
cross-validatons as before, and the calculations will be performed in
parallel. This works both when using the <code>crossval</code> function
and the <code>validation</code> argument to <code>mvr</code>. The
parallel specification has effect until it is changed.</p>
<p>The default value for <code>parallel</code> is <code>NULL</code>,
which specifies that the calculations are done serially, using one CPU.
Specifying the value 1 has the same effect.</p>
<p>Specifying an integer
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">&gt; 1</annotation></semantics></math>
makes the calculations use the function <code>mclapply</code> with the
given number as the number of CPUs to use. Note: <code>mclapply</code>
depends on â€˜forkingâ€™ which does not exist on MS Windows, so
<code>mclapply</code> cannot be used there. Example:</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pls.options.html">pls.options</a></span><span class="op">(</span>parallel <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="co"># Use mclapply with 4 CPUs</span></span>
<span><span class="va">gas1.cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">octane</span> <span class="op">~</span> <span class="va">NIR</span>, ncomp <span class="op">=</span> <span class="fl">10</span>, data <span class="op">=</span> <span class="va">gasTrain</span>, validation <span class="op">=</span> <span class="st">"LOO"</span><span class="op">)</span></span></code></pre></div>
<p>The <code>parallel</code> option can also be specified as a cluster
object created by the <code>makeCluster</code> function from the package
<strong>parallel</strong>. Any following cross-validation will then be
performed with the function <code>parLapply</code> on that cluster. Any
valid cluster specification can be used. The user should stop the
cluster with <code>stopCluster(pls.options()$parallel)</code> when it is
no longer needed.</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">parallel</span><span class="op">)</span> <span class="co"># Needed for the makeCluster call</span></span>
<span><span class="fu"><a href="../reference/pls.options.html">pls.options</a></span><span class="op">(</span>parallel <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">makeCluster</a></span><span class="op">(</span><span class="fl">4</span>, type <span class="op">=</span> <span class="st">"PSOCK"</span><span class="op">)</span><span class="op">)</span> <span class="co"># PSOCK cluster, 4 CPUs</span></span>
<span><span class="va">gas1.cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mvr.html">plsr</a></span><span class="op">(</span><span class="va">octane</span> <span class="op">~</span> <span class="va">NIR</span>, ncomp <span class="op">=</span> <span class="fl">10</span>, data <span class="op">=</span> <span class="va">gasTrain</span>, validation <span class="op">=</span> <span class="st">"LOO"</span><span class="op">)</span></span>
<span><span class="co">## later:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">stopCluster</a></span><span class="op">(</span><span class="fu"><a href="../reference/pls.options.html">pls.options</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">parallel</span><span class="op">)</span></span></code></pre></div>
<p>Several types of clusters are available: FORK uses forking, so
starting the cluster is very quick, however it is not available on MS
Windows. PSOCK starts <strong>R</strong> processes with the
<code>Rscript</code> command, which is slower, but is supported on MS
Windows. It can also start worker processes on different machines (see
<code><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">?makeCluster</a></code> for how). MPI uses MPI to start and
communicate with processes. This is the most flexible, but is often
slower to start up than the other types. It also dependens on the
packages <strong>snow</strong> and <strong>Rmpi</strong> to be installed
and working. It is especially useful when running batch jobs on a
computing cluster, because MPI can interact with the queue system on the
cluster to find out which machines to use when the job starts. Here is
an example of running a batch job on a cluster using MPI:</p>
<p>R script (myscript.R):</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a><span class="fu">library</span>(parallel) <span class="co"># for the makeCluster call</span></span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a><span class="fu">pls.options</span>(<span class="at">parallel =</span> <span class="fu">makeCluster</span>(<span class="dv">16</span>, <span class="at">type =</span> <span class="st">"MPI"</span>) <span class="co"># MPI cluster, 16 CPUs</span></span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a>gas1.cv <span class="ot">&lt;-</span> <span class="fu">plsr</span>(octane <span class="sc">~</span> NIR, <span class="at">ncomp =</span> <span class="dv">10</span>, <span class="at">data =</span> gasTrain, <span class="at">validation =</span> <span class="st">"LOO"</span>)</span>
<span id="cb51-4"><a href="#cb51-4" tabindex="-1"></a><span class="do">## later:</span></span>
<span id="cb51-5"><a href="#cb51-5" tabindex="-1"></a><span class="fu">save.image</span>(<span class="at">file =</span> <span class="st">"results.RData"</span>)</span>
<span id="cb51-6"><a href="#cb51-6" tabindex="-1"></a><span class="fu">stopCluster</span>(<span class="fu">pls.options</span>()<span class="sc">$</span>parallel)</span>
<span id="cb51-7"><a href="#cb51-7" tabindex="-1"></a><span class="fu">mpi.exit</span>() <span class="co"># stop Rmpi</span></span></code></pre></div>
<p>To run the job:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a><span class="ex">mpirun</span> <span class="at">-np</span> 1 R <span class="at">--slave</span> <span class="at">--file</span><span class="op">=</span>myscript.R</span></code></pre></div>
<p>The details of how to run <code>mpirun</code> varies between the
different MPI implementations and how they interact with the queue
system used (if any). The above should work for OpenMPI or Intel MPI
running under the Slurm queue system. In other situations, one might
have to specify which machines to use with, e.g., the <code>-host</code>
or <code>-machinefile</code> switch.</p>
</div>
<div class="section level3">
<h3 id="package-design">9.3 Package design<a class="anchor" aria-label="anchor" href="#package-design"></a>
</h3>
<p>The <strong>pls</strong> package is designed such that an interface
function <code>mvr</code> handles the formula and data, and calls an
underlying fit function (and possibly a cross-validation function) to do
the real work. There are several reasons for this design: it makes it
easier to implement new algorithms, one can easily skip the
time-consuming formula and data handling in computing-intensive
applications (simulations, etc.), and it makes it easier to use the
<strong>pls</strong> package as a building block in other packages. The
plotting facilities are implemented similarly: the <code>plot</code>
method simply calls the correct plot function based on the
<code>plottype</code> argument. Here, however, the separate plot
functions are meant to be callable interactively, because some people
like to use the generic <code>plot</code> function, while others like to
use separate functions for each plot type. There are also
<code>plot</code> methods for some of the components of fitted models
that can be extracted with extract functions, like score and loading
matrices. Thus there are several ways to get some plots, e.g.:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">mymod</span>, plottype <span class="op">=</span> <span class="st">"scores"</span>, <span class="va">...</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/scoreplot.html">scoreplot</a></span><span class="op">(</span><span class="va">mymod</span>, <span class="va">...</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="../reference/scores.html">scores</a></span><span class="op">(</span><span class="va">mymod</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<p>One example of a package that uses <strong>pls</strong> is
<strong>lspls</strong>, available on CRAN. In that package LS is
combined with PLS in a regression procedure. It calls the fit functions
of <strong>pls</strong> directly, and also uses the plot functions to
construct score and loading plots. There is also the
<strong>plsgenomics</strong> package, which includes a modified version
of (an earlier version of) the SIMPLS fit function
<code>simpls.fit</code>.</p>
</div>
<div class="section level3">
<h3 id="calling-fit-functions-directly">9.4 Calling fit functions directly<a class="anchor" aria-label="anchor" href="#calling-fit-functions-directly"></a>
</h3>
<p>The underlying fit functions are called <code>kernelpls.fit</code>,
<code>oscorespls.fit</code>, and <code>simpls.fit</code> for the PLSR
methods, and <code>svdpc.fit</code> for the PCR method. They all take
arguments <code>X</code>, <code>Y</code>, <code>ncomp</code>, and
<code>stripped</code>. Arguments <code>X</code>, <code>Y</code>, and
<code>ncomp</code> specify
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
(as matrices, not data frames), and the number of components to fit,
respectively. The argument <code>stripped</code> defaults to
<code>FALSE</code>. When it is <code>TRUE</code>, the calculations are
stripped down to the bare minimum required for returning the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>
means,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ˜</mi><annotation encoding="application/x-tex">\mathbf{Y}</annotation></semantics></math>
means, and the regression coefficients. This is used to speed up
cross-validation procedures.</p>
<p>The fit functions can be called directly, for instance when one wants
to avoid the overhead of formula and data handling in repeated fits. As
an example, this is how a simple leave-one-out cross-validation for a
uni-response-model could be implemented, using the SIMPLS:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">gasTrain</span><span class="op">$</span><span class="va">NIR</span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">gasTrain</span><span class="op">$</span><span class="va">octane</span></span>
<span><span class="va">ncomp</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span><span class="va">cvPreds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>nrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">ncomp</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simpls.fit.html">simpls.fit</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">i</span>,<span class="op">]</span>, <span class="va">Y</span><span class="op">[</span><span class="op">-</span><span class="va">i</span><span class="op">]</span>, ncomp <span class="op">=</span> <span class="va">ncomp</span>, stripped <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>    <span class="va">cvPreds</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> <span class="op">-</span> <span class="va">fit</span><span class="op">$</span><span class="va">Xmeans</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/drop.html" class="external-link">drop</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="va">fit</span><span class="op">$</span><span class="va">Ymeans</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The RMSEP of the cross-validated predictions are</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="op">(</span><span class="va">cvPreds</span> <span class="op">-</span> <span class="va">Y</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.3570 0.2966 0.2524 0.2476 0.2398</span></span></code></pre>
<p>which can be seen to be the same as the (unadjusted) CV results for
the <code>gas1</code> model in Section 3.</p>
</div>
<div class="section level3">
<h3 id="formula-handling-in-more-detail">9.5 Formula handling in more detail<a class="anchor" aria-label="anchor" href="#formula-handling-in-more-detail"></a>
</h3>
<p>The handling of formulas and variables in the model fitting is very
similar to what happens in the function <code>lm</code>: The variables
specified in the formula are looked up in the data frame given in the
<code>data</code> argument of the fit function (<code>plsr</code>,
<code>pcr</code> or <code>mvr</code>), or in the calling environment if
not found in the data frame. Factors are coded into one or more of
columns, depending on the number of levels, and on the contrasts option.
All (possibly coded) variables are then collected in a numerical model
matrix. This matrix is then handed to the underlying fit or
cross-validation functions. A similar handling is used in the
<code>predict</code> method. The intercept is treated specially in
<strong>pls</strong>. After the model matrix has been constructed, the
intercept column is removed. This ensures that any factors are coded as
if the intercept was present. The underlying fit functions then center
the rest of the variables as a part of the fitting process. (This is
intrinsic to the PLSR and PCR algorithms.) The intercept is handled
separately. A consequence of this is that explicitly specifying formulas
without the intercept (e.g., <code>y ~ a + b - 1</code>) will only
result in the coding of any factors to change ; the intercept will still
be fitted.</p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-R:Chambers+Hastie:1992" class="csl-entry">
Chambers, John M., and Trevor J. Hastie. 1992. <em>Statistical Models in
<span>S</span></em>. London: Chapman &amp; Hall.
</div>
<div id="ref-Cramer1988" class="csl-entry">
Cramer, R. D., D. E. Patterson, and J. D. Bunce. 1988.
<span>â€œComparative Molecular-Field Analysis (<span>ComFA</span>). 1.
<span>Effect</span> of Shape on Binding of Steroids to Carrier
Proteins.â€</span> <em>Journal of the American Chemical Society</em> 110
(18): 5959â€“67.
</div>
<div id="ref-DayMacGre:ImprPlsAlg" class="csl-entry">
Dayal, B. S., and J. F. MacGregor. 1997. <span>â€œImproved PLS
Algorithms.â€</span> <em>Journal of Chemometrics</em> 11 (1): 73â€“85.
</div>
<div id="ref-Fornell1982" class="csl-entry">
Fornell, C., and F. L. Bookstein. 1982. <span>â€œTwo Structural Equation
Models â€“ <span>LISREL</span> and <span>PLS</span> Applied to
Consumer-Exit Voice Theory.â€</span> <em>Journal of Marketing
Research</em> 19 (4): 440â€“52.
</div>
<div id="ref-Frank1993" class="csl-entry">
Frank, Ildiko E., and Jerome H. Friedman. 1993. <span>â€œA Statistical
View of Some Chemometrics Regression Tools (with Discussion).â€</span>
<em>Technometrics</em> 35 (2): 109â€“48.
</div>
<div id="ref-Geladi1985" class="csl-entry">
Geladi, P., D. MacDougall, and H. Martens. 1985. <span>â€œLinearization
and Scatter-Correction for <span>NIR</span> Reflectance Spectra of
Meat.â€</span> <em>Applied Spectroscopy</em> 39: 491â€“500.
</div>
<div id="ref-TESL2013" class="csl-entry">
Hastie, T., J. Friedman, and R. Tibshirani. 2013. <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.
Springer.
</div>
<div id="ref-TESL" class="csl-entry">
Hastie, T., R. Tibshirani, and J. H. Friedman, eds. 2001. <em>The
Elements of Statistical Learning</em>. New York: Springer.
</div>
<div id="ref-indahl2009canonical" class="csl-entry">
Indahl, Ulf G, Kristian Hovde Liland, and Tormod NÃ¦s. 2009.
<span>â€œCanonical Partial Least Squaresâ€”a Unified PLS Approach to
Classification and Regression Problems.â€</span> <em>Journal of
Chemometrics: A Journal of the Chemometrics Society</em> 23 (9):
495â€“504.
</div>
<div id="ref-indahl1999multivariate" class="csl-entry">
Indahl, Ulf G, Narinder S Sahni, Bente Kirkhus, and Tormod NÃ¦s. 1999.
<span>â€œMultivariate Strategies for Classification Based on
NIR-Spectraâ€”with Application to Mayonnaise.â€</span> <em>Chemometrics and
Intelligent Laboratory Systems</em> 49 (1): 19â€“31.
</div>
<div id="ref-Jong1993a" class="csl-entry">
Jong, Sijmen de. 1993. <span>â€œ<span>SIMPLS</span>: An Alternative
Approach to Partial Least Squares Regression.â€</span> <em>Chemometrics
and Intelligent Laboratory Systems</em> 18: 251â€“63.
</div>
<div id="ref-Kal:2DatNIR" class="csl-entry">
Kalivas, John H. 1997. <span>â€œTwo Data Sets of Near Infrared
Spectra.â€</span> <em>Chemometrics and Intelligent Laboratory
Systems</em> 37: 255â€“59.
</div>
<div id="ref-Kresta1991" class="csl-entry">
Kresta, J. V., J. F. MacGregor, and T. E. Marlin. 1991.
<span>â€œMultivariate Statistical Monitoring of Process Operating
Performance.â€</span> <em>The Canadian Journal of Chemical
Engineering</em> 69 (1): 35â€“47.
</div>
<div id="ref-LacMic:EstERRDA" class="csl-entry">
Lachenbruch, Peter A., and M. Ray Mickey. 1968. <span>â€œEstimation of
Error Rates in Discriminant Analysis.â€</span> <em>Technometrics</em> 10
(1): 1â€“11.
</div>
<div id="ref-Martens2001" class="csl-entry">
Martens, H. 2001. <span>â€œReliable and Relevant Modelling of Real World
Data: A Personal Account of the Development of <span>PLS</span>
Regression.â€</span> <em>Chemometrics and Intelligent Laboratory
Systems</em> 58 (2): 85â€“95.
</div>
<div id="ref-MarNaes:MultCal" class="csl-entry">
Martens, Harald, and Tormod NÃ¦s. 1989. <em>Multivariate
Calibration</em>. Chichester: Wiley.
</div>
<div id="ref-Mas_etal_HandChemQualB" class="csl-entry">
Massart, D. L., B. G. M. Vandeginste, L. M. C. Buydens, S. de Jong, P.
J. Lewi, and J. Smeyers-Verbeke. 1998. <em>Handbook of Chemometrics and
Qualimetrics: Part b</em>. Elsevier.
</div>
<div id="ref-McIntosh1996" class="csl-entry">
McIntosh, A. R., F. L. Bookstein, J. V. Haxby, and C. L. Grady. 1996.
<span>â€œSpatial Pattern Analysis of Functional Brain Images Using Partial
Least Squares.â€</span> <em>Neuroimage</em> 3 (3): 143â€“57.
</div>
<div id="ref-MevCed:MSEPest" class="csl-entry">
Mevik, BjÃ¸rn-Helge, and Henrik RenÃ© Cederkvist. 2004. <span>â€œMean
Squared Error of Prediction <span>(MSEP)</span> Estimates for Principal
Component Regression <span>(PCR)</span> and Partial Least Squares
Regression <span>(PLSR)</span>.â€</span> <em>Journal of Chemometrics</em>
18 (9): 422â€“29.
</div>
<div id="ref-MevWeh:plsJSS" class="csl-entry">
Mevik, BjÃ¸rn-Helge, and Ron Wehrens. 2007. <span>â€œThe <span class="nocase">pls</span> Package: Principal Component and Partial Least
Squares Regression in <span>R</span>.â€</span> <em>Journal of Statistical
Software</em> 18 (2): 1â€“24.
</div>
<div id="ref-Nguyen2002" class="csl-entry">
Nguyen, D. V., and D. M. Rocke. 2002. <span>â€œTumor Classification by
Partial Least Squares Using Microarray Gene Expression Data.â€</span>
<em>Bioinformatics</em> 18 (1): 39â€“50.
</div>
<div id="ref-SwiWeiWijBuy_StrConRobMulCalMod" class="csl-entry">
Swierenga, H., A. P. de Weijer, R. J. van Wijk, and L. M. C. Buydens.
1999. <span>â€œStrategy for Constructing Robust Multivariate Calibration
Models.â€</span> <em>Chemometrics and Intelligent Laboratory Systems</em>
49 (1): 1â€“17.
</div>
<div id="ref-Voet1994" class="csl-entry">
Voet, H. van der. 1994. <span>â€œComparing the Predictive Accuracy of
Models Using a Simple Randomization Test.â€</span> <em>Chemom. Intell.
Lab. Syst.</em> 25 (2): 313â€“23.
</div>
<div id="ref-Wold2001" class="csl-entry">
Wold, S. 2001. <span>â€œPersonal Memories of the Early <span>PLS</span>
Development.â€</span> <em>Chemometrics and Intelligent Laboratory
Systems</em> 58 (2): 83â€“84.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Kristian Hovde Liland, BjÃ¸rn-Helge Mevik, Ron Wehrens.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
