[{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"Introduction to the pls Package","text":"pls package implements Principal Component Regression (PCR) Partial Least Squares Regression (PLSR) R, freely available CRAN website, licensed Gnu General Public License (GPL). user interface modelled traditional formula interface, exemplified lm. done people used R learn yet another interface, also believe formula interface good way working interactively models. thus methods generic functions like predict, update coef. also specialised functions like scores, loadings RMSEP, flexible cross-validation system. Visual inspection assessment important chemometrics, pls package number plot functions plotting scores, loadings, predictions, coefficients RMSEP estimates. package implements PCR several algorithms PLSR. design modular, easy use underlying algorithms functions. hope package serve well interactive data analysis building block functions packages using PLSR PCR. describe package used data analysis, well can used part packages. Also included section formulas data frames, people used R modelling idioms.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"introduction","dir":"Articles","previous_headings":"","what":"1 Introduction","title":"Introduction to the pls Package","text":"vignette meant introduction pls package. based paper â€˜pls Package: Principal Component Partial Least Squares Regression Râ€™, published Journal Statistical Software (Mevik Wehrens 2007), extended reflect developments package. PLSR methodology shortly described Section 2. Section 3 presents example session, get overview package. Section 4 describe formulas data frames (used pls). Users familiar formulas data frames R can skip section first reading. Fitting models described Section 5, cross-validatory choice components discussed Section 6. Next, inspecting plotting models described (Section 7), followed section predicting future observations (Section 8). Finally, Section 9 covers advanced topics parallel computing, setting options, using underlying functions directly, implementation details.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"theory","dir":"Articles","previous_headings":"","what":"2 Theory","title":"Introduction to the pls Package","text":"Multivariate regression methods like Principal Component Regression (PCR) Partial Least Squares Regression (PLSR) enjoy large popularity wide range fields, including natural sciences. main reason designed confront situation many, possibly correlated, predictor variables, relatively samplesâ€”situation common, especially chemistry developments spectroscopy since seventies revolutionised chemical analysis. fact, origin PLSR lies chemistry (see, e.g., (Wold 2001; H. Martens 2001)). field near-infrared (NIR) spectroscopy, highly overlapping lines difficult interpret overtones, existed method obtain quantitative information spectra. Also fields benefited greatly multivariate regression methods like PLSR PCR. medicinal chemistry, example, one likes derive molecular properties molecular structure. Quantitative Structure-Activity Relations (QSAR, also Quantitative Structure-Property Relations, QSPR), particular, Comparative Molecular Field Analysis (ComFA) (Cramer, Patterson, Bunce 1988), use PLSR. applications range statistical process control (Kresta, MacGregor, Marlin 1991) tumour classification (Nguyen Rocke 2002) spatial analysis brain images (McIntosh et al. 1996) marketing (Fornell Bookstein 1982). usual multiple linear regression (MLR) context, least-squares solution ğ˜=ğ—ğ+Î•\\begin{equation} \\mathbf{Y} = \\mathbf{X}\\mathbf{B} + \\Epsilon \\end{equation} given ğ=(ğ—Tğ—)âˆ’1ğ—Tğ˜\\begin{equation} \\mathbf{B} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y} \\label{eq:lsq} \\end{equation} problem often ğ—Tğ—\\mathbf{X}^T \\mathbf{X} singular, either number variables (columns) ğ—\\mathbf{X} exceeds number objects (rows), collinearities. PCR PLSR circumvent decomposing ğ—\\mathbf{X} orthogonal scores ğ“\\mathbf{T} loadings ğ\\mathbf{P} ğ—=ğ“ğT\\begin{equation} \\mathbf{X} = \\mathbf{T} \\mathbf{P}^T \\end{equation} regressing ğ˜\\mathbf{Y} ğ—\\mathbf{X} first aa columns scores ğ“\\mathbf{T}. PCR, scores given left singular vectors ğ—\\mathbf{X}, multiplied corresponding singular values, loadings right singular vectors ğ—\\mathbf{X}. , however, takes account information ğ—\\mathbf{X}, therefore may suboptimal prediction purposes. PLSR aims incorporate information ğ—\\mathbf{X} ğ˜\\mathbf{Y} definition scores loadings. fact, one specific version PLSR, called SIMPLS (Jong 1993), can shown scores loadings chosen way describe much possible covariance ğ—\\mathbf{X} ğ˜\\mathbf{Y}, PCR concentrates variance ğ—\\mathbf{X}. PLSR algorithms give identical results SIMPLS case one ğ˜\\mathbf{Y} variable, deviate slightly multivariate ğ˜\\mathbf{Y} case ; differences likely important practice.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"algorithms","dir":"Articles","previous_headings":"2 Theory","what":"2.1 Algorithms","title":"Introduction to the pls Package","text":"PCR, approximate ğ—\\mathbf{X} matrix first aa Principal Components (PCs), usually obtained singular value decomposition (SVD): ğ—=ğ—Ìƒ()+Î•X=(ğ”()ğƒ())ğ•()T+Î•X=ğ“()ğ()T+Î•X\\begin{equation} \\mathbf{X} = \\tilde{\\mathbf{X}}_{()} + \\Epsilon_X     = (\\mathbf{U}_{()} \\mathbf{D}_{()} ) \\mathbf{V}^T_{()} + \\Epsilon_X     = \\mathbf{T}_{()} \\mathbf{P}_{()}^T + \\Epsilon_X \\end{equation} Next, regress ğ˜\\mathbf{Y} scores, leads regression coefficients ğ=ğ(ğ“Tğ“)âˆ’1ğ“Tğ˜=ğ•ğƒâˆ’1ğ”Tğ˜\\begin{equation} \\mathbf{B} = \\mathbf{P} (\\mathbf{T}^T \\mathbf{T})^{-1} \\mathbf{T}^T \\mathbf{Y}     = \\mathbf{V} \\mathbf{D}^{-1} \\mathbf{U}^T \\mathbf{Y} \\end{equation} subscripts aa dropped clarity. PLSR, components, called Latent Variables (LVs) context, obtained iteratively. One starts SVD crossproduct matrix ğ’=ğ—Tğ˜\\mathbf{S} = \\mathbf{X}^T \\mathbf{Y}, thereby including information variation ğ—\\mathbf{X} ğ˜\\mathbf{Y}, correlation . first left right singular vectors, ww qq, used weight vectors ğ—\\mathbf{X} ğ˜\\mathbf{Y}, respectively, obtain scores tt uu: t=ğ—w=ğ„w\\begin{equation} t = \\mathbf{X} w = \\mathbf{E} w \\end{equation} u=ğ˜q=ğ…q\\begin{equation} u = \\mathbf{Y} q = \\mathbf{F} q \\end{equation} ğ„\\mathbf{E} ğ…\\mathbf{F} initialised ğ—\\mathbf{X} ğ˜\\mathbf{Y}, respectively. X scores tt often normalised: t=t/tTt\\begin{equation} t =  t / \\sqrt{t^Tt} \\end{equation} Y scores uu actually necessary regression often saved interpretation purposes. Next, X Y loadings obtained regressing vector tt: p=ğ„Tt\\begin{equation} \\label{eq:plspt} p = \\mathbf{E}^T t \\end{equation}q=ğ…Tt\\begin{equation} \\label{eq:plsqt} q = \\mathbf{F}^T t \\end{equation} Finally, data matrices â€˜deflatedâ€™: information related latent variable, form outer products tpTt p^T tqTt q^T, subtracted (current) data matrices ğ„\\mathbf{E} ğ…\\mathbf{F}. ğ„n+1=ğ„nâˆ’tpT\\begin{equation} \\mathbf{E}_{n+1} = \\mathbf{E}_n - t p^T \\end{equation}ğ…n+1=ğ…nâˆ’tqT\\begin{equation} \\mathbf{F}_{n+1} = \\mathbf{F}_n - t q^T \\end{equation} estimation next component can start SVD crossproduct matrix ğ„n+1Tğ…n+1\\mathbf{E}_{n+1}^T\\mathbf{F}_{n+1}. every iteration, vectors ww, tt, pp qq saved columns matrices ğ–\\mathbf{W}, ğ“\\mathbf{T}, ğ\\mathbf{P} ğ\\mathbf{Q}, respectively. One complication columns matrix ğ–\\mathbf{W} can compared directly: derived successively deflated matrices ğ„\\mathbf{E} ğ…\\mathbf{F}. shown alternative way represent weights, way columns relate original ğ—\\mathbf{X} matrix, given ğ‘=ğ–(ğTğ–)âˆ’1\\begin{equation} \\mathbf{R} = \\mathbf{W} (\\mathbf{P}^T \\mathbf{W})^{-1} \\end{equation} Now, position PCR case: instead regressing ğ˜\\mathbf{Y} ğ—\\mathbf{X}, use scores ğ“\\mathbf{T} calculate regression coefficients, later convert back realm original variables pre-multiplying matrix ğ‘\\mathbf{R} (since ğ“=ğ—ğ‘\\mathbf{T} = \\mathbf{X} \\mathbf{R}): ğ=ğ‘(ğ“Tğ“)âˆ’1ğ“Tğ˜=ğ‘ğ“Tğ˜=ğ‘ğT\\begin{equation} \\mathbf{B} = \\mathbf{R} (\\mathbf{T}^T \\mathbf{T})^{-1} \\mathbf{T}^T \\mathbf{Y}     = \\mathbf{R} \\mathbf{T}^T \\mathbf{Y}     = \\mathbf{R} \\mathbf{Q}^T \\end{equation} , , first aa components used. many components optimal determined, usually cross-validation. Many alternative formulations can found literature. shown, instance, one ğ—\\mathbf{X} ğ˜\\mathbf{Y} needs deflated ; alternatively, one can directly deflate crossproduct matrix ğ’\\mathbf{S} (done SIMPLS, example). Moreover, many equivalent ways scaling. example , scores tt normalised, one can also choose introduce normalisation another point algorithm. Unfortunately, can make difficult directly compare scores loadings different PLSR implementations.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"on-the-use-of-plsr-and-pcr","dir":"Articles","previous_headings":"2 Theory","what":"2.2 On the use of PLSR and PCR","title":"Introduction to the pls Package","text":"theory, PLSR advantage PCR. One imagine situation minor component ğ—\\mathbf{X} highly correlated ğ˜\\mathbf{Y} ; selecting enough components lead bad predictions. PLSR, component automatically present first LV. practice, however, hardly difference use PLSR PCR ; situations, methods achieve similar prediction accuracies, although PLSR usually needs fewer latent variables PCR. Put way around: number latent variables, PLSR cover variation ğ˜\\mathbf{Y} PCR cover ğ—\\mathbf{X}. turn, behave similar ridge regression (Frank Friedman 1993). can also shown PCR PLSR behave shrinkage methods (Hastie, Tibshirani, Friedman 2001), although cases PLSR seems increase variance individual regression coefficients, one possible explanation PLSR always better PCR.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"example-session","dir":"Articles","previous_headings":"","what":"3 Example session","title":"Introduction to the pls Package","text":"section walk example session, get overview package. able use package, one first load : prints message telling package attached, package implements function loadings masks function name package stats. (output commands cases suppressed save space.) Four example data sets included pls: yarn: data set 28 near-infrared spectra (NIR) PET yarns, measured 268 wavelengths, predictors, density response (density) (Swierenga et al. 1999). data set also includes logical variable train can used split data training data set size 21 test data set size 7. See ?yarn details. oliveoil: data set 5 quality measurements (chemical) 6 panel sensory panel variables (sensory) made 16 olive oil samples (Massart et al. 1998). See ?oliveoil details. gasoline: data set consisting octane number (octane) NIR spectra (NIR) 60 gasoline samples (Kalivas 1997). NIR spectrum consists 401 diffuse reflectance measurements 900 1700 nm. See ?gasoline details. mayonnaise: data set consisting oil type (oil.type), experimental design (design), train-test split (train) NIR spectra (NIR) 162 mayonnaise samples (Indahl et al. 1999). NIR spectrum consists 351 measurements 1100 2500 nm. See ?mayonnaisefor details. used examples follow. use data sets, must first loaded: rest paper, assumed package data sets loaded . Also, examples run options(digits = 4). Gasoline NIR spectra section, PLSR gasoline data illustrate use pls. spectra shown Figure 1. first divide data set train test data sets: typical way fitting PLSR model fits model 10 components, includes leave-one-(LOO) cross-validated predictions (Lachenbruch Mickey 1968). can get overview fit validation results summary method: validation results Root Mean Squared Error Prediction (RMSEP). two cross-validation estimates: CV ordinary CV estimate, adjCV bias-corrected CV estimate (Mevik Cederkvist 2004). (LOO CV, virtually difference) . often simpler judge RMSEPs plotting : Cross-validated RMSEP curves gasoline data plots estimated RMSEPs functions number components (Figure 2). legendpos argument adds legend indicated position. Two components seem enough. gives RMSEP 0.297. mentioned introduction, main practical difference PCR PLSR PCR often needs components PLSR achieve prediction error. data set, PCR need three components achieve RMSEP. number components chosen, one can inspect different aspects fit plotting predictions, scores, loadings, etc. default plot prediction plot: Cross-validated predictions gasoline data shows cross-validated predictions two components versus measured values (Figure 3). chosen aspect ratio 1, draw target line. points follow target line quite nicely, indication curvature anomalies. plots can selected argument plottype: Score plot gasoline data gives pairwise plot score values three first components (Figure 4). Score plots often used look patterns, groups outliers data. (instance, plotting two first components model built yarn dataset clearly indicates experimental design data.) example, clear indication grouping outliers. numbers parentheses component labels relative amount X variance explained component. explained variances can extracted explicitly loading plot (Figure 5) much used interpretation purposes, instance look known spectral peaks profiles: Loading plot gasoline data labels = \"numbers\" argument makes plot function try interpret variable names numbers, use xx axis labels. Score loading plots also plotting functions, scoreplot loadingplot, options plotting scores loadings, respectively. instance, scoreplotand companion extractor scores argument RMSEP/MSEP/R2 called estimate, can used plot cross-validated scores test data scores, e.g., Calibrated cross-validated score plots gasoline data fitted model often used predict response values new observations. following predicts responses ten observations gasTest, using two components: know true response values samples, can calculate test set RMSEP: two components, get 0.244, quite close cross-validated estimate (0.297).","code":"library(pls) data(yarn) data(oliveoil) data(gasoline) data(mayonnaise) gasTrain <- gasoline[1:50,] gasTest <- gasoline[51:60,] gas1 <- plsr(octane ~ NIR, ncomp = 10, data = gasTrain, validation = \"LOO\") summary(gas1) ## Data:    X dimension: 50 401  ##  Y dimension: 50 1 ## Fit method: kernelpls ## Number of components considered: 10 ##  ## VALIDATION: RMSEP ## Cross-validated using 50 leave-one-out segments. ##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps ## CV           1.545    1.357   0.2966   0.2524   0.2476   0.2398   0.2319 ## adjCV        1.545    1.356   0.2947   0.2521   0.2478   0.2388   0.2313 ##        7 comps  8 comps  9 comps  10 comps ## CV      0.2386   0.2316   0.2449    0.2673 ## adjCV   0.2377   0.2308   0.2438    0.2657 ##  ## TRAINING: % variance explained ##         1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps ## X         78.17    85.58    93.41    96.06    96.94    97.89    98.38    98.85 ## octane    29.39    96.85    97.89    98.26    98.86    98.96    99.09    99.16 ##         9 comps  10 comps ## X         99.02     99.19 ## octane    99.28     99.39 plot(RMSEP(gas1), legendpos = \"topright\") plot(gas1, ncomp = 2, asp = 1, line = TRUE) plot(gas1, plottype = \"scores\", comps = 1:3) explvar(gas1) ##  Comp 1  Comp 2  Comp 3  Comp 4  Comp 5  Comp 6  Comp 7  Comp 8  Comp 9 Comp 10  ## 78.1708  7.4122  7.8242  2.6578  0.8768  0.9466  0.4922  0.4723  0.1688  0.1694 par(mar = c(4, 4, 0.3, 1) + 0.1) plot(gas1, \"loadings\", comps = 1:2, legendpos = \"topleft\",      labels = \"numbers\", xlab = \"nm\") abline(h = 0) par.old <- par(mfrow=c(1,2)) scoreplot(gas1) scoreplot(gas1, estimate=\"CV\") par(par.old) predict(gas1, ncomp = 2, newdata = gasTest) ## , , 2 comps ##  ##    octane ## 51  87.94 ## 52  87.25 ## 53  88.16 ## 54  84.97 ## 55  85.15 ## 56  84.51 ## 57  87.56 ## 58  86.85 ## 59  89.19 ## 60  87.09 RMSEP(gas1, newdata = gasTest) ## (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps   ##      1.5369       1.1696       0.2445       0.2341       0.3287       0.2780   ##     6 comps      7 comps      8 comps      9 comps     10 comps   ##      0.2703       0.3301       0.3571       0.4090       0.6116"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"formulas-and-data-frames","dir":"Articles","previous_headings":"","what":"4 Formulas and data frames","title":"Introduction to the pls Package","text":"pls package formula interface works like formula interface Râ€™s standard lm functions, ways. section gives short description formulas data frames apply pls. information formulas can found lm help file, Chapter 11 â€˜Introduction Râ€™, Chapter 2 â€˜White Bookâ€™ (Chambers Hastie 1992). good reads anyone wanting understand R works formulas, user strongly advised read .","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"formulas","dir":"Articles","previous_headings":"4 Formulas and data frames","what":"4.1 Formulas","title":"Introduction to the pls Package","text":"formula consists left hand side (lhs), tilde (~), right hand side (rhs). lhs consists single term, representing response(s). rhs consists one terms separated +, representing regressor(s). instance, formula ~ b + c + d, response, b, c, d regressors. intercept handled automatically, need specified formula. term represents matrix, numeric vector factor (factor used response). response term matrix, multi-response model fit. pls, right hand side quite often consists single term, representing matrix regressor: y ~ X. also possible specify transformations variables. instance, log(y) ~ msc(Z) specifies regression logarithm y onto Z Z transformed Multiplicative Scatter (Signal) Correction (MSC) (Geladi, MacDougall, Martens 1985), pre-treatment common infrared spectroscopy. transformations contain symbols interpreted formula handling, e.g., +, * ^, terms protected () function, like : y ~ x1 + (x2 + x3). specifies two regressors: x1, sum x2 x3.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"data-frames","dir":"Articles","previous_headings":"4 Formulas and data frames","what":"4.2 Data frames","title":"Introduction to the pls Package","text":"fit functions first look specified variables supplied data frame, advisable collect variables . makes easier know data used fitting, keep different variants data around, predict new data. create data frame, one can use data.frame function: v1, v2 v3 factors numeric vectors, mydata <- data.frame(y = v1, = v2, b = v3) result data frame variables named y, b. PLSR PCR often used matrix single predictor term (especially one working spectroscopic data). Also, multi-response models require matrix response term. Z matrix, protected â€˜protect functionâ€™ () calls data.frame: mydata <- data.frame(..., Z = (Z)). Otherwise, split separate variables column, variable called Z data frame, use Z formula. One can also add matrix existing data frame: also prevent Z split separate variables. Finally, one can use cbind combine vectors matrices matrices fly formula. useful response, e.g., cbind(y1, y2) ~ X. Variables data frame can accessed $ operator, e.g., mydata$y. However, pls functions access variables automatically, user never use $ formulas.","code":"> mydata <- data.frame(...) > mydata$Z <- Z"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"fitting-models","dir":"Articles","previous_headings":"","what":"5 Fitting models","title":"Introduction to the pls Package","text":"main functions fitting models pcr plsr. (simply wrappers function mvr, selecting appropriate fit algorithm) . use plsr examples section, everything done pcr (mvr). simplest form, function call fitting models plsr(formula, ncomp, data) (plsr can substituted pcr mvr). argument formula formula described , ncomp number components one wishes fit, data data frame containing variables use model. function returns fitted model (object class \"mvr\") can inspected (Section 7) used predicting new observations (Section 8). instance: response term formula matrix, multi-response model fit, e.g.,: (see, print method simply tells us type model , fit function called.) argument ncomp optional. missing, maximal possible number components used. Also data optional, missing, variables specified formula searched global environment (userâ€™s workspace). Usually, preferable keep variables data frames, can sometimes convenient global environment. variables reside data frame, e.g.Â yarn, tempted use formulas like yarn$density ~ yarn$NIR! Use density ~ NIR specify data frame data = yarn . facilities working interactively models. use part samples data set, instance first 20, one can use arguments subset = 1:20 data = yarn[1:20,]. Also, one wants try different alternatives model, one can use function update. instance refit model dens1 using observations marked TRUE yarn$train, change number components 10. arguments, formula, can also changed update. can save bit typing working interactively models (doesnâ€™t save computing time; model refitted time). general, reader referred â€˜White Bookâ€™ (Chambers Hastie 1992) â€˜Introduction Râ€™ information fitting working models R. Missing data can sometimes problem. PLSR PCR algorithms currently implemented pls handle missing values intrinsically, observations missing values must removed. can done na.action argument. na.action = na.omit (default), observation missing values removed model completely. na.action = na.exclude, removed fitting process, included NAs residuals fitted values. want explicit error missing values data, use na.action = na.fail. default na.action can set options(), e.g., options(na.action = quote(na.fail)). Standardisation pre-treatments predictor variables often called . pls, predictor variables always centered, part fit algorithm. Scaling can requested scale argument. scale TRUE, variable standardised dividing standard deviation, scale numeric vector, variable divided corresponding number. instance, fit model standardised chemical measurements: mentioned earlier, MSC (Geladi, MacDougall, Martens 1985) implemented pls function msc can used formulas: scatter corrects NIR prior fitting, arranges new spectra automatically scatter corrected (using reference spectrum fitting) predict: arguments can given fit call: validation selecting validation, ... sending arguments underlying functions, notably cross-validation function mvrCv. arguments, see ?mvr.","code":"dens1 <- plsr(density ~ NIR, ncomp = 5, data = yarn) dim(oliveoil$sensory) ## [1] 16  6 plsr(sensory ~ chemical, data = oliveoil) ## Partial least squares regression, fitted with the kernel algorithm. ## Call: ## pls::plsr(formula = sensory ~ chemical, data = oliveoil) trainind <- which(yarn$train == TRUE) dens2 <- update(dens1, subset = trainind) dens3 <- update(dens1, ncomp = 10) olive1 <- plsr(sensory ~ chemical, scale = TRUE, data = oliveoil) gas2 <- plsr(octane ~ msc(NIR), ncomp = 10, data = gasTrain) predict(gas2, ncomp = 3, newdata = gasTest)"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"choosing-the-number-of-components-with-cross-validation","dir":"Articles","previous_headings":"","what":"6 Choosing the number of components with cross-validation","title":"Introduction to the pls Package","text":"Cross-validation, commonly used determine optimal number components take account, controlled validation argument modelling functions (mvr, plsr pcr). default value \"none\". Supplying value \"CV\" \"LOO\" cause modelling procedure call mvrCv perform cross-validation; \"LOO\" provides leave-one-cross-validation, whereas \"CV\" divides data segments. Default use ten segments, randomly selected, also segments consecutive objects interleaved segments (sometimes also referred â€˜Venetian blindsâ€™) possible use argument segment.type. One can also specify segments explicitly argument segments; see ?mvrCv details. validation performed way, model contain element comprising information --bag predictions (form predicted values, well MSEP R2 values). reference, MSEP error using components calculated well. validation results can visualised using plottype = \"validation\" argument standard plotting function. example shown Figure 2 gasoline data; typically, one select number components cross-validation error show significant decrease. decision many components retain extent always subjective. However, especially building large numbers models (e.g., simulation studies), can crucial consistent strategy choose â€œoptimalâ€ number components. Two strategies implemented function selectNcomp. first based -called one-sigma heuristic (Hastie, Friedman, Tibshirani 2013) consists choosing model fewest components still less one standard error away overall best model. second strategy employs permutation approach, basically tests whether adding new component beneficial (Voet 1994). implemented backwards, taking global minimum crossvalidation curve starting point, assessing models fewer fewer components: long significant deterioration performance found (default Î±=0.01\\alpha = 0.01 level), algorithm continues remove components. Applying function quite straightforward: leads plots Figure 6 â€“ note graphical arguments can supplied customize plots. cases, global minimum crossvalidation curve indicated gray dotted lines, suggestion optimal number components vertical blue dashed line. left plot shows width one-sigma intervals suggestion based ; right plot indicates models assessed permutation approach large blue circles. two criteria always agree (case) usually quite close. two strategies suggesting optimal model dimensions: left plot shows one-sigma strategy, right plot permutation strategy. pre-treatment depends composition training set applied, cross-validation procedure described optimal, sense cross-validation errors biased downward. long purpose select optimal number components, bias may important, difficult avoid . modelling functions argument scale can used auto-scaling per segment. However, elaborate methods MSC need explicit handling per segment. , function crossval available. takes mvr object performs cross-validation done: applying pre-treatment segment. results can shown plot (looks similar Figure 2) summarised numbers.  Applying MSC case leads nearly identical cross-validation estimates prediction error. scaling depend division data segments (e.g., log-scaling), functions crossval mvrCv give results ; however, crossval much slower. Cross-validation can computationally demanding (especially using function crossval). Therefore, mvrCv crossval can perform calculations parallel multi-core machine several machines. described Section 9.2.","code":"ncomp.onesigma <- selectNcomp(gas2, method = \"onesigma\", plot = TRUE,                               ylim = c(.18, .6)) ncomp.permut <- selectNcomp(gas2, method = \"randomization\", plot = TRUE,                             ylim = c(.18, .6)) gas2.cv <- crossval(gas2, segments = 10) plot(MSEP(gas2.cv), legendpos=\"topright\") summary(gas2.cv, what = \"validation\") ## Data:    X dimension: 50 401  ##  Y dimension: 50 1 ## Fit method: kernelpls ## Number of components considered: 10 ##  ## VALIDATION: RMSEP ## Cross-validated using 10 random segments. ##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps ## CV           1.545    1.319   0.2754   0.2614   0.2630   0.2546   0.2636 ## adjCV        1.545    1.316   0.2745   0.2601   0.2582   0.2500   0.2571 ##        7 comps  8 comps  9 comps  10 comps ## CV      0.2671   0.2794   0.3098    0.3250 ## adjCV   0.2605   0.2713   0.2986    0.3119"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"inspecting-fitted-models","dir":"Articles","previous_headings":"","what":"7 Inspecting fitted models","title":"Introduction to the pls Package","text":"closer look fitted model may reveal interesting agreements disagreements known relations X Y. Several functions implemented pls plotting, extracting summarising model components.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"plotting","dir":"Articles","previous_headings":"7 Inspecting fitted models","what":"7.1 Plotting","title":"Introduction to the pls Package","text":"One can access plotting functions \"plottype\" argument plot method mvr objects. simply wrapper function calling actual plot functions; latter available user well. default plot prediction plot (predplot), showing predicted versus measured values. Test set predictions used test set supplied newdata argument. Otherwise, model built using cross-validation, cross-validated predictions used, otherwise predictions training set. can overridden argument. example type plot can seen Figure 3. optional argument can used indicate many components included prediction. assess many components optimal, validation plot (validationplot) can used one shown Figure 2; shows measure prediction performance (either RMSEP, MSEP, R2R^2) number components. Usually, one takes first local minimum rather absolute minimum curve, avoid -fitting. regression coefficients can visualised using plottype = \"coef\" plot method, directly function coefplot. allows simultaneous plotting regression vectors several different numbers components . regression vectors gasoline data set using MSC shown Figure 7 using command Regression coefficients gasoline data Note coefficients two components three components similar. third component contributes little predictions. RMSEPs (see Figure 2) predictions (see Section 8) two three components quite similar. Scores loadings can plotted using functions scoreplot (example shown Figure 4) loadingplot (Figure 5), respectively. One can indicate number components comps argument ; two components given, plotting scores give pairs plot, otherwise scatter plot. loadingplot, default use line plots. Finally, â€˜correlation loadingsâ€™ plot (function corrplot, plottype = \"correlation\" plot) shows correlations variable selected components (see Figure 8). plots scatter plots two sets scores concentric circles radii given radii. point corresponds X variable. squared distance point origin equals fraction variance variable explained components panel. default values radii correspond 50% 100% explained variance, respectively. Correlation loadings plot gasoline data plot functions accept ordinary plot parameters, col pch. model several responses one selects one model size, e.g.Â ncomp = 4:6, plot functions (notably prediction plots (see ), validation plots coefficient plots) plot window divided one plot shown combination response model size. number rows columns chosen automatically, can specified explicitly arguments nRows nCols. plots fit plot window, one asked press return see rest plots.","code":"plot(gas1, plottype = \"coef\", ncomp=1:3, legendpos = \"bottomleft\",      labels = \"numbers\", xlab = \"nm\")"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"extraction","dir":"Articles","previous_headings":"7 Inspecting fitted models","what":"7.2 Extraction","title":"Introduction to the pls Package","text":"Regression coefficients can extracted using generic function coef; function takes several arguments, indicating number components take account, whether intercept needed (default FALSE). Scores loadings can extracted using functions scores loadings X, Yscores Yloadings Y. also return percentage variance explained attributes. PLSR, weights can extracted using function loading.weights. applied PCR model, function returns NULL. Note commands like plot(scores(gas1)) perfectly correct, lead exactly plots using scoreplot. vcov function can used get covariance matrix pcr models, e.g., uncertainty plotting (see ?vcov.mvr).","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"summaries","dir":"Articles","previous_headings":"7 Inspecting fitted models","what":"7.3 Summaries","title":"Introduction to the pls Package","text":"print method object class \"mvr\" shows regression type used, perhaps indicating form validation employed, shows function call. summary method gives information: also shows amount variance explained model (choices aa, number latent variables). summary method additional argument () able focus training phase validation phase, respectively. Default print types information.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"predicting-new-observations","dir":"Articles","previous_headings":"","what":"8 Predicting new observations","title":"Introduction to the pls Package","text":"Fitted models often used predict future observations, pls implements predict method PLSR PCR models. common way calling function predict(mymod, ncomp = myncomp, newdata = mynewdata), mymod fitted model, myncomp specifies model size(s) use, mynewdata data frame new X observations. data frame can also contain response measurements new observations, can used compare predicted values measured ones, estimate overall prediction ability model. newdata missing, predict uses data used fit model, .e., returns fitted values. argument ncomp missing, predict returns predictions models 1 component, 2 components, â€¦\\ldots, AA components, AA number components used fitting model. Otherwise, model size(s) listed ncomp used. instance, get predictions model built Section 3, two three components, one use (predict five first test observations, save space.) predictions two three components quite similar. expected, given regression vectors (Figure 7) well estimated RMSEPs two model sizes similar. One can also specify explicitly components use predicting. done specifying components argument comps. (ncomp comps specified, comps takes precedence ncomp.) instance, get predictions model component 2, one can use results different predictions two components (.e., components one two) . (intercept always included predictions. can removed subtracting mymod$Ymeans predicted values.) predict method returns three-dimensional array, entry (,j,k)(,j,k) predicted value observation ii, response jj model size kk. Note singleton dimensions dropped, predicting five observations uni-response model ncomp = 3 gives 5Ã—1Ã—15 \\times 1 \\times 1 array, vector length five. make easier distinguish predictions models one response predictions one model size. (using comps argument, last dimension dropped, predictions always single model.) One can drop singleton dimensions explicitly using drop(predict(...)): Missing values newdata propagated NAs predicted response, default. can changed na.action argument. See ?na.omit details. newdata data frame. Recognising fact right hand side PLSR PCR formulas often single matrix term, predict method allows one use matrix newdata, instead one can simply say However, couple caveats: First, works predict. functions take newdata argument (RMSEP) must data frame (also need response values). Second, newdata data frame, predict able perform tests supplied data, dimensions types variables. Third, exception scaling (specified scale argument fitting model), transformations coding factors interactions performed manually newdata matrix. often interesting predict scores new observations, instead response values. can done specifying argument type = \"scores\" predict. One get matrix scores corresponding components specified comps (ncomp accepted synonym comps predicting scores). Predictions can plotted function predplot. function generic, can also used plotting predictions types models, lm. Typically, predplot called like : Test set predictions plots predicted (2 components) versus measured response values. (Note newdata must data frame X Y variables.)","code":"predict(gas1, ncomp = 2:3, newdata = gasTest[1:5,]) ## , , 2 comps ##  ##    octane ## 51  87.94 ## 52  87.25 ## 53  88.16 ## 54  84.97 ## 55  85.15 ##  ## , , 3 comps ##  ##    octane ## 51  87.95 ## 52  87.30 ## 53  88.21 ## 54  84.87 ## 55  85.24 predict(gas1, comps = 2, newdata = gasTest[1:5,]) ##    octane ## 51  87.53 ## 52  86.30 ## 53  87.35 ## 54  85.82 ## 55  85.32 drop(predict(gas1, ncomp = 2:3, newdata = gasTest[1:5,])) ##    2 comps 3 comps ## 51   87.94   87.95 ## 52   87.25   87.30 ## 53   88.16   88.21 ## 54   84.97   84.87 ## 55   85.15   85.24 newdataframe <- data.frame(X = newmatrix) predict(..., newdata = newdataframe) predict(..., newdata = newmatrix) predplot(gas1, ncomp = 2, newdata = gasTest, asp = 1, line = TRUE)"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"further-topics","dir":"Articles","previous_headings":"","what":"9 Further topics","title":"Introduction to the pls Package","text":"section presents couple slightly technical topics advanced use package.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"selecting-fit-algorithms","dir":"Articles","previous_headings":"9 Further topics","what":"9.1 Selecting fit algorithms","title":"Introduction to the pls Package","text":"several PLSR algorithms, pls package currently implements three : kernel algorithm tall matrices (many observations, variables) (Dayal MacGregor 1997), classic orthogonal scores algorithm (.K.. NIPALS algorithm) (Harald Martens NÃ¦s 1989) SIMPLS algorithm (Jong 1993). kernel orthogonal scores algorithms produce results (kernel algorithm fastest problems). SIMPLS produces fit single-response models, slightly different results multi-response models. also usually faster NIPALS algorithm. factory default use kernel algorithm. One can specify different algorithm method argument; .e., method = \"oscorespls\". oneâ€™s personal taste algorithms coincide defaults pls, can quite tedious (error prone) write e.g.Â method = \"oscorespls\" every time (even though can shortened e.g.Â = \"o\" due partial matching). Therefore, defaults can changed, function pls.options. Called without arguments, returns current settings named list: options specify default fit algorithm mvr, plsr, pcr. return specific option, one can use pls.options(\"plsralg\"). change default PLSR algorithm rest session, one can use, e.g.: Note changes options last R exits. (Earlier versions pls stored changes global environment saved restored, current CRAN policies allow .)","code":"pls.options() ## $mvralg ## [1] \"kernelpls\" ##  ## $plsralg ## [1] \"kernelpls\" ##  ## $cpplsalg ## [1] \"cppls\" ##  ## $pcralg ## [1] \"svdpc\" ##  ## $parallel ## NULL ##  ## $w.tol ## [1] 2.22e-16 ##  ## $X.tol ## [1] 1e-12 pls.options(plsralg = \"oscorespls\")"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"additional-responses-and-focused-loadings","dir":"Articles","previous_headings":"9 Further topics > 9.1 Selecting fit algorithms","what":"9.1.1 Additional responses and focused loadings","title":"Introduction to the pls Package","text":"One alternative PLS algorithm called Canonical (Powered) Partial Least Squares available cppls fitting. uses canonical correlation loading calculations. single response regression models, coincides standard algorihms, fore multiresponse dummy-coded responses (combination), criterion aggressive, typically leading parsimonious models sometimes better prediction performance. use canonical correlation also opens additional responses used fitting, predicting. enabled throught extra argument Y.add. Weighting samples also possible using weightsargument. Finally, focused loading weights can enabled forced throught lowerand upperarguments (see example ?cppls (Indahl, Liland, NÃ¦s 2009))","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"missing-data-handling","dir":"Articles","previous_headings":"9 Further topics > 9.1 Selecting fit algorithms","what":"9.1.2 Missing data handling","title":"Introduction to the pls Package","text":"data missing completely random (MCAR), algorithms nipalsand nipalspc can used place standard algorithms. omit missing values without dropping observations variables, calculating loading weights, scores loadings iterative process called NIPALS.","code":""},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"parallel-cross-validation","dir":"Articles","previous_headings":"9 Further topics","what":"9.2 Parallel cross-validation","title":"Introduction to the pls Package","text":"Cross-validation computationally demanding procedure. new model fitted segment. underlying fit functions optimised, implementation cross-validation used specifying validation argument mvr tries avoid unneeded calculations (house-keeping things like formula handling, can surprisingly expensive). Even , cross-validation can take long time, models large matrices, many components many segments. default, cross-validation calculations pls performed serially, one CPU (core). (following, use â€˜CPUâ€™ denote CPUs cores.) Since version 2.14.0, R shipped package parallel running calculations parallel, multi-CPU machines several machines. pls package can use facilities parallel run cross-validations parallel. parallel package several ways running calculations parallel, available systems. Therefore, support pls quite general, one can select ways work well given system. specify run calculations parallel, one sets option parallel pls.options. setting option, one simply runs cross-validatons , calculations performed parallel. works using crossval function validation argument mvr. parallel specification effect changed. default value parallel NULL, specifies calculations done serially, using one CPU. Specifying value 1 effect. Specifying integer >1> 1 makes calculations use function mclapply given number number CPUs use. Note: mclapply depends â€˜forkingâ€™ exist MS Windows, mclapply used . Example: parallel option can also specified cluster object created makeCluster function package parallel. following cross-validation performed function parLapply cluster. valid cluster specification can used. user stop cluster stopCluster(pls.options()$parallel) longer needed. Several types clusters available: FORK uses forking, starting cluster quick, however available MS Windows. PSOCK starts R processes Rscript command, slower, supported MS Windows. can also start worker processes different machines (see ?makeCluster ). MPI uses MPI start communicate processes. flexible, often slower start types. also dependens packages snow Rmpi installed working. especially useful running batch jobs computing cluster, MPI can interact queue system cluster find machines use job starts. example running batch job cluster using MPI: R script (myscript.R): run job: details run mpirun varies different MPI implementations interact queue system used (). work OpenMPI Intel MPI running Slurm queue system. situations, one might specify machines use , e.g., -host -machinefile switch.","code":"pls.options(parallel = 4) # Use mclapply with 4 CPUs gas1.cv <- plsr(octane ~ NIR, ncomp = 10, data = gasTrain, validation = \"LOO\") library(parallel) # Needed for the makeCluster call pls.options(parallel = makeCluster(4, type = \"PSOCK\")) # PSOCK cluster, 4 CPUs gas1.cv <- plsr(octane ~ NIR, ncomp = 10, data = gasTrain, validation = \"LOO\") ## later: stopCluster(pls.options()$parallel) library(parallel) # for the makeCluster call pls.options(parallel = makeCluster(16, type = \"MPI\") # MPI cluster, 16 CPUs gas1.cv <- plsr(octane ~ NIR, ncomp = 10, data = gasTrain, validation = \"LOO\") ## later: save.image(file = \"results.RData\") stopCluster(pls.options()$parallel) mpi.exit() # stop Rmpi mpirun -np 1 R --slave --file=myscript.R"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"package-design","dir":"Articles","previous_headings":"9 Further topics","what":"9.3 Package design","title":"Introduction to the pls Package","text":"pls package designed interface function mvr handles formula data, calls underlying fit function (possibly cross-validation function) real work. several reasons design: makes easier implement new algorithms, one can easily skip time-consuming formula data handling computing-intensive applications (simulations, etc.), makes easier use pls package building block packages. plotting facilities implemented similarly: plot method simply calls correct plot function based plottype argument. , however, separate plot functions meant callable interactively, people like use generic plot function, others like use separate functions plot type. also plot methods components fitted models can extracted extract functions, like score loading matrices. Thus several ways get plots, e.g.: One example package uses pls lspls, available CRAN. package LS combined PLS regression procedure. calls fit functions pls directly, also uses plot functions construct score loading plots. also plsgenomics package, includes modified version (earlier version ) SIMPLS fit function simpls.fit.","code":"plot(mymod, plottype = \"scores\", ...) scoreplot(mymod, ...) plot(scores(mymod), ...)"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"calling-fit-functions-directly","dir":"Articles","previous_headings":"9 Further topics","what":"9.4 Calling fit functions directly","title":"Introduction to the pls Package","text":"underlying fit functions called kernelpls.fit, oscorespls.fit, simpls.fit PLSR methods, svdpc.fit PCR method. take arguments X, Y, ncomp, stripped. Arguments X, Y, ncomp specify ğ—\\mathbf{X} ğ˜\\mathbf{Y} (matrices, data frames), number components fit, respectively. argument stripped defaults FALSE. TRUE, calculations stripped bare minimum required returning ğ—\\mathbf{X} means, ğ˜\\mathbf{Y} means, regression coefficients. used speed cross-validation procedures. fit functions can called directly, instance one wants avoid overhead formula data handling repeated fits. example, simple leave-one-cross-validation uni-response-model implemented, using SIMPLS: RMSEP cross-validated predictions can seen (unadjusted) CV results gas1 model Section 3.","code":"X <- gasTrain$NIR Y <- gasTrain$octane ncomp <- 5 cvPreds <- matrix(nrow = nrow(X), ncol = ncomp) for (i in 1:nrow(X)) {     fit <- simpls.fit(X[-i,], Y[-i], ncomp = ncomp, stripped = TRUE)     cvPreds[i,] <- (X[i,] - fit$Xmeans) %*% drop(fit$coefficients) +         fit$Ymeans } sqrt(colMeans((cvPreds - Y)^2)) ## [1] 1.3570 0.2966 0.2524 0.2476 0.2398"},{"path":"https://khliland.github.io/pls/articles/pls-manual.html","id":"formula-handling-in-more-detail","dir":"Articles","previous_headings":"9 Further topics","what":"9.5 Formula handling in more detail","title":"Introduction to the pls Package","text":"handling formulas variables model fitting similar happens function lm: variables specified formula looked data frame given data argument fit function (plsr, pcr mvr), calling environment found data frame. Factors coded one columns, depending number levels, contrasts option. (possibly coded) variables collected numerical model matrix. matrix handed underlying fit cross-validation functions. similar handling used predict method. intercept treated specially pls. model matrix constructed, intercept column removed. ensures factors coded intercept present. underlying fit functions center rest variables part fitting process. (intrinsic PLSR PCR algorithms.) intercept handled separately. consequence explicitly specifying formulas without intercept (e.g., y ~ + b - 1) result coding factors change ; intercept still fitted.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kristian Hovde Liland. Author, maintainer. BjÃ¸rn-Helge Mevik. Author. Ron Wehrens. Author. Paul Hiemstra. Contributor.","code":""},{"path":"https://khliland.github.io/pls/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Liland K, Mevik B, Wehrens R (2026). pls: Partial Least Squares Principal Component Regression. R package version 2.9-0, https://github.com/khliland/pls.","code":"@Manual{,   title = {pls: Partial Least Squares and Principal Component Regression},   author = {Kristian Hovde Liland and BjÃ¸rn-Helge Mevik and Ron Wehrens},   year = {2026},   note = {R package version 2.9-0},   url = {https://github.com/khliland/pls}, }"},{"path":"https://khliland.github.io/pls/index.html","id":"the-pls-r-package","dir":"","previous_headings":"","what":"Partial Least Squares and Principal Component Regression","title":"Partial Least Squares and Principal Component Regression","text":"source code repository CRAN package â€œplsâ€.","code":""},{"path":"https://khliland.github.io/pls/index.html","id":"installation-from-cran","dir":"","previous_headings":"","what":"Installation from CRAN","title":"Partial Least Squares and Principal Component Regression","text":"(Recommended, unless want test newest changes.)","code":"install.packages(\"pls\")"},{"path":"https://khliland.github.io/pls/index.html","id":"installation-from-github","dir":"","previous_headings":"","what":"Installation from github","title":"Partial Least Squares and Principal Component Regression","text":"(needed, install devtools package CRAN first.)","code":"library(devtools) install_github(\"khliland/pls\")"},{"path":"https://khliland.github.io/pls/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Partial Least Squares and Principal Component Regression","text":"See help pages package instructions, (installed CRAN): vignette(\"pls-manual\"). Documentation also avaiable GitHub page https://khliland.github.io/pls/.","code":""},{"path":"https://khliland.github.io/pls/index.html","id":"new-featuress","dir":"","previous_headings":"","what":"New featuress","title":"Partial Least Squares and Principal Component Regression","text":"2.9.0: Added nipals() (NIPALS PLS) nipalspcr() (NIPALS PCR) robustness missing data. Added cross-validation test set abilities scores() scoreplot(). Added pkgdown site documentation vignette. 2.8-4: Added fac2seg() create cross-validation segments factor. 2.8-1: Added vcov() computing variance-covariance matrices PCR.","code":""},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Biplots of PLSR and PCR Models. â€” biplot.mvr","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"Biplot method mvr objects.","code":""},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"","code":"# S3 method for class 'mvr' biplot(   x,   comps = 1:2,   which = c(\"x\", \"y\", \"scores\", \"loadings\"),   var.axes = FALSE,   xlabs,   ylabs,   main,   ... )"},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"x mvr object. comps integer vector length two.  components plot. character.  matrices plot.  One \"x\" (X scores loadings), \"y\" (Y scores loadings), \"scores\" (X Y scores) \"loadings\" (X Y loadings). var.axes logical.  TRUE, second set points arrows representing . xlabs either character vector labels first set points, FALSE labels.  missing, row names first matrix used labels. ylabs either character vector labels second set points, FALSE labels.  missing, row names second matrix used labels. main character.  Title plot.  missing, title constructed biplot.mvr. ... arguments passed biplot.default.","code":""},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"biplot.mvr can also called mvr plot method specifying plottype = \"biplot\".","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/biplot.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Biplots of PLSR and PCR Models. â€” biplot.mvr","text":"","code":"data(oliveoil) mod <- plsr(sensory ~ chemical, data = oliveoil) if (FALSE) { # \\dontrun{ ## These are equivalent biplot(mod) plot(mod, plottype = \"biplot\")  ## The four combinations of x and y points: par(mfrow = c(2,2)) biplot(mod, which = \"x\") # Default biplot(mod, which = \"y\") biplot(mod, which = \"scores\") biplot(mod, which = \"loadings\") } # }"},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"Functions extract information mvr objects: Regression coefficients, fitted values, residuals, model frame, model matrix, names variables components, \\(X\\) variance explained components.","code":""},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"","code":"# S3 method for class 'mvr' coef(object, ncomp = object$ncomp, comps, intercept = FALSE, ...)  # S3 method for class 'mvr' fitted(object, ...)  # S3 method for class 'mvr' residuals(object, ...)  # S3 method for class 'mvr' model.frame(formula, ...)  # S3 method for class 'mvr' model.matrix(object, ...)  respnames(object)  prednames(object, intercept = FALSE)  compnames(object, comps, explvar = FALSE, ...)  explvar(object)"},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"object, formula mvr object.  fitted model. ncomp, comps vector positive integers.  components include coefficients extract names .  See . intercept logical.  Whether coefficients intercept included.  Ignored comps specified.  Defaults FALSE. ... arguments sent underlying functions.  Currently used model.frame.mvr model.matrix.mvr. explvar logical.  Whether explained \\(X\\) variance appended component names.","code":""},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"coef.mvr returns array regression coefficients. fitted.mvr returns array fitted values. residuals.mvr returns array residuals. model.frame.mvr returns data frame. model.matrix.mvr returns \\(X\\) matrix. prednames, respnames compnames return character vector corresponding names. explvar returns numeric vector explained variances, NULL available.","code":""},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"functions mostly used inside functions.  (Functions coef.mvr, fitted.mvr residuals.mvr usually called generic functions coef, fitted residuals, respectively.) coef.mvr used extract regression coefficients model, .e. \\(B\\) \\(y = XB\\) (\\(Q\\) \\(y = TQ\\) \\(T\\) scores, see Yloadings).  array dimension c(nxvar, nyvar, length(ncomp)) c(nxvar, nyvar, length(comps)) returned. comps missing (NULL), coef()[,,ncomp[]] coefficients models ncomp[] components, \\(= 1, \\ldots, length(ncomp)\\).  Also, intercept = TRUE, first dimension \\(nxvar + 1\\), intercept coefficients first row. comps given, however, coef()[,,comps[]] coefficients model component comps[], .e. contribution component comps[] regression coefficients. fitted.mvr residuals.mvr return fitted values residuals, respectively.  model fitted na.action = na.exclude (setting default na.action \"na.exclude\" options), fitted values (residuals) corresponding excluded observations returned NA; otherwise, omitted. model.frame.mvr returns model frame; .e. data frame variables neccessary generate model matrix.  See model.frame details. model.matrix.mvr returns (possibly coded) matrix used \\(X\\) fitting.  See model.matrix details. prednames, respnames compnames extract names \\(X\\) variables, responses components, respectively.  intercept = TRUE prednames, name intercept variable (.e. \"(Intercept)\") returned well.  compnames can also extract component names score loading matrices.  explvar = TRUE compnames, explained variance component (available) appended component names.  optimal formatting explained variances components used, one specify desired components argument comps. explvar extracts amount \\(X\\) variance (per cent) explained component model.  can also handle score loading matrices returned scores loadings.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/coef.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Information From a Fitted PLSR or PCR Model â€” coef.mvr","text":"","code":"data(yarn) mod <- pcr(density ~ NIR, data = yarn[yarn$train,], ncomp = 5) B <- coef(mod, ncomp = 3, intercept = TRUE) ## A manual predict method: stopifnot(drop(B[1,,] + yarn$NIR[!yarn$train,] %*% B[-1,,]) ==           drop(predict(mod, ncomp = 3, newdata = yarn[!yarn$train,])))  ## Note the difference in formatting: mod2 <- pcr(density ~ NIR, data = yarn[yarn$train,]) compnames(mod2, explvar = TRUE)[1:3] #> [1] \"Comp 1 (5.2e+01 %)\" \"Comp 2 (4.7e+01 %)\" \"Comp 3 (7.3e-01 %)\" compnames(mod2, comps = 1:3, explvar = TRUE) #> [1] \"Comp 1 (52.05 %)\" \"Comp 2 (46.73 %)\" \"Comp 3 (0.73 %)\""},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"Function plot regression coefficients mvr object.","code":""},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"","code":"coefplot(   object,   ncomp = object$ncomp,   comps,   intercept = FALSE,   separate = FALSE,   se.whiskers = FALSE,   nCols,   nRows,   labels,   type = \"l\",   lty,   lwd = NULL,   pch,   cex = NULL,   col,   legendpos,   xlab = \"variable\",   ylab = \"regression coefficient\",   main,   pretty.xlabels = TRUE,   xlim,   ylim,   ask = nRows * nCols < nPlots && dev.interactive(),   ... )"},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"object mvr object.  fitted model. ncomp, comps vector positive integers.  components plot. See coef.mvr details. intercept logical.  Whether coefficients intercept plotted.  Ignored comps specified.  Defaults FALSE. See coef.mvr details. separate logical.  TRUE, coefficients different model sizes blotted separate plots. se.whiskers logical.  TRUE, whiskers plus/minus 1 estimated standard error added plot.  available model cross-validated jackknife = TRUE.  Also, current implementation, intercept must FALSE, separate must TRUE length(ncomp) > 1. nCols, nRows integer.  number coloumns rows plots laid .  specified, coefplot tries intelligent. labels optional.  Alternative \\(x\\) axis labels.  See Details. type character.  type plot make.  Defaults \"l\" (lines).  Alternative types include \"p\" (points) \"b\" ().  See plot complete list types. lty vector line types (recycled neccessary).  Line types can specified integers character strings (see par details). lwd vector positive numbers (recycled neccessary), giving width lines. pch plot character.  character string vector single characters integers (recycled neccessary).  See points alternatives. cex numeric vector character expansion sizes (recycled neccessary) plotted symbols. col character integer vector colors plotted lines symbols (recycled neccessary).  See par details. legendpos Legend position.  Optional.  Ignored separate TRUE.  present, legend drawn given position.  position can specified symbolically (e.g., legendpos = \"topright\").  requires >= 2.1.0.  Alternatively, position can specified explicitly (legendpos = t(c(x,y))) interactively (legendpos = locator()).  works well plots single-response models. xlab, ylab titles \\(x\\) \\(y\\) axes.  Typically character strings, can expressions (e.g., expression(R^2) lists.  See title details. main optional main title plot.  See Details. pretty.xlabels logical.  TRUE, coefplot tries plot \\(x\\) labels nicely.  See Details. xlim, ylim optional vector length two, \\(x\\) \\(y\\) limits plot. ask logical.  Whether ask user page plot. ... arguments sent underlying plot functions.","code":""},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"coefplot handles multiple responses making one plot response.  separate TRUE, separate plots made combination model size response.  plots laid rectangular fashion. legendpos given, legend drawn given position (unless separate TRUE). argument labels can vector labels one \"names\" \"numbers\".  labels used \\(x\\) axis labels.  labels \"names\" \"numbers\", variable names used labels, difference \"numbers\", variable names converted numbers, possible. Variable names forms \"number\" \"number text\" (space optional), handled. argument main can used specify main title plot. handled non-standard way.  (sub) plot, main used main title plot.  one (sub) plot, however, presence main produce corresponding â€˜globalâ€™ title page.  graphical parametres, e.g., cex.main, supplied coefplot affect â€˜ordinaryâ€™ plot titles, â€˜globalâ€™ one.  appearance can changed setting parameters par, affect titles.  (different settings two titles, one can override par settings arguments coefplot.) argument pretty.xlabels used labels specified.  TRUE (default), code tries use â€˜prettyâ€™ selection labels.  labels \"numbers\", also uses numerical values labels horisontal spacing.  one excluded parts spectral region, one might therefore want use pretty.xlabels = FALSE. separate TRUE, arguments lty, col, pch default par() setting.  Otherwise, default 1:nLines, nLines number model sizes specified, .e., length ncomp comps. function can also called mvr plot method specifying plottype = \"coefficients\".","code":""},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"legend many options.  want greater control appearance legend, omit legendpos argument call legend manually. handling labels pretty.xlabels experimental.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/coefplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Regression Coefficients of PLSR and PCR models â€” coefplot","text":"","code":"data(yarn) mod.nir <- plsr(density ~ NIR, ncomp = 8, data = yarn) if (FALSE) { # \\dontrun{ coefplot(mod.nir, ncomp = 1:6) plot(mod.nir, plottype = \"coefficients\", ncomp = 1:6) # Equivalent to the previous ## Plot with legend: coefplot(mod.nir, ncom = 1:6, legendpos = \"bottomright\") } # }  data(oliveoil) mod.sens <- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil) if (FALSE) coefplot(mod.sens, ncomp = 2:4, separate = TRUE) # \\dontrun{}"},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"CPPLS (Indahl et al.) â€” cppls.fit","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"Fits PLS model using CPPLS algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"","code":"cppls.fit(   X,   Y,   ncomp,   Y.add = NULL,   center = TRUE,   stripped = FALSE,   lower = 0.5,   upper = 0.5,   trunc.pow = FALSE,   weights = NULL,   ... )"},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. Y.add vector matrix additional responses containing relevant information observations. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. lower vector lower limits power optimisation. Defaults 0.5. upper vector upper limits power optimisation. Defaults 0.5. trunc.pow logical. TRUE experimental alternative power algorithm used. (Optional) weights vector individual weights observations. (Optional) ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. loading.weights matrix loading weights. Yscores matrix Y-scores. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar total variance X. gammas gamma-values obtained power optimisation. canonical.correlations Canonical correlation values calculations loading weights. matrix containing vectors weights canonical correlation (cor(Za,Yb)). smallNorms vector indices explanatory variables length close equal 0. stripped TRUE, components coefficients, Xmeans, Ymeans gammas returned.","code":""},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"function called directly, generic functions cppls mvr argument method=\"cppls\". Canonical Powered PLS (CPPLS) generalisation PLS incorporating discrete continuous responses (also simultaneously), additional responses, individual weighting observations power methodology sharpening focus groups variables. Depending input cppls can produce following special cases: PLS: uni-response continuous Y PPLS: uni-response continuous Y, (lower || upper) != 0.5 PLS-DA (using correlation maximisation - B/W): dummy-coded descrete response Y PPLS-DA: dummy-coded descrete response Y, (lower || upper) != 0.5 CPLS: multi-response Y (continuous, discrete combination) CPPLS: multi-response Y (continuous, discrete combination), (lower || upper) != 0.5 name \"canonical\" comes canonical correlation analysis used calculating vectors loading weights, \"powered\" refers reparameterisation vectors loading weights can optimised given interval.","code":""},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"Indahl, U. (2005) twist partial least squares regression. Journal Chemometrics, 19, 32â€“44. Liland, K.H Indahl, U.G (2009) Powered partial least squares discriminant analysis, Journal Chemometrics, 23, 7â€“18. Indahl, U.G., Liland, K.H. NÃ¦s, T. (2009) Canonical partial least squares - unified PLS approach classification regression problems. Journal Chemometrics, 23, 495â€“504.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"Kristian Hovde Liland","code":""},{"path":"https://khliland.github.io/pls/reference/cppls.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CPPLS (Indahl et al.) â€” cppls.fit","text":"","code":"data(mayonnaise) # Create dummy response mayonnaise$dummy <-     I(model.matrix(~y-1, data.frame(y = factor(mayonnaise$oil.type))))  # Predict CPLS scores for test data may.cpls <- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train) may.test <- predict(may.cpls, newdata = mayonnaise[!mayonnaise$train,], type = \"score\")  # Predict CPLS scores for test data (experimental used design as additional Y information) may.cpls.yadd <- cppls(dummy ~ NIR, 10, data = mayonnaise, subset = train, Y.add=design) may.test.yadd <- predict(may.cpls.yadd, newdata = mayonnaise[!mayonnaise$train,], type = \"score\")  # Classification by linear discriminant analysis (LDA) library(MASS) error <- matrix(ncol = 10, nrow = 2) dimnames(error) <- list(Model = c('CPLS', 'CPLS (Y.add)'), ncomp = 1:10) for (i in 1:10) {     fitdata1 <- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],                            NIR.score = I(may.cpls$scores[,1:i,drop=FALSE]))     testdata1 <- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],                             NIR.score = I(may.test[,1:i,drop=FALSE]))     error[1,i] <-         (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata1),                   newdata = testdata1)$class == testdata1$oil.type)) / 42     fitdata2 <- data.frame(oil.type = mayonnaise$oil.type[mayonnaise$train],                            NIR.score = I(may.cpls.yadd$scores[,1:i,drop=FALSE]))     testdata2 <- data.frame(oil.type = mayonnaise$oil.type[!mayonnaise$train],                             NIR.score = I(may.test.yadd[,1:i,drop=FALSE]))     error[2,i] <-         (42 - sum(predict(lda(oil.type ~ NIR.score, data = fitdata2),                   newdata = testdata2)$class == testdata2$oil.type)) / 42 } round(error,2) #>               ncomp #> Model             1    2    3    4    5    6    7    8 9 10 #>   CPLS         0.29 0.29 0.19 0.17 0.24 0.14 0.05 0.02 0  0 #>   CPLS (Y.add) 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0  0"},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of PLSR and PCR models â€” crossval","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"â€œstand aloneâ€ cross-validation function mvr objects.","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"","code":"crossval(   object,   segments = 10,   segment.type = c(\"random\", \"consecutive\", \"interleaved\"),   length.seg,   jackknife = FALSE,   trace = 15,   ... )"},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"object mvr object; regression cross-validate. segments number segments use, list segments (see ). segment.type type segments use.  Ignored segments list. length.seg Positive integer.  length segments use.  specified, overrides segments unless segments list. jackknife logical.  Whether jackknifing regression coefficients performed. trace TRUE, tracing turned .  numeric, denotes time limit (seconds).  estimated total time cross-validation exceeds limit, tracing turned . ... additional arguments, sent underlying fit function.","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"supplied object returned, additional component validation, list components method euqals \"CV\" cross-validation. pred array cross-validated predictions. coefficients (jackknife TRUE) array jackknifed regression coefficients.  dimensions correspond predictors, responses, number components, segments, respectively. PRESS0 vector PRESS values (one response variable) model zero components, .e., intercept. PRESS matrix PRESS values models 1, ..., ncomp components.  row corresponds one response variable. adj matrix adjustment values calculating bias corrected MSEP.  MSEP uses . segments list segments used cross-validation. ncomp number components. gammas method cppls used, gamma values powers CV segment returned.","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"function performs cross-validation model fit mvr.  can handle models plsr(y ~ msc(X), ...{}) models predictor variables need recalculated segment. recalculation needed, result crossval(mvr(...{})) identical mvr(...{}, validation = \"CV\"), slower. Note use crossval, data must specified data argument fitting object. segments list, arguments segment.type length.seg ignored.  elements list integer vectors specifying indices segments.  See cvsegments details. Otherwise, segments type segment.type generated.  many segments generate selected specifying number segments segments, giving segment length length.seg.  specified, segments ignored. jackknife TRUE, jackknifed regression coefficients returned, can used variance estimation (var.jack) hypothesis testing (jack.test). tracing turned , segment number printed segment. default, cross-validation performed serially.  However, can done parallel using functionality parallel package setting option parallel pls.options. See pls.options different ways specify parallelism.  See also Examples .","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"PRESS0 always cross-validated using leave-one-cross-validation.  usually makes little difference practice, fixed correctness. current implementation jackknife stores jackknife-replicates regression coefficients, can costly large matrices. might change future version.","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error Prediction (MSEP) Estimates Principal Component Regression (PCR) Partial Least Squares Regression (PLSR).  Journal Chemometrics, 18(9), 422â€“429.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/crossval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of PLSR and PCR models â€” crossval","text":"","code":"data(yarn) yarn.pcr <- pcr(density ~ msc(NIR), 6, data = yarn) yarn.cv <- crossval(yarn.pcr, segments = 10) if (FALSE) plot(MSEP(yarn.cv)) # \\dontrun{}  if (FALSE) { # \\dontrun{ ## Parallelised cross-validation, using transient cluster: pls.options(parallel = 4) # use mclapply (not available on Windows) pls.options(parallel = quote(parallel::makeCluster(4, type = \"PSOCK\"))) # parLapply ## A new cluster is created and stopped for each cross-validation: yarn.cv <- crossval(yarn.pcr) yarn.loocv <- crossval(yarn.pcr, length.seg = 1)  ## Parallelised cross-validation, using persistent cluster: library(parallel) ## This creates the cluster: pls.options(parallel = makeCluster(4, type = \"FORK\")) # not available on Windows pls.options(parallel = makeCluster(4, type = \"PSOCK\")) ## The cluster can be used several times: yarn.cv <- crossval(yarn.pcr) yarn.loocv <- crossval(yarn.pcr, length.seg = 1) ## The cluster should be stopped manually afterwards: stopCluster(pls.options()$parallel)  ## Parallelised cross-validation, using persistent MPI cluster: ## This requires the packages snow and Rmpi to be installed library(parallel) ## This creates the cluster: pls.options(parallel = makeCluster(4, type = \"MPI\")) ## The cluster can be used several times: yarn.cv <- crossval(yarn.pcr) yarn.loocv <- crossval(yarn.pcr, length.seg = 1) ## The cluster should be stopped manually afterwards: stopCluster(pls.options()$parallel) ## It is good practice to call mpi.exit() or mpi.quit() afterwards: mpi.exit() } # }"},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate segments for cross-validation â€” cvsegments","title":"Generate segments for cross-validation â€” cvsegments","text":"function generates list segments cross-validation.  can generate random, consecutive interleaved segments, supports keeping replicates segment.","code":""},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate segments for cross-validation â€” cvsegments","text":"","code":"cvsegments(   N,   k,   length.seg = ceiling(N/k),   nrep = 1,   type = c(\"random\", \"consecutive\", \"interleaved\"),   stratify = NULL )"},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate segments for cross-validation â€” cvsegments","text":"N Integer.  number rows data set. k Integer.  number segments return. length.seg Integer.  length segments.  given, overrides k. nrep Integer.  number (consecutive) rows replicates object.  Replicates always kept segment. type One \"random\", \"consecutive\" \"interleaved\".  type segments generate.  Default \"random\". stratify Either list indices integer vector indicating stratum sample (set replicates) belongs (see Details).","code":""},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate segments for cross-validation â€” cvsegments","text":"list vectors.  vector contains indices one segment.  attribute \"incomplete\" contains number incomplete segments, attribute \"type\" contains type segments.","code":""},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate segments for cross-validation â€” cvsegments","text":"length.seg specified, used calculate number segments generate.  Otherwise k must specified.  \\(k*length.seg \\ne N\\), \\(k*length.seg - N\\) last segments contain \\(length.seg - 1\\) indices. type \"random\", indices allocated segments random order.  \"consecutive\", first segment contain first \\(length.seg\\) indices, .  type \"interleaved\", first segment contain indices \\(1, length.seg+1, 2*lenght.seg+1, \\ldots, (k-1)*length.seg+1\\), . \\(nrep > \\), assumed nrep consecutive rows replicates (repeated measurements) object, care taken replicates never put different segments. Warning: k divide N, specified length.seg divide N, nrep divide length.seg, number segments /segment length adjusted needed. Warnings printed cases, one always inspect resulting segments make sure expected. Stratification samples enabled stratify argument.  useful sub-groups data set proportional representation cross-validation segments response categorical (classifiation). stratify combined nrep, stratify corresponds sets replicates (see example).","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate segments for cross-validation â€” cvsegments","text":"BjÃ¸rn-Helge Mevik, Ron Wehrens Kristian Hovde Liland","code":""},{"path":"https://khliland.github.io/pls/reference/cvsegments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate segments for cross-validation â€” cvsegments","text":"","code":"## Segments for 10-fold randomised cross-validation: cvsegments(100, 10) #> $V1 #>  [1] 52 19 14 18  1 13 92 73 10 38 #>  #> $V2 #>  [1] 99 96 84 80 47 46 28 37 21 63 #>  #> $V3 #>  [1]  4 34 20 30 66  2 67 98 48  8 #>  #> $V4 #>  [1] 97 17 24 85 25 79 54 11  9 88 #>  #> $V5 #>  [1]  23  49  72  90 100   7  15  76  45  36 #>  #> $V6 #>  [1] 33 41 82 27 35 32 69 16 40 39 #>  #> $V7 #>  [1] 53 74 61 78 93 44 31 81 57 83 #>  #> $V8 #>  [1] 86 59 64  5 60 55 62 42  3 77 #>  #> $V9 #>  [1] 58 29 43 51 56 91 94 26 50 70 #>  #> $V10 #>  [1] 87 75 95 71 22 89 12 65 68  6 #>  #> attr(,\"incomplete\") #> [1] 0 #> attr(,\"type\") #> [1] \"random\"  ## Segments with four objects, taken consecutive: (segs <- cvsegments(60, length.seg = 4, type = \"cons\")) #> $V1 #> [1] 1 2 3 4 #>  #> $V2 #> [1] 5 6 7 8 #>  #> $V3 #> [1]  9 10 11 12 #>  #> $V4 #> [1] 13 14 15 16 #>  #> $V5 #> [1] 17 18 19 20 #>  #> $V6 #> [1] 21 22 23 24 #>  #> $V7 #> [1] 25 26 27 28 #>  #> $V8 #> [1] 29 30 31 32 #>  #> $V9 #> [1] 33 34 35 36 #>  #> $V10 #> [1] 37 38 39 40 #>  #> $V11 #> [1] 41 42 43 44 #>  #> $V12 #> [1] 45 46 47 48 #>  #> $V13 #> [1] 49 50 51 52 #>  #> $V14 #> [1] 53 54 55 56 #>  #> $V15 #> [1] 57 58 59 60 #>  #> attr(,\"incomplete\") #> [1] 0 #> attr(,\"type\") #> [1] \"consecutive\" data(gasoline) plsr(octane ~ NIR, data=gasoline, ncomp=5, validation=\"CV\", segments=segs) #> Partial least squares regression, fitted with the kernel algorithm. #> Cross-validated using 15 consecutive segments. #> Call: #> pls::plsr(formula = octane ~ NIR, ncomp = 5, data = gasoline,     validation = \"CV\", segments = segs)  ## Incomplete segments segs <- cvsegments(50, length.seg = 3) #> Warning: Required segment length does not divide the number of observations. #>   A best effort segment size will be used. attr(segs, \"incomplete\") #> [1] 1  ## Leave-one-out cross-validation: cvsegments(100, 100) #> $V1 #> [1] 97 #>  #> $V2 #> [1] 31 #>  #> $V3 #> [1] 7 #>  #> $V4 #> [1] 72 #>  #> $V5 #> [1] 92 #>  #> $V6 #> [1] 83 #>  #> $V7 #> [1] 63 #>  #> $V8 #> [1] 90 #>  #> $V9 #> [1] 10 #>  #> $V10 #> [1] 75 #>  #> $V11 #> [1] 24 #>  #> $V12 #> [1] 68 #>  #> $V13 #> [1] 1 #>  #> $V14 #> [1] 89 #>  #> $V15 #> [1] 15 #>  #> $V16 #> [1] 35 #>  #> $V17 #> [1] 46 #>  #> $V18 #> [1] 56 #>  #> $V19 #> [1] 2 #>  #> $V20 #> [1] 78 #>  #> $V21 #> [1] 55 #>  #> $V22 #> [1] 70 #>  #> $V23 #> [1] 84 #>  #> $V24 #> [1] 11 #>  #> $V25 #> [1] 94 #>  #> $V26 #> [1] 98 #>  #> $V27 #> [1] 42 #>  #> $V28 #> [1] 64 #>  #> $V29 #> [1] 51 #>  #> $V30 #> [1] 54 #>  #> $V31 #> [1] 82 #>  #> $V32 #> [1] 74 #>  #> $V33 #> [1] 76 #>  #> $V34 #> [1] 60 #>  #> $V35 #> [1] 38 #>  #> $V36 #> [1] 30 #>  #> $V37 #> [1] 95 #>  #> $V38 #> [1] 28 #>  #> $V39 #> [1] 85 #>  #> $V40 #> [1] 9 #>  #> $V41 #> [1] 17 #>  #> $V42 #> [1] 88 #>  #> $V43 #> [1] 66 #>  #> $V44 #> [1] 25 #>  #> $V45 #> [1] 29 #>  #> $V46 #> [1] 13 #>  #> $V47 #> [1] 61 #>  #> $V48 #> [1] 49 #>  #> $V49 #> [1] 81 #>  #> $V50 #> [1] 58 #>  #> $V51 #> [1] 69 #>  #> $V52 #> [1] 100 #>  #> $V53 #> [1] 71 #>  #> $V54 #> [1] 77 #>  #> $V55 #> [1] 26 #>  #> $V56 #> [1] 4 #>  #> $V57 #> [1] 93 #>  #> $V58 #> [1] 12 #>  #> $V59 #> [1] 23 #>  #> $V60 #> [1] 91 #>  #> $V61 #> [1] 47 #>  #> $V62 #> [1] 5 #>  #> $V63 #> [1] 50 #>  #> $V64 #> [1] 39 #>  #> $V65 #> [1] 40 #>  #> $V66 #> [1] 33 #>  #> $V67 #> [1] 37 #>  #> $V68 #> [1] 62 #>  #> $V69 #> [1] 8 #>  #> $V70 #> [1] 19 #>  #> $V71 #> [1] 67 #>  #> $V72 #> [1] 52 #>  #> $V73 #> [1] 18 #>  #> $V74 #> [1] 45 #>  #> $V75 #> [1] 73 #>  #> $V76 #> [1] 32 #>  #> $V77 #> [1] 16 #>  #> $V78 #> [1] 41 #>  #> $V79 #> [1] 27 #>  #> $V80 #> [1] 21 #>  #> $V81 #> [1] 87 #>  #> $V82 #> [1] 57 #>  #> $V83 #> [1] 59 #>  #> $V84 #> [1] 44 #>  #> $V85 #> [1] 79 #>  #> $V86 #> [1] 22 #>  #> $V87 #> [1] 20 #>  #> $V88 #> [1] 36 #>  #> $V89 #> [1] 6 #>  #> $V90 #> [1] 80 #>  #> $V91 #> [1] 43 #>  #> $V92 #> [1] 65 #>  #> $V93 #> [1] 96 #>  #> $V94 #> [1] 34 #>  #> $V95 #> [1] 99 #>  #> $V96 #> [1] 3 #>  #> $V97 #> [1] 14 #>  #> $V98 #> [1] 53 #>  #> $V99 #> [1] 48 #>  #> $V100 #> [1] 86 #>  #> attr(,\"incomplete\") #> [1] 0 #> attr(,\"type\") #> [1] \"leave-one-out\" ## Leave-one-out with variable/unknown data set size n: n <- 50 cvsegments(n, length.seg = 1) #> $V1 #> [1] 28 #>  #> $V2 #> [1] 15 #>  #> $V3 #> [1] 44 #>  #> $V4 #> [1] 46 #>  #> $V5 #> [1] 33 #>  #> $V6 #> [1] 42 #>  #> $V7 #> [1] 35 #>  #> $V8 #> [1] 13 #>  #> $V9 #> [1] 3 #>  #> $V10 #> [1] 49 #>  #> $V11 #> [1] 37 #>  #> $V12 #> [1] 25 #>  #> $V13 #> [1] 26 #>  #> $V14 #> [1] 10 #>  #> $V15 #> [1] 21 #>  #> $V16 #> [1] 29 #>  #> $V17 #> [1] 1 #>  #> $V18 #> [1] 40 #>  #> $V19 #> [1] 39 #>  #> $V20 #> [1] 14 #>  #> $V21 #> [1] 4 #>  #> $V22 #> [1] 38 #>  #> $V23 #> [1] 9 #>  #> $V24 #> [1] 5 #>  #> $V25 #> [1] 50 #>  #> $V26 #> [1] 22 #>  #> $V27 #> [1] 8 #>  #> $V28 #> [1] 11 #>  #> $V29 #> [1] 16 #>  #> $V30 #> [1] 34 #>  #> $V31 #> [1] 18 #>  #> $V32 #> [1] 36 #>  #> $V33 #> [1] 48 #>  #> $V34 #> [1] 31 #>  #> $V35 #> [1] 20 #>  #> $V36 #> [1] 45 #>  #> $V37 #> [1] 47 #>  #> $V38 #> [1] 41 #>  #> $V39 #> [1] 6 #>  #> $V40 #> [1] 19 #>  #> $V41 #> [1] 30 #>  #> $V42 #> [1] 2 #>  #> $V43 #> [1] 27 #>  #> $V44 #> [1] 24 #>  #> $V45 #> [1] 23 #>  #> $V46 #> [1] 7 #>  #> $V47 #> [1] 32 #>  #> $V48 #> [1] 12 #>  #> $V49 #> [1] 43 #>  #> $V50 #> [1] 17 #>  #> attr(,\"incomplete\") #> [1] 0 #> attr(,\"type\") #> [1] \"leave-one-out\"  ## Data set with replicates cvsegments(100, 25, nrep = 2) #> $V1 #> [1] 29 30 53 54 #>  #> $V2 #> [1] 97 98 21 22 #>  #> $V3 #> [1] 45 46 63 64 #>  #> $V4 #> [1]  5  6 41 42 #>  #> $V5 #> [1]  79  80  99 100 #>  #> $V6 #> [1] 23 24 33 34 #>  #> $V7 #> [1] 37 38 83 84 #>  #> $V8 #> [1] 89 90  3  4 #>  #> $V9 #> [1] 43 44 39 40 #>  #> $V10 #> [1] 11 12 93 94 #>  #> $V11 #> [1] 91 92 55 56 #>  #> $V12 #> [1] 27 28 17 18 #>  #> $V13 #> [1] 87 88 51 52 #>  #> $V14 #> [1] 61 62 75 76 #>  #> $V15 #> [1]  7  8 73 74 #>  #> $V16 #> [1] 47 48  9 10 #>  #> $V17 #> [1] 13 14 31 32 #>  #> $V18 #> [1] 85 86 25 26 #>  #> $V19 #> [1] 65 66 77 78 #>  #> $V20 #> [1] 15 16  1  2 #>  #> $V21 #> [1] 71 72 19 20 #>  #> $V22 #> [1] 57 58 59 60 #>  #> $V23 #> [1] 49 50 95 96 #>  #> $V24 #> [1] 81 82 67 68 #>  #> $V25 #> [1] 35 36 69 70 #>  #> attr(,\"incomplete\") #> [1] 0 #> attr(,\"type\") #> [1] \"random\" ## Note that rows 1 and 2 are in the same segment, rows 3 and 4 in the ## same segment, and so on.  ## Stratification cvsegments(10, 3, type = \"consecutive\", stratify = c(rep(1,7), rep(2,3))) #> $V1 #> [1] 1 2 3 8 #>  #> $V2 #> [1] 4 5 9 #>  #> $V3 #> [1]  6  7 10 #>  #> attr(,\"incomplete\") #> [1] 2 #> attr(,\"type\") #> [1] \"consecutive\" ## Note that the last three samples are spread across the segments ## according to the stratification vector. cvsegments(20, 3, type = \"consecutive\", nrep = 2, stratify = c(rep(1,7), rep(2,3))) #> Warning: Segment length is not a multiple of the number of replicates. #>   A best effort segment size will be used. #> $V1 #> [1]  1  2  3  4  5  6 15 16 #>  #> $V2 #> [1]  7  8  9 10 17 18 #>  #> $V3 #> [1] 11 12 13 14 19 20 #>  #> attr(,\"incomplete\") #> [1] 2 #> attr(,\"type\") #> [1] \"consecutive\" ## Note the length of stratify matching number of replicate sets, not samples.  ## Converting a factor to segments fac <- factor(c(\"a\", \"b\", \"a\", \"b\", \"c\", \"c\")) fac2seg(fac) #> [[1]] #> [1] 1 3 #>  #> [[2]] #> [1] 2 4 #>  #> [[3]] #> [1] 5 6 #>  ## Starting from a numeric vector num <- c(1, 2, 1, 2, 3, 3) fac2seg(factor(num)) #> [[1]] #> [1] 1 3 #>  #> [[2]] #> [1] 2 4 #>  #> [[3]] #> [1] 5 6 #>"},{"path":"https://khliland.github.io/pls/reference/delete.intercept.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete intercept from model matrix â€” delete.intercept","title":"Delete intercept from model matrix â€” delete.intercept","text":"utility function delete intercept column model matrix, adjust \"assign\" attribute correspondingly.  used formula handling functions like mvr model.matrix.mvr.","code":""},{"path":"https://khliland.github.io/pls/reference/delete.intercept.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete intercept from model matrix â€” delete.intercept","text":"","code":"delete.intercept(mm)"},{"path":"https://khliland.github.io/pls/reference/delete.intercept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete intercept from model matrix â€” delete.intercept","text":"mm Model matrix.","code":""},{"path":"https://khliland.github.io/pls/reference/delete.intercept.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete intercept from model matrix â€” delete.intercept","text":"model matrix without intercept column.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/delete.intercept.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Delete intercept from model matrix â€” delete.intercept","text":"BjÃ¸rn-Helge Mevik Ron Wehrens","code":""},{"path":"https://khliland.github.io/pls/reference/fac2seg.html","id":null,"dir":"Reference","previous_headings":"","what":"Factor to Segments â€” fac2seg","title":"Factor to Segments â€” fac2seg","text":"Factor Segments","code":""},{"path":"https://khliland.github.io/pls/reference/fac2seg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Factor to Segments â€” fac2seg","text":"","code":"fac2seg(fac)"},{"path":"https://khliland.github.io/pls/reference/fac2seg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Factor to Segments â€” fac2seg","text":"fac factor level represents segment","code":""},{"path":"https://khliland.github.io/pls/reference/fac2seg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Factor to Segments â€” fac2seg","text":"list vectors, vector contains indices elements corresponding segment","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/fac2seg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Factor to Segments â€” fac2seg","text":"","code":"fac <- factor(c(\"a\", \"b\", \"a\", \"b\", \"c\", \"c\")) fac2seg(fac) #> [[1]] #> [1] 1 3 #>  #> [[2]] #> [1] 2 4 #>  #> [[3]] #> [1] 5 6 #>"},{"path":"https://khliland.github.io/pls/reference/gasoline.html","id":null,"dir":"Reference","previous_headings":"","what":"Octane numbers and NIR spectra of gasoline â€” gasoline","title":"Octane numbers and NIR spectra of gasoline â€” gasoline","text":"data set NIR spectra octane numbers 60 gasoline samples.  NIR spectra measured using diffuse reflectance log(1/R) 900 nm 1700 nm 2 nm intervals, giving 401 wavelengths.  Many thanks John H. Kalivas.","code":""},{"path":"https://khliland.github.io/pls/reference/gasoline.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Octane numbers and NIR spectra of gasoline â€” gasoline","text":"data frame 60 observations following 2 variables. octane numeric vector.  octane number. NIR matrix 401 columns.  NIR spectrum.","code":""},{"path":"https://khliland.github.io/pls/reference/gasoline.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Octane numbers and NIR spectra of gasoline â€” gasoline","text":"Kalivas, John H. (1997) Two Data Sets Near Infrared Spectra Chemometrics Intelligent Laboratory Systems, 37, 255â€“259.","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Jackknife approximate t tests of regression coefficients â€” jack.test","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"Performes approximate t tests regression coefficients based jackknife variance estimates.","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"","code":"jack.test(object, ncomp = object$ncomp, use.mean = TRUE)  # S3 method for class 'jacktest' print(x, P.values = TRUE, ...)"},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"object mvr object.  cross-validated model fitted jackknife = TRUE. ncomp number components use estimating variances use.mean logical.  TRUE (default), mean coefficients used estimating (co)variances; otherwise coefficients model fitted entire data set.  See var.jack details. x jacktest object, result jack.test. P.values logical.  Whether print \\(p\\) values (default). ... arguments sent underlying print function printCoefmat.","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"jack.test returns object class \"jacktest\", components coefficients estimated regression coefficients sd square root jackknife variance estimates tvalues \\(t\\) statistics df `degrees freedom' used calculating \\(p\\) values pvalues calculated \\(p\\) values print.jacktest returns \"jacktest\" object (invisibly).","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"jack.test uses variance estimates var.jack perform \\(t\\) tests regression coefficients.  resulting object print method, print.jacktest, uses printCoefmat actual printing.","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"jackknife variance estimates known biased (see var.jack).  Also, distribution regression coefficient estimates jackknife variance estimates unknown (least PLSR/PCR).  Consequently, distribution (particular, degrees freedom) resulting \\(t\\) statistics unknown.  present code simply assumes \\(t\\) distribution \\(m - 1\\) degrees freedom, \\(m\\) number cross-validation segments. Therefore, resulting \\(p\\) values used uncritically, perhaps regarded mere indicator (non-)significance. Finally, also keep mind number predictor variables increase, problem multiple tests increases correspondingly.","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"Martens H. Martens M. (2000) Modified Jack-knife Estimation Parameter Uncertainty Bilinear Modelling Partial Least Squares Regression (PLSR).  Food Quality Preference, 11, 5â€“16.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/jack.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jackknife approximate t tests of regression coefficients â€” jack.test","text":"","code":"data(oliveoil) mod <- pcr(sensory ~ chemical, data = oliveoil, validation = \"LOO\", jackknife = TRUE) jack.test(mod, ncomp = 2) #> Response yellow (2 comps): #>           Estimate Std. Error Df t value Pr(>|t|) #> Acidity  -53.88406   32.00643 15 -1.6835   0.1130 #> Peroxide  -1.64614    1.85612 15 -0.8869   0.3891 #> K232      -9.49515   24.15870 15 -0.3930   0.6998 #> K270      -3.66858    3.07335 15 -1.1937   0.2511 #> DK        -0.35815    0.34117 15 -1.0498   0.3105 #>  #> Response green (2 comps): #>          Estimate Std. Error Df t value Pr(>|t|) #> Acidity  68.69511   39.86563 15  1.7232   0.1054 #> Peroxide  1.41003    2.42316 15  0.5819   0.5693 #> K232     12.06057   31.00606 15  0.3890   0.7028 #> K270      4.67437    3.85337 15  1.2131   0.2439 #> DK        0.45638    0.43416 15  1.0512   0.3098 #>  #> Response brown (2 comps): #>           Estimate Std. Error Df t value Pr(>|t|)   #> Acidity  -5.974767   4.183469 15 -1.4282  0.17373   #> Peroxide  1.271210   0.568083 15  2.2377  0.04084 * #> K232     -0.958874   4.680049 15 -0.2049  0.84042   #> K270     -0.401311   0.188443 15 -2.1296  0.05017 . #> DK       -0.039263   0.030609 15 -1.2827  0.21905   #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Response glossy (2 comps): #>           Estimate Std. Error Df t value Pr(>|t|)   #> Acidity  -7.693126   6.520910 15 -1.1798  0.25647   #> Peroxide -1.126323   0.522543 15 -2.1555  0.04778 * #> K232     -1.413252   4.776935 15 -0.2958  0.77140   #> K270     -0.527123   0.467543 15 -1.1274  0.27727   #> DK       -0.051409   0.076280 15 -0.6739  0.51060   #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Response transp (2 comps): #>            Estimate Std. Error Df t value Pr(>|t|)   #> Acidity  -13.630902   8.573695 15 -1.5899  0.13272   #> Peroxide  -1.286214   0.722367 15 -1.7806  0.09524 . #> K232      -2.458184   8.325620 15 -0.2953  0.77185   #> K270      -0.931303   0.695580 15 -1.3389  0.20055   #> DK        -0.090869   0.109167 15 -0.8324  0.41825   #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 #>  #> Response syrup (2 comps): #>          Estimate Std. Error Df t value  Pr(>|t|)     #> Acidity  1.848304   2.947628 15  0.6270 0.5400554     #> Peroxide 0.666474   0.130938 15  5.0900 0.0001331 *** #> K232     0.365127   0.887538 15  0.4114 0.6866016     #> K270     0.128133   0.187759 15  0.6824 0.5053697     #> DK       0.012474   0.022187 15  0.5622 0.5822789     #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1"},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"Fits PLSR model kernel algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"","code":"kernelpls.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)"},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. loading.weights matrix loading weights. Yscores matrix Y-scores. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar Total variance X. stripped TRUE, components coefficients, Xmeans Ymeans returned.","code":""},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"function called directly, generic functions plsr mvr argument method=\"kernelpls\" (default).  Kernel PLS particularly efficient number objects (much) larger number variables. results equal NIPALS algorithm.  Several different forms kernel PLS described literature, e.g.  De Jong Ter Braak, two algorithms Dayal MacGregor.  function implements fastest latter, calculating crossproduct matrix X.  Dyal & MacGregor paper, â€œalgorithm 1â€.","code":""},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"de Jong, S. ter Braak, C. J. F. (1994) Comments PLS kernel algorithm.  Journal Chemometrics, 8, 169â€“174. Dayal, B. S. MacGregor, J. F. (1997) Improved PLS algorithms. Journal Chemometrics, 11, 73â€“85.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/kernelpls.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Kernel PLS (Dayal and MacGregor) â€” kernelpls.fit","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/mayonnaise.html","id":null,"dir":"Reference","previous_headings":"","what":"NIR measurements and oil types of mayonnaise â€” mayonnaise","title":"NIR measurements and oil types of mayonnaise â€” mayonnaise","text":"Raw NIR measurements (351 wavelengths, 1100-2500 nm steps 4 nm) taken 54 samples mayonnaise based six different oil types (soybean, sunflower, canola, olive, corn, grapeseed). resulting 54 samples measured triplicates, resulting 54 x 3 = 162 different spectra (120/42 training/test).","code":""},{"path":"https://khliland.github.io/pls/reference/mayonnaise.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NIR measurements and oil types of mayonnaise â€” mayonnaise","text":"data frame 162 observations following 4 variables. NIR matrix 351 columns oil.type numeric vector design matrix 5 columns train logical vector","code":""},{"path":"https://khliland.github.io/pls/reference/mayonnaise.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NIR measurements and oil types of mayonnaise â€” mayonnaise","text":"Indahl U, Sahni NS, Kirkhus B, NÃ¦s T.  Multivariate strategies classification based NIR-spectra-application mayonnaise. Chemometr. Intell. Lab. Sys. 1999; 49: 19-31.","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiplicative Scatter Correction â€” msc","title":"Multiplicative Scatter Correction â€” msc","text":"Performs multiplicative scatter/signal correction data matrix.","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiplicative Scatter Correction â€” msc","text":"","code":"msc(X, reference = NULL)  # S3 method for class 'msc' predict(object, newdata, ...)  # S3 method for class 'msc' makepredictcall(var, call)"},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiplicative Scatter Correction â€” msc","text":"X, newdata numeric matrices.  data scatter correct. reference numeric vector.  Spectre use reference.  NULL, column means X used. object object inheriting class \"msc\", normally result call msc single matrix argument. ... arguments.  Currently ignored. var variable. call term formula, call.","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiplicative Scatter Correction â€” msc","text":"msc predict.msc return multiplicative scatter corrected matrix, attribute \"reference\" vector used reference spectre. matrix given class c(\"msc\", \"matrix\"). predict.msc, \"reference\" attribute object used reference spectre.","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiplicative Scatter Correction â€” msc","text":"makepredictcall.msc internal utility function; meant interactive use.  See makepredictcall details.","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multiplicative Scatter Correction â€” msc","text":"Martens, H., NÃ¦s, T. (1989) Multivariate calibration. Chichester: Wiley.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiplicative Scatter Correction â€” msc","text":"BjÃ¸rn-Helge Mevik Ron Wehrens","code":""},{"path":"https://khliland.github.io/pls/reference/msc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiplicative Scatter Correction â€” msc","text":"","code":"data(yarn) ## Direct correction: Ztrain <- msc(yarn$NIR[yarn$train,]) Ztest <- predict(Ztrain, yarn$NIR[!yarn$train,])  ## Used in formula: mod <- plsr(density ~ msc(NIR), ncomp = 6, data = yarn[yarn$train,]) pred <- predict(mod, newdata = yarn[!yarn$train,]) # Automatically scatter corrected"},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares and Principal Component Regression â€” mvr","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"Functions perform partial least squares regression (PLSR), canonical powered partial least squares (CPPLS) principal component regression (PCR), formula interface.  Cross-validation can used.  Prediction, model extraction, plot, print summary methods exist.","code":""},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"","code":"mvr(   formula,   ncomp,   Y.add,   data,   subset,   na.action,   method = pls.options()$mvralg,   scale = FALSE,   center = TRUE,   validation = c(\"none\", \"CV\", \"LOO\"),   model = TRUE,   x = FALSE,   y = FALSE,   ... )  plsr(..., method = pls.options()$plsralg)  pcr(..., method = pls.options()$pcralg)  cppls(..., Y.add, weights, method = pls.options()$cpplsalg)  nipals(..., weights, method = \"nipalspls\")  nipalspcr(..., method = \"nipalspc\")"},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"formula model formula.  lm formula constructs supported.  See . ncomp number components include model (see ). Y.add vector matrix additional responses containing relevant information observations.  used cppls. data optional data frame data fit model . subset optional vector specifying subset observations used fitting process. na.action function indicates happen data contain missing values.  default set na.action setting options, na.fail unset. â€˜factory-freshâ€™ default na.omit.  Another possible value NULL, action.  Value na.exclude can useful.  See na.omit alternatives. method multivariate regression method used.  \"model.frame\", model frame returned. scale numeric vector, logical.  numeric vector, \\(X\\) scaled dividing variable corresponding element scale.  scale TRUE, \\(X\\) scaled dividing variable sample standard deviation.  cross-validation selected, scaling standard deviation done every segment. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. validation character.  kind (internal) validation use. See . model logical.  TRUE, model frame returned. x logical.  TRUE, model matrix returned. y logical.  TRUE, response returned. ... additional optional arguments, passed underlying fit functions, mvrCv. Currently, fit functions oscorespls.fit widekernelpls.fit implement extra arguments: tol: numeric.  Tolerance used determining convergence. maxit: positive integer.  maximal number iterations used. cppls.fit implements: lower: vector lower limits power optimisation. upper: vector upper limits power optimisation. trunc.pow: logical. Whether use experimental alternative power algorithm. mvrCv implements several arguments; following probably useful : segments: number segments use, list segments. segment.type: type segments use. length.seg: Positive integer.  length segments use. jackknife: logical.  Whether perform jackknifing regression coefficients. See functions' documentation details. weights vector individual weights observations.  used cppls.  (Optional)","code":""},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"method = \"model.frame\", model frame returned. Otherwise, object class mvr returned.  object contains components returned underlying fit function.  addition, contains following components: validation validation requested, results cross-validation.  See mvrCv details. fit.time elapsed time fit.  used crossval decide whether turn tracing. na.action observations missing values removed, na.action contains vector indices.  class vector used functions like fitted decide treat observations. ncomp number components model. method method used fit model.  See argument method possible values. center use centering model scale scaling requested (scale), scaling used. call function call. terms model terms. model model = TRUE, model frame. x x = TRUE, model matrix. y y = TRUE, model response.","code":""},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"functions fit PLSR, CPPLS PCR models 1, \\(\\ldots\\), ncomp number components.  Multi-response models fully supported. type model fit specified method argument. Four PLSR algorithms available: kernel algorithm (\"kernelpls\"), wide kernel algorithm (\"widekernelpls\"), SIMPLS (\"simpls\") classical orthogonal scores algorithm (\"oscorespls\"). One CPPLS algorithm available (\"cppls\") providing several extensions PLS. One PCR algorithm available: using singular value decomposition (\"svdpc\").  method \"model.frame\", model frame returned.  functions pcr, plsr cppls wrappers mvr, different values method. formula argument symbolic formula form response ~ terms, response name response vector matrix (multi-response models) terms name one predictor matrices, usually separated +, e.g., water ~ FTIR y ~ X + Z.  See lm detailed description.  named variables exist supplied data data frame global environment.  Note: use mvr(mydata$y ~ mydata$X, ...{}), instead use mvr(y ~ X, data = mydata, ...{}).  Otherwise, predict.mvr work properly.  chapter Statistical models R manual Introduction R distributed good reference formulas . number components fit specified argument ncomp. supplied, maximal number components used (taking account cross-validation). implemented algorithms mean-center predictor response matrices. can turned specifying center = FALSE.  See Seasholtz Kowalski discussion centering PLS regression. validation = \"CV\", cross-validation performed.  number type cross-validation segments specified arguments segments segment.type.  See mvrCv details.  validation = \"LOO\", leave-one-cross-validation performed.  error specify segments validation = \"LOO\" specified. default, cross-validation performed serially.  However, can done parallel using functionality parallel package setting option parallel pls.options. See pls.options differnt ways specify parallelism.  See also Examples . Note cross-validation optimised speed, generality sacrificed.  Especially, model matrix calculated complete cross-validation, models like y ~ msc(X) properly cross-validated.  However, scaling requested scale = TRUE properly cross-validated.  proper cross-validation models model matrix must updated/regenerated segment, use separate function crossval.","code":""},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"Martens, H., NÃ¦s, T. (1989) Multivariate calibration. Chichester: Wiley. Seasholtz, M. B. Kowalski, B. R. (1992) effect mean centering prediction multivariate calibration.  Journal Chemometrics, 6(2), 103â€“111.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares and Principal Component Regression â€” mvr","text":"","code":"data(yarn) ## Default methods: yarn.pcr <- pcr(density ~ NIR, 6, data = yarn, validation = \"CV\") yarn.pls <- plsr(density ~ NIR, 6, data = yarn, validation = \"CV\") yarn.cppls <- cppls(density ~ NIR, 6, data = yarn, validation = \"CV\")  ## Alternative methods: yarn.oscorespls <- mvr(density ~ NIR, 6, data = yarn, validation = \"CV\",                       method = \"oscorespls\") yarn.simpls <- mvr(density ~ NIR, 6, data = yarn, validation = \"CV\",                   method = \"simpls\") # See ?simpls.fit for example of numerical instability in SIMPLS  if (FALSE) { # \\dontrun{ ## Parallelised cross-validation, using transient cluster: pls.options(parallel = 4) # use mclapply pls.options(parallel = quote(makeCluster(4, type = \"PSOCK\"))) # use parLapply ## A new cluster is created and stopped for each cross-validation: yarn.pls <- plsr(density ~ NIR, 6, data = yarn, validation = \"CV\") yarn.pcr <- pcr(density ~ NIR, 6, data = yarn, validation = \"CV\")  ## Parallelised cross-validation, using persistent cluster: library(parallel) ## This creates the cluster: pls.options(parallel = makeCluster(4, type = \"PSOCK\")) ## The cluster can be used several times: yarn.pls <- plsr(density ~ NIR, 6, data = yarn, validation = \"CV\") yarn.pcr <- pcr(density ~ NIR, 6, data = yarn, validation = \"CV\") ## The cluster should be stopped manually afterwards: stopCluster(pls.options()$parallel)  ## Parallelised cross-validation, using persistent MPI cluster: ## This requires the packages snow and Rmpi to be installed library(parallel) ## This creates the cluster: pls.options(parallel = makeCluster(4, type = \"MPI\")) ## The cluster can be used several times: yarn.pls <- plsr(density ~ NIR, 6, data = yarn, validation = \"CV\") yarn.pcr <- pcr(density ~ NIR, 6, data = yarn, validation = \"CV\") ## The cluster should be stopped manually afterwards: stopCluster(pls.options()$parallel) ## It is good practice to call mpi.exit() or mpi.quit() afterwards: mpi.exit() } # }  ## Multi-response models: data(oliveoil) sens.pcr <- pcr(sensory ~ chemical, ncomp = 4, scale = TRUE, data = oliveoil) sens.pls <- plsr(sensory ~ chemical, ncomp = 4, scale = TRUE, data = oliveoil)  ## Classification # A classification example utilizing additional response information # (Y.add) is found in the cppls.fit manual ('See also' above)."},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation â€” mvrCv","title":"Cross-validation â€” mvrCv","text":"Performs cross-validation calculations mvr. function meant called directly, generic functions pcr, plsr, cppls mvr argument validation set \"CV\" \"LOO\".  arguments mvrCv can specified generic function call. segments list, arguments segment.type length.seg ignored.  elements list integer vectors specifying indices segments.  See cvsegments details. Otherwise, segments type segment.type generated.  many segments generate selected specifying number segments segments, giving segment length length.seg.  specified, segments ignored. jackknife TRUE, jackknifed regression coefficients returned, can used variance estimation (var.jack) hypothesis testing (jack.test). X Y need centered. Note function used situations \\(X\\) needs recalculated segment (except scaling standard deviation), instance msc preprocessing.  models, use general (slower) function crossval. Also note needed, function silently(!) reduce ncomp maximal number components can cross-validated, \\(n - l - 1\\), \\(n\\) number observations \\(l\\) length longest segment.  (possibly reduced) number components returned component ncomp. default, cross-validation performed serially.  However, can done parallel using functionality parallel package setting option parallel pls.options. See pls.options different ways specify parallelism.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation â€” mvrCv","text":"","code":"mvrCv(   X,   Y,   ncomp,   Y.add = NULL,   weights = NULL,   method = pls.options()$mvralg,   scale = FALSE,   segments = 10,   segment.type = c(\"random\", \"consecutive\", \"interleaved\"),   length.seg,   jackknife = FALSE,   trace = FALSE,   ... )"},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation â€” mvrCv","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. Y.add vector matrix additional responses containing relevant information observations.  used cppls. weights vector individual weights observations.  used cppls.  (Optional) method multivariate regression method used. scale logical.  TRUE, learning \\(X\\) data segment scaled dividing variable sample standard deviation.  prediction data scaled amount. segments number segments use, list segments (see ). segment.type type segments use.  Ignored segments list. length.seg Positive integer.  length segments use.  specified, overrides segments unless segments list. jackknife logical.  Whether jackknifing regression coefficients performed. trace logical; TRUE, segment number printed segment. ... additional arguments, sent underlying fit function.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation â€” mvrCv","text":"list following components: method equals \"CV\" cross-validation. pred array cross-validated predictions. coefficients (jackknife TRUE) array jackknifed regression coefficients.  dimensions correspond predictors, responses, number components, segments, respectively. PRESS0 vector PRESS values (one response variable) model zero components, .e., intercept. PRESS matrix PRESS values models 1, ..., ncomp components.  row corresponds one response variable. adj matrix adjustment values calculating bias corrected MSEP.  MSEP uses . segments list segments used cross-validation. ncomp actual number components used. gamma method cppls used, gamma values powers CV segment returned.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cross-validation â€” mvrCv","text":"PRESS0 always cross-validated using leave-one-cross-validation.  usually makes little difference practice, fixed correctness. current implementation jackknife stores jackknife-replicates regression coefficients, can costly large matrices. might change future version.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation â€” mvrCv","text":"Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error Prediction (MSEP) Estimates Principal Component Regression (PCR) Partial Least Squares Regression (PLSR).  Journal Chemometrics, 18(9), 422â€“429.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validation â€” mvrCv","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/mvrCv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation â€” mvrCv","text":"","code":"data(yarn) yarn.pcr <- pcr(density ~ NIR, 6, data = yarn, validation = \"CV\", segments = 10) if (FALSE) plot(MSEP(yarn.pcr)) # \\dontrun{}"},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":null,"dir":"Reference","previous_headings":"","what":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"Functions estimate mean squared error prediction (MSEP), root mean squared error prediction (RMSEP) \\(R^2\\) (.K.. coefficient multiple determination) fitted PCR PLSR models.  Test-set, cross-validation calibration-set estimates implemented.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"","code":"mvrValstats(   object,   estimate,   newdata,   ncomp = 1:object$ncomp,   comps,   intercept = cumulative,   se = FALSE,   ... )  R2(object, ...)  # S3 method for class 'mvr' R2(   object,   estimate,   newdata,   ncomp = 1:object$ncomp,   comps,   intercept = cumulative,   se = FALSE,   ... )  MSEP(object, ...)  # S3 method for class 'mvr' MSEP(   object,   estimate,   newdata,   ncomp = 1:object$ncomp,   comps,   intercept = cumulative,   se = FALSE,   ... )  RMSEP(object, ...)  # S3 method for class 'mvr' RMSEP(object, ...)"},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"object mvr object estimate character vector.  estimators use.  subset c(\"\", \"train\", \"CV\", \"adjCV\", \"test\").  \"adjCV\" available (R)MSEP.  See estimators chosen. newdata data frame test set data. ncomp, comps vector positive integers.  components number components use.  See . intercept logical.  Whether estimates model zero components returned well. se logical.  Whether estimated standard errors estimates calculated.  implemented yet. ... arguments sent underlying functions (RMSEP) MSEP","code":""},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"RMSEP simply calls MSEP takes square root estimates.  therefore accepts arguments MSEP. Several estimators can used.  \"train\" training calibration data estimate, also called (R)MSEC.  R2, unadjusted \\(R^2\\).  overoptimistic used assessing models.  \"CV\" cross-validation estimate, \"adjCV\" (RMSEP MSEP) bias-corrected cross-validation estimate.  can calculated model cross-validated.  Finally, \"test\" test set estimate, using newdata test set. estimators use decided follows (see mvrValstats).  estimate specified, test set estimate returned newdata specified, otherwise CV adjusted CV (RMSEP MSEP) estimates model cross-validated, otherwise training data estimate.  estimate \"\", possible estimates calculated. Otherwise, specified estimates calculated. Several model sizes can also specified.  comps missing (NULL), length(ncomp) models used, ncomp[1] components, ..., ncomp[length(ncomp)] components.  Otherwise, single model components comps[1], ..., comps[length(comps)] used.  intercept TRUE, model zero components also used (addition ). \\(R^2\\) values returned \"R2\" calculated \\(1 - SSE/SST\\), \\(SST\\) (corrected) total sum squares response, \\(SSE\\) sum squared errors either fitted values (.e., residual sum squares), test set predictions cross-validated predictions (.e., \\(PRESS\\)).  estimate = \"train\", equivalent squared correlation fitted values response.  estimate = \"train\", estimate often called prediction \\(R^2\\). mvrValstats utility function calculates statistics needed MSEP R2.  intended used interactively.  accepts arguments MSEP R2. However, estimate argument must specified explicitly: partial matching automatic choice made.  function simply calculates types estimates knows, leaves untouched.","code":""},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"mvrValstats returns list components SSE three-dimensional array SSE values.  first dimension different estimators, second response variables third models. SST matrix SST values.  first dimension different estimators second response variables. nobj numeric vector giving number objects used estimator. comps components specified, 0 prepended intercept TRUE. cumulative TRUE comps NULL specified. functions return object class \"mvrVal\", components val three-dimensional array estimates.  first dimension different estimators, second response variables third models. type \"MSEP\", \"RMSEP\" \"R2\". comps components specified, 0 prepended intercept TRUE. cumulative TRUE comps NULL specified. call function call","code":""},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"Mevik, B.-H., Cederkvist, H. R. (2004) Mean Squared Error Prediction (MSEP) Estimates Principal Component Regression (PCR) Partial Least Squares Regression (PLSR).  Journal Chemometrics, 18(9), 422â€“429.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/mvrVal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MSEP, RMSEP and R2 of PLSR and PCR models â€” mvrVal","text":"","code":"data(oliveoil) mod <- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil, validation = \"LOO\") RMSEP(mod) #>  #> Response: yellow  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV            20.1    18.97    16.10    16.71    18.11 #> adjCV         20.1    18.91    16.03    16.61    17.93 #>  #> Response: green  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           24.26    23.88    20.45    21.35    23.96 #> adjCV        24.26    23.80    20.35    21.20    23.70 #>  #> Response: brown  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           5.297    4.019    3.987    3.987    4.107 #> adjCV        5.297    3.990    3.955    3.947    4.050 #>  #> Response: glossy  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           6.391    5.109    5.161    5.571    6.446 #> adjCV        6.391    5.087    5.129    5.522    6.363 #>  #> Response: transp  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV            8.58    7.258    7.158    7.665    8.794 #> adjCV         8.58    7.232    7.118    7.607    8.691 #>  #> Response: syrup  #>        (Intercept)  1 comps  2 comps  3 comps  4 comps #> CV           3.166    2.134    2.325    2.478    2.939 #> adjCV        3.166    2.128    2.310    2.458    2.901 if (FALSE) plot(R2(mod)) # \\dontrun{}"},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust for Missing Values â€” naExcludeMvr","title":"Adjust for Missing Values â€” naExcludeMvr","text":"Use missing value information adjust residuals predictions.  â€˜mvr equivalentâ€™ naresid.exclude napredict.exclude functions.","code":""},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust for Missing Values â€” naExcludeMvr","text":"","code":"naExcludeMvr(omit, x, ...)"},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust for Missing Values â€” naExcludeMvr","text":"omit object produced na.action function, typically \"na.action\" attribute result na.omit na.exclude. x three-dimensional array adjusted based upon missing value information omit. ... arguments.  Currently used.","code":""},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust for Missing Values â€” naExcludeMvr","text":"x, padded NAs along first dimension (â€˜rowsâ€™).","code":""},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjust for Missing Values â€” naExcludeMvr","text":"utility function used allow predict.mvr residuals.mvr compensate removal NAs fitting process. called na.action na.exclude, pads x NAs correct positions number rows original data frame.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/naExcludeMvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adjust for Missing Values â€” naExcludeMvr","text":"BjÃ¸rn-Helge Mevik Ron Wehrens","code":""},{"path":"https://khliland.github.io/pls/reference/nipals.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"NIPALS PLS with missing values â€” nipals.fit","title":"NIPALS PLS with missing values â€” nipals.fit","text":"NIPALS implementation tolerates NAs X Y ignoring updating scores loadings. useful design matrix incomplete number components relatively low.","code":""},{"path":"https://khliland.github.io/pls/reference/nipals.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NIPALS PLS with missing values â€” nipals.fit","text":"","code":"nipals.fit(   X,   Y,   ncomp,   center = TRUE,   stripped = FALSE,   maxiter = 500,   tol = 1e-06,   ... )"},{"path":"https://khliland.github.io/pls/reference/nipals.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NIPALS PLS with missing values â€” nipals.fit","text":"X numeric matrix (coercible) predictors. Missing values allowed handled internally. Y numeric matrix (coercible) responses. Missing values also handled internally. ncomp number PLS components extract. center logical whether center X Y fitting. Means ignore missing entries. stripped logical. TRUE coefficients mean vectors returned. maxiter maximum number inner iterations force convergence component. tol tolerance used stop inner loop direction vector changes little. ... currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/nipals.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NIPALS PLS with missing values â€” nipals.fit","text":"list components nipals.fit, computations never fail presence missing entries.","code":""},{"path":"https://khliland.github.io/pls/reference/nipalspc.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"NIPALS PCR with missing values â€” nipalspc.fit","title":"NIPALS PCR with missing values â€” nipalspc.fit","text":"NIPALS-based PCR tolerates missing entries predictors responses using observed cells updating scores loadings.  follows API svdpc.fit can used whenever low-level PCR needs handle incomplete data.","code":""},{"path":"https://khliland.github.io/pls/reference/nipalspc.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NIPALS PCR with missing values â€” nipalspc.fit","text":"","code":"nipalspc.fit(   X,   Y,   ncomp,   center = TRUE,   stripped = FALSE,   maxiter = 500,   tol = 1e-06,   ... )"},{"path":"https://khliland.github.io/pls/reference/nipalspc.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NIPALS PCR with missing values â€” nipalspc.fit","text":"X numeric matrix (coercible) predictors. Missing values allowed handled internally. Y numeric matrix (coercible) responses. Missing values also handled internally final regression step. ncomp number PCR components extract. center logical. TRUE X Y centered column-wise (ignoring missing entries). stripped logical. TRUE coefficients mean vectors returned faster use resampling. maxiter maximum number inner iterations per component. tol convergence tolerance used direction vector stabilizes. ... currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/nipalspc.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NIPALS PCR with missing values â€” nipalspc.fit","text":"list mirroring return value svdpc.fit computed via NA-robust NIPALS PCR updates.","code":""},{"path":"https://khliland.github.io/pls/reference/oliveoil.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensory and physico-chemical data of olive oils â€” oliveoil","title":"Sensory and physico-chemical data of olive oils â€” oliveoil","text":"data set scores 6 attributes sensory panel measurements 5 physico-chemical quality parameters 16 olive oil samples.  first five oils Greek, next five Italian last six Spanish.","code":""},{"path":"https://khliland.github.io/pls/reference/oliveoil.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sensory and physico-chemical data of olive oils â€” oliveoil","text":"data frame 16 observations following 2 variables. sensory matrix 6 columns.  Scores attributes â€˜yellowâ€™, â€˜greenâ€™, â€˜brownâ€™, â€˜glossyâ€™, â€˜transpâ€™, â€˜syrupâ€™. chemical matrix 5 columns.  Measurements acidity, peroxide, K232, K270, DK.","code":""},{"path":"https://khliland.github.io/pls/reference/oliveoil.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sensory and physico-chemical data of olive oils â€” oliveoil","text":"Massart, D. L., Vandeginste, B. G. M., Buydens, L. M. C., de Jong, S., Lewi, P. J., Smeyers-Verbeke, J. (1998) Handbook Chemometrics Qualimetrics: Part B.  Elsevier. Tables 35.1 35.4.","code":""},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Orthogonal scores PLSR â€” oscorespls.fit","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"Fits PLSR model orthogonal scores algorithm (aka NIPALS algorithm).","code":""},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"","code":"oscorespls.fit(   X,   Y,   ncomp,   center = TRUE,   stripped = FALSE,   tol = .Machine$double.eps^0.5,   maxit = 100,   ... )"},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. tol numeric.  tolerance used determining convergence multi-response models. maxit positive integer.  maximal number iterations used internal Eigenvector calculation. ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. loading.weights matrix loading weights. Yscores matrix Y-scores. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar Total variance X. stripped TRUE, components coefficients, Xmeans Ymeans returned.","code":""},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"function called directly, generic functions plsr mvr argument method=\"oscorespls\".  implements orthogonal scores algorithm, described Martens NÃ¦s (1989).  one two â€œclassicalâ€ PLSR algorithms, orthogonal loadings algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"Martens, H., NÃ¦s, T. (1989) Multivariate calibration. Chichester: Wiley.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/oscorespls.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Orthogonal scores PLSR â€” oscorespls.fit","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for MVR objects â€” plot.mvr","title":"Plot Method for MVR objects â€” plot.mvr","text":"plot.mvr plots predictions, coefficients, scores, loadings, biplots, correlation loadings validation plots (RMSEP curves, etc.).","code":""},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for MVR objects â€” plot.mvr","text":"","code":"# S3 method for class 'mvr' plot(   x,   plottype = c(\"prediction\", \"validation\", \"coefficients\", \"scores\", \"loadings\",     \"biplot\", \"correlation\"),   ... )"},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for MVR objects â€” plot.mvr","text":"x object class mvr.  fitted model plot. plottype character.  kind plot plot. ... arguments, sent underlying plot functions.","code":""},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method for MVR objects â€” plot.mvr","text":"plot.mvr returns whatever underlying plot function returns.","code":""},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for MVR objects â€” plot.mvr","text":"function simply wrapper underlying plot functions used make selected plots.  See predplot.mvr, validationplot, coefplot, scoreplot, loadingplot, biplot.mvr corrplot details.  Note arguments except x plottype must named.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Method for MVR objects â€” plot.mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/plot.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for MVR objects â€” plot.mvr","text":"","code":"data(yarn) nir.pcr <- pcr(density ~ NIR, ncomp = 9, data = yarn, validation = \"CV\") if (FALSE) { # \\dontrun{ plot(nir.pcr, ncomp = 5) # Plot of cross-validated predictions plot(nir.pcr, \"scores\") # Score plot plot(nir.pcr, \"loadings\", comps = 1:3) # The three first loadings plot(nir.pcr, \"coef\", ncomp = 5) # Coefficients plot(nir.pcr, \"val\") # RMSEP curves plot(nir.pcr, \"val\", val.type = \"MSEP\", estimate = \"CV\") # CV MSEP } # }"},{"path":"https://khliland.github.io/pls/reference/pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares and Principal Component Regression â€” pls","title":"Partial Least Squares and Principal Component Regression â€” pls","text":"Multivariate regression methods Partial Least Squares Regression (PLSR), Principal Component Regression (PCR) Canonical Powered Partial Least Squares (CPPLS).","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/pls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial Least Squares and Principal Component Regression â€” pls","text":"Maintainer: Kristian Hovde Liland kristian.liland@nmbu.Authors: BjÃ¸rn-Helge Mevik b-h@mevik.net Ron Wehrens contributors: Paul Hiemstra [contributor]","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set or return options for the pls package â€” pls.options","title":"Set or return options for the pls package â€” pls.options","text":"function set options pls package, return current options.","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set or return options for the pls package â€” pls.options","text":"","code":"pls.options(...)"},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set or return options for the pls package â€” pls.options","text":"... single list, single character vector, number named arguments (name = value).","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set or return options for the pls package â€” pls.options","text":"list (possibly changed) options.  named argument (list element) provided, list returned invisibly.","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set or return options for the pls package â€” pls.options","text":"called arguments, empty list single argument, pls.options returns current options. called character vector single argument, list arguments named vector returned. called non-empty list single argument, list elements named, treated named arguments function. Otherwise, pls.options called one named arguments name = value.  argument, option named name given value value. recognised options : mvralg fit method use mvr mvrCv.  value one allowed methods.  Defaults \"kernelpls\".  Can overridden argument method mvr mvrCv. pcralg fit method use pcr.  value one allowed methods.  Defaults \"svdpc\".  Can overridden argument method pcr. plsralg fit method use plsr.  value one allowed methods.  Defaults \"kernelpls\".  Can overridden argument method plsr. cpplsalg fit method use cppls.  value one allowed methods.  Defaults \"cppls\".  Can overridden argument method cppls. parallel Specification cross-validation (CV) mvr performed.  specification NULL (default) 1, CV done serially, otherwise done parallel using functionality parallel package. integer greater 1, CV done parallel specified number processes, using mclapply. cluster object created makeCluster, CV done parallel cluster, using parLapply.  user stop cluster longer needed, using stopCluster. Finally, specification unevaluated call makeCluster, call evaluated, CV done parallel resulting cluster, using parLapply.  case, cluster stopped (stopCluster) CV.  Thus, final case, cluster created destroyed CV, just like using mclapply. w.tol tolerance used removing values close 0 vectors loading weights cppls.  Defaults .Machine$double.eps. X.tol tolerance used removing predictor variables L1 norms close 0 cppls.  Defaults 10^-12.","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Set or return options for the pls package â€” pls.options","text":"function slight modification function sm.options package sm.","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set or return options for the pls package â€” pls.options","text":"BjÃ¸rn-Helge Mevik Ron Wehrens","code":""},{"path":"https://khliland.github.io/pls/reference/pls.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set or return options for the pls package â€” pls.options","text":"","code":"## Return current options: pls.options() #> $mvralg #> [1] \"kernelpls\" #>  #> $plsralg #> [1] \"kernelpls\" #>  #> $cpplsalg #> [1] \"cppls\" #>  #> $pcralg #> [1] \"svdpc\" #>  #> $parallel #> NULL #>  #> $w.tol #> [1] 2.220446e-16 #>  #> $X.tol #> [1] 1e-12 #>  pls.options(\"plsralg\") #> $plsralg #> [1] \"kernelpls\" #>  pls.options(c(\"plsralg\", \"pcralg\")) #> $plsralg #> [1] \"kernelpls\" #>  #> $pcralg #> [1] \"svdpc\" #>   ## Set options: pls.options(plsralg = \"simpls\", mvralg = \"simpls\") pls.options(list(plsralg = \"simpls\", mvralg = \"simpls\")) # Equivalent pls.options() #> $mvralg #> [1] \"simpls\" #>  #> $plsralg #> [1] \"simpls\" #>  #> $cpplsalg #> [1] \"cppls\" #>  #> $pcralg #> [1] \"svdpc\" #>  #> $parallel #> NULL #>  #> $w.tol #> [1] 2.220446e-16 #>  #> $X.tol #> [1] 1e-12 #>   ## Restore `factory settings': pls.options(list(mvralg = \"kernelpls\", plsralg = \"kernelpls\", cpplsalg = \"cppls\",                  pcralg = \"svdpc\", parallel = NULL,                  w.tol = .Machine$double.eps, X.tol = 10^-12)) pls.options() #> $mvralg #> [1] \"kernelpls\" #>  #> $plsralg #> [1] \"kernelpls\" #>  #> $cpplsalg #> [1] \"cppls\" #>  #> $pcralg #> [1] \"svdpc\" #>  #> $parallel #> NULL #>  #> $w.tol #> [1] 2.220446e-16 #>  #> $X.tol #> [1] 1e-12 #>"},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict Method for PLSR and PCR â€” predict.mvr","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"Prediction mvr (PCR, PLSR) models.  New responses scores predicted using fitted model new matrix observations.","code":""},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"","code":"# S3 method for class 'mvr' predict(   object,   newdata,   ncomp = 1:object$ncomp,   comps,   type = c(\"response\", \"scores\"),   na.action = na.pass,   ... )"},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"object mvr object.  fitted model newdata data frame.  new data.  missing, training data used. ncomp, comps vector positive integers.  components use prediction.  See . type character.  Whether predict scores response values na.action function determining done missing values newdata.  default predict NA.  See na.omit alternatives. ... arguments.  Currently used","code":""},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"type \"response\", three dimensional array predicted response values returned.  dimensions correspond observations, response variables model sizes, respectively. type \"scores\", score matrix returned.","code":""},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"type \"response\" (default), predicted response values returned.  comps missing (NULL), predictions length(ncomp) models ncomp[1] components, ncomp[2] components, etc., returned.  Otherwise, predictions single model exact components comps returned. (Note cases, intercept always included predictions.  can removed subtracting Ymeans component fitted model.) type \"scores\", predicted score values returned components given comps.  comps missing NULL, ncomps used instead. also possible supply matrix instead data frame newdata, assumed \\(X\\) data matrix.  Note usual checks type data omitted.  Also note possible predict; work functions like predplot, RMSEP R2, also need response variable new data.","code":""},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"warning message like 'newdata' 10 rows variable(s) found 106 rows means variables found newdata data frame.  (usually) happens formula contains terms like yarn$NIR.  use terms; use data argument instead.  See mvr details.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/predict.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict Method for PLSR and PCR â€” predict.mvr","text":"","code":"data(yarn) nir.mvr <- mvr(density ~ NIR, ncomp = 5, data = yarn[yarn$train,])  ## Predicted responses for models with 1, 2, 3 and 4 components pred.resp <- predict(nir.mvr, ncomp = 1:4, newdata = yarn[!yarn$train,])  ## Predicted responses for a single model with components 1, 2, 3, 4 predict(nir.mvr, comps = 1:4, newdata = yarn[!yarn$train,]) #>      density #> 110 51.04992 #> 22  50.72019 #> 31  32.01454 #> 41  34.29076 #> 51  30.35994 #> 61  20.57832 #> 71  19.07786  ## Predicted scores predict(nir.mvr, comps = 1:3, type = \"scores\", newdata = yarn[!yarn$train,]) #>          Comp 1     Comp 2     Comp 3 #> 110  1.54411104  0.6112014 -0.2783797 #> 22   1.54887982 -0.3204970 -0.1990664 #> 31   0.03391126  1.4202763 -0.3941334 #> 41   0.30033040  0.2952664 -0.3835675 #> 51  -0.06780681 -1.1572169 -0.1909823 #> 61  -1.04444815  1.3565774 -0.1926097 #> 71  -0.90185306 -0.4988215 -0.3715940"},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction Plots â€” predplot","title":"Prediction Plots â€” predplot","text":"Functions plot predicted values measured values fitted model.","code":""},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction Plots â€” predplot","text":"","code":"predplot(object, ...)  # Default S3 method predplot(object, ...)  # S3 method for class 'mvr' predplot(   object,   ncomp = object$ncomp,   which,   newdata,   nCols,   nRows,   xlab = \"measured\",   ylab = \"predicted\",   main,   ask = nRows * nCols < nPlots && dev.interactive(),   ...,   font.main,   cex.main )  predplotXy(   x,   y,   line = FALSE,   labels,   type = \"p\",   main = \"Prediction plot\",   xlab = \"measured response\",   ylab = \"predicted response\",   line.col = par(\"col\"),   line.lty = NULL,   line.lwd = NULL,   ... )"},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction Plots â€” predplot","text":"object fitted model. ... arguments sent underlying plot functions. ncomp integer vector.  model sizes (numbers components) use prediction. character vector.  types predictions plot.  subset c(\"train\", \"validation\", \"test\").  specified, plot.mvr selects test set predictions newdata supplied, otherwise cross-validated predictions model cross-validated, otherwise fitted values calibration data. newdata data frame.  New data predict. nCols, nRows integer.  number coloumns rows plots laid .  specified, plot.mvr tries intelligent. xlab, ylab titles \\(x\\) \\(y\\) axes.  Typically character strings, can expressions lists.  See title details. main optional main title plot.  See Details. ask logical.  Whether ask user page plot. font.main font use main titles.  See par details.  Also see Details . cex.main numeric.  magnification used main titles relative current size.  Also see Details . x numeric vector.  observed response values. y numeric vector.  predicted response values. line logical.  Whether target line drawn. labels optional.  Alternative plot labels use.  Either vector labels, \"names\" \"numbers\" use row names row numbers data labels. type character.  type plot make.  Defaults \"p\" (points).  See plot complete list types.  argument ignored labels specified. line.col, line.lty, line.lwd character numeric.  col, lty lwd parametres target line.  See par details.","code":""},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction Plots â€” predplot","text":"functions invisibly return matrix (last) plotted data.","code":""},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction Plots â€” predplot","text":"predplot generic function plotting predicted versus measured response values, default mvr methods currently implemented. default method simple, handle multiple responses new data. mvr method, handles multiple responses, model sizes types predictions making one plot combination.  can also called plot method mvr, specifying plottype = \"prediction\" (default). argument main can used specify main title plot. handled non-standard way.  (sub) plot, main used main title plot.  one (sub) plot, however, presence main produce corresponding â€˜globalâ€™ title page.  graphical parametres, e.g., cex.main, supplied coefplot affect â€˜ordinaryâ€™ plot titles, â€˜globalâ€™ one.  appearance can changed setting parameters par, affect titles (exception font.main cex.main, affect â€˜globalâ€™ title one plot).  (different settings two titles, one can override par settings arguments predplot.) predplotXy internal function meant interactive use.  called predplot methods, arguments, e.g, line, can given predplot call.","code":""},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Prediction Plots â€” predplot","text":"font.main cex.main must (completely) named. avoid argument cex font matches . Tip: labels specified labels long, get clipped border plot region.  can avoided supplying graphical parameter xpd = TRUE plot call.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction Plots â€” predplot","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/predplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction Plots â€” predplot","text":"","code":"data(yarn) mod <- plsr(density ~ NIR, ncomp = 10, data = yarn[yarn$train,], validation = \"CV\") if (FALSE) { # \\dontrun{ predplot(mod, ncomp = 1:6) plot(mod, ncomp = 1:6) # Equivalent to the previous ## Both cross-validated and test set predictions: predplot(mod, ncomp = 4:6, which = c(\"validation\", \"test\"),          newdata = yarn[!yarn$train,]) } # }  data(oliveoil) mod.sens <- plsr(sensory ~ chemical, ncomp = 4, data = oliveoil) if (FALSE) plot(mod.sens, ncomp = 2:4) # Several responses gives several plots # \\dontrun{}"},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"Functions make scatter plots scores correlation loadings, scatter line plots loadings.","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"","code":"scoreplot(object, ...)  # Default S3 method scoreplot(   object,   comps = 1:2,   labels,   identify = FALSE,   type = \"p\",   xlab,   ylab,   estimate,   newdata,   ... )  # S3 method for class 'scores' plot(x, ...)  loadingplot(object, ...)  # Default S3 method loadingplot(   object,   comps = 1:2,   scatter = FALSE,   labels,   identify = FALSE,   type,   lty,   lwd = NULL,   pch,   cex = NULL,   col,   legendpos,   xlab,   ylab,   pretty.xlabels = TRUE,   xlim,   ... )  # S3 method for class 'loadings' plot(x, ...)  corrplot(   object,   comps = 1:2,   labels,   plotx = TRUE,   ploty = FALSE,   radii = c(sqrt(1/2), 1),   identify = FALSE,   type = \"p\",   xlab,   ylab,   col,   ... )"},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"object object.  fitted model. ... arguments sent underlying plot function(s). comps integer vector.  components plot. labels optional.  Alternative plot labels \\(x\\) axis labels. See Details. identify logical.  Whether use identify interactively identify points.  See . type character.  type plot make.  Defaults \"p\" (points) scatter plots \"l\" (lines) line plots.  See plot complete list types (types possible/meaningful plots). xlab, ylab titles \\(x\\) \\(y\\) axes.  Typically character strings, can expressions lists.  See title details. estimate optional character vector passed scores() scoreplot() can request training, CV test estimate plotting. newdata optional data frame supplied scores() estimate = \"test\". x scores loadings object.  scores loadings plot. scatter logical.  Whether loadings plotted scatter instead lines. lty vector line types (recycled neccessary).  Line types can specified integers character strings (see par details). lwd vector positive numbers (recycled neccessary), giving width lines. pch plot character.  character string vector single characters integers (recycled neccessary).  See points alternatives. cex numeric vector character expansion sizes (recycled neccessary) plotted symbols. col character integer vector colors plotted lines symbols (recycled neccessary).  See par details. legendpos Legend position.  Optional.  Ignored scatter TRUE.  present, legend drawn given position.  position can specified symbolically (e.g., legendpos = \"topright\").  requires >= 2.1.0.  Alternatively, position can specified explicitly (legendpos = t(c(x,y))) interactively (legendpos = locator()). pretty.xlabels logical.  TRUE, loadingplot tries plot \\(x\\) labels nicely.  See Details. xlim optional vector length two, \\(x\\) limits plot. plotx locical.  Whether plot \\(X\\) correlation loadings. Defaults TRUE. ploty locical.  Whether plot \\(Y\\) correlation loadings. Defaults FALSE. radii numeric vector, giving radii circles drawn corrplot.  default radii represent 50% 100% explained variance \\(X\\) variables chosen components.","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"functions return whatever underlying plot function (identify) returns.","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"plot.scores simply wrapper calling scoreplot, passing arguments.  Similarly plot.loadings. scoreplot generic, currently default method works matrices object scores returns matrix. default scoreplot method makes one scatter plots scores, depending many components selected.  one two components selected, identify TRUE, function identify used interactively identify points. Also loadingplot generic, default method works matrices object loadings returns matrix.  scatter TRUE, default method works exactly like default scoreplot method.  Otherwise, makes lineplot selected loading vectors, identify TRUE, uses identify interactively identify points.  Also, legendpos given, legend drawn position indicated. corrplot works exactly like default scoreplot method, except least two components must selected.  â€œcorrelation loadingsâ€, .e. correlations variable selected components (see References), plotted pairwise scatter plots, concentric circles radii given radii.  point corresponds variable.  squared distance point origin equals fraction variance variable explained components panel.  default radii corresponds 50% 100% explained variance.  default, correlation loadings \\(X\\) variables plotted, ploty TRUE, also \\(Y\\) correlation loadings plotted. scoreplot, loadingplot corrplot can also called plot method mvr objects, specifying plottype \"scores\", \"loadings\" \"correlation\", respectively.  See plot.mvr. argument labels can vector labels one \"names\" \"numbers\". scatter plot produced (.e., scoreplot, corrplot, loadingplot scatter = TRUE), labels used instead plot symbols points plotted.  labels \"names\" \"numbers\", row names row numbers matrix (scores, loadings correlation loadings) used. line plot produced (.e., loadingplot), labels used \\(x\\) axis labels.  labels \"names\" \"numbers\", variable names used labels, difference \"numbers\", variable names converted numbers, possible.  Variable names forms \"number\" \"number text\" (space optional), handled. argument pretty.xlabels used labels specified line plot.  TRUE (default), code tries use â€˜prettyâ€™ selection labels.  labels \"numbers\", also uses numerical values labels horisontal spacing.  one excluded parts spectral region, one might therefore want use pretty.xlabels = FALSE.","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"legend many options.  want greater control appearance legend, omit legendpos argument call legend manually. Graphical parametres (pch cex) can also used scoreplot corrplot.  listed argument list simply handled specifically function (unlike loadingplot), passed directly underlying plot functions ...{}. Tip: labels specified labels long, get clipped border plot region.  can avoided supplying graphical parameter xpd = TRUE plot call. handling labels pretty.xlabels coefplot experimental.","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"Martens, H., Martens, M. (2000) Modified Jack-knife Estimation Parameter Uncertainty Bilinear Modelling Partial Least Squares Regression (PLSR).  Food Quality Preference, 11(1â€“2), 5â€“16.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/scoreplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of Scores, Loadings and Correlation Loadings â€” scoreplot","text":"","code":"data(yarn) mod <- plsr(density ~ NIR, ncomp = 10, data = yarn) ## These three are equivalent: if (FALSE) { # \\dontrun{ scoreplot(mod, comps = 1:5) plot(scores(mod), comps = 1:5) plot(mod, plottype = \"scores\", comps = 1:5)  loadingplot(mod, comps = 1:5) loadingplot(mod, comps = 1:5, legendpos = \"topright\") # With legend loadingplot(mod, comps = 1:5, scatter = TRUE) # Plot as scatterplots  corrplot(mod, comps = 1:2) corrplot(mod, comps = 1:3) } # }  # Use of labels in plots and x scales data(gasoline) colnames(gasoline$NIR) <- paste(seq(900, 1700, 2), \"nm\") gas <- plsr(octane ~ NIR, ncomp = 10, data = gasoline) loadingplot(gas, labels=\"numbers\")  loadingplot(gas, labels=\"names\")  loadingplot(gas, labels=\"names\", scatter=TRUE)"},{"path":"https://khliland.github.io/pls/reference/scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"functions extract score loading matrices fitted mvr models.","code":""},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"","code":"loadings(object, ...)  # Default S3 method loadings(object, ...)  scores(object, ...)  # Default S3 method scores(object, estimate, newdata, ...)  Yscores(object)  loading.weights(object)  Yloadings(object)"},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"object fitted model extract . ... extra arguments, currently used. estimate optional character vector (\"train\", \"CV\", \"test\") used scores select desired estimate. newdata optional data frame passed scores estimate = \"test\".","code":""},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"matrix scores loadings.","code":""},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"functions extract indicated matrix fitted model, work object suitably named component. default scores loadings methods also handle prcomp objects (scores loadings components called x rotation, resp.), add attribute \"explvar\" variance explained component, available.  (See explvar details.)","code":""},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"loadings function package stats.  simply returns element named \"loadings\".  See loadings details.  function can accessed stats::loadings(...).","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Scores and Loadings from PLSR and PCR Models â€” scores","text":"","code":"data(yarn) plsmod <- plsr(density ~ NIR, 6, data = yarn) scores(plsmod) #>          Comp 1      Comp 2       Comp 3       Comp 4      Comp 5       Comp 6 #> 1    4.57990419 -0.09140373  0.869242045 -0.017624270  0.18502203  0.099904242 #> 2    3.24841966  0.89743358  0.469247768  0.096725666 -0.03959236 -0.027485757 #> 3    3.75411539 -0.82766123  0.114423744 -0.118119468  0.16331738 -0.053562185 #> 4    1.77397722  1.81447783  0.253607676  0.175783437 -0.11128205 -0.068314261 #> 5    2.17007140  0.12029310 -0.002896461  0.002020851 -0.11245856 -0.008001149 #> 6    2.49106503 -1.78266322 -0.041678574 -0.211359090 -0.13985623  0.066714219 #> 7    0.46210460  2.79295125 -0.265431714  0.168243919  0.13127368 -0.200592065 #> 8    0.54266383  1.00552486 -0.172445948  0.104351353 -0.07781285  0.022128415 #> 9    1.13590335 -0.67265429 -0.637478608 -0.056866988  0.28724448 -0.002555841 #> 10   1.14492576 -2.69639522 -0.365745299 -0.185221159 -0.09638374  0.012648858 #> 11  -1.12262204  3.11725314  0.070563455 -0.094171311 -0.20423283 -0.167496591 #> 12  -1.20053991  1.73520617 -0.015753174  0.097684399 -0.14695942  0.017545312 #> 13  -1.06084971  0.17731462 -0.126529855  0.086348166 -0.04902282  0.109594846 #> 14  -0.85884461 -1.72512705 -0.143766013 -0.009128428 -0.09768392  0.071537229 #> 15  -0.68291566 -3.65041572 -0.200548113 -0.103482366  0.01193804 -0.097646550 #> 16  -2.58038381  3.49457557  0.226667852 -0.510871968  0.02943195 -0.022853788 #> 17  -2.85280950  2.33305213  0.125156861 -0.128225389  0.15676625  0.031781764 #> 18  -3.02813920  0.93940405  0.234453776  0.060569164  0.08243872  0.132526028 #> 19  -3.07386202 -0.87231577  0.331430586  0.124441248  0.05921566  0.118437352 #> 20  -3.03452441 -2.70869481  0.439804866  0.094660241 -0.02467206  0.039652890 #> 21  -2.85800943 -4.70204024  0.391362802  0.048811675  0.04302261 -0.290446059 #> 110  1.49058368  0.56788023 -0.206846940  0.062233909  0.01885088 -0.044744183 #> 22   1.50061613 -0.37410610 -0.130661131 -0.019952044 -0.14343798  0.020996299 #> 31  -0.02429829  1.37366578 -0.325696729  0.118601107  0.06845529 -0.022478376 #> 41   0.24798549  0.23912041 -0.320229664  0.056986162  0.02048780  0.081784970 #> 51  -0.11200548 -1.23265000 -0.132955691 -0.014323259 -0.16945767  0.108601806 #> 61  -1.10182066  1.29797017 -0.126319525  0.108970829 -0.03664540 -0.005976487 #> 71  -0.95071098 -0.56999551 -0.310977991  0.062913616  0.19203311  0.078299062 #> attr(,\"class\") #> [1] \"scores\" #> attr(,\"explvar\") #>     Comp 1     Comp 2     Comp 3     Comp 4     Comp 5     Comp 6  #> 46.8349936 51.5408548  1.0793049  0.2145479  0.1844248  0.1177235  loadings(plsmod)[,1:4] #>               Comp 1        Comp 2       Comp 3        Comp 4 #> NIR1    6.624595e-03  1.541745e-02 -0.116401274 -0.0320444153 #> NIR2    2.132897e-02  3.259607e-02 -0.143816927 -0.0608729488 #> NIR3    3.907772e-02  5.674406e-02 -0.135692817 -0.0874724587 #> NIR4    5.182098e-02  8.249987e-02 -0.088729023 -0.0755824107 #> NIR5    5.375104e-02  1.044961e-01 -0.033554914 -0.0562929027 #> NIR6    4.611467e-02  1.222377e-01  0.001861870 -0.0489105670 #> NIR7    3.155193e-02  1.374709e-01  0.015294632 -0.0521218645 #> NIR8    1.146237e-02  1.501444e-01  0.013186256 -0.0618918557 #> NIR9   -1.169045e-02  1.614116e-01  0.001453473 -0.0681412420 #> NIR10  -3.536374e-02  1.744725e-01 -0.016742230 -0.0603595204 #> NIR11  -5.933681e-02  1.902894e-01 -0.038619507 -0.0386450581 #> NIR12  -8.306889e-02  2.071693e-01 -0.060675092 -0.0072256811 #> NIR13  -1.032609e-01  2.232145e-01 -0.081648448  0.0358317103 #> NIR14  -1.177729e-01  2.372211e-01 -0.102986174  0.0990587399 #> NIR15  -1.303175e-01  2.494489e-01 -0.126883472  0.1824573576 #> NIR16  -1.466046e-01  2.595813e-01 -0.154632968  0.2697444974 #> NIR17  -1.640180e-01  2.661338e-01 -0.177228247  0.3233529623 #> NIR18  -1.743316e-01  2.674873e-01 -0.185362771  0.3089211292 #> NIR19  -1.733705e-01  2.635447e-01 -0.177065880  0.2244538105 #> NIR20  -1.619144e-01  2.543173e-01 -0.153061593  0.0856512907 #> NIR21  -1.448837e-01  2.387700e-01 -0.119415782 -0.0712235354 #> NIR22  -1.277032e-01  2.173329e-01 -0.088415171 -0.1928233371 #> NIR23  -1.110050e-01  1.943493e-01 -0.067224160 -0.2513429993 #> NIR24  -9.460788e-02  1.711954e-01 -0.051959578 -0.2610302415 #> NIR25  -8.474681e-02  1.470327e-01 -0.041449205 -0.2545203297 #> NIR26  -8.379625e-02  1.247347e-01 -0.034800275 -0.2444184550 #> NIR27  -8.084661e-02  1.022109e-01 -0.029874808 -0.2171423219 #> NIR28  -6.313834e-02  7.272864e-02 -0.037366335 -0.1383743913 #> NIR29  -3.904403e-02  4.486388e-02 -0.045376831 -0.0715608527 #> NIR30  -1.951470e-02  2.529461e-02 -0.045120956 -0.0312093825 #> NIR31  -8.256665e-03  1.440309e-02 -0.040934326 -0.0078561628 #> NIR32  -5.225275e-03  1.025369e-02 -0.038102657  0.0001045079 #> NIR33  -7.271759e-03  1.020135e-02 -0.038545098 -0.0013953124 #> NIR34  -1.050634e-02  1.194265e-02 -0.041011952 -0.0060286985 #> NIR35  -1.386392e-02  1.246251e-02 -0.044041488 -0.0095007175 #> NIR36  -1.842760e-02  8.818447e-03 -0.048260842 -0.0096857377 #> NIR37  -2.384892e-02  3.617778e-03 -0.053681986 -0.0082855432 #> NIR38  -2.890335e-02  2.482860e-03 -0.058950050 -0.0107229978 #> NIR39  -3.267125e-02  3.274024e-03 -0.063723711 -0.0149707164 #> NIR40  -3.420457e-02  8.904731e-04 -0.067575181 -0.0129794353 #> NIR41  -3.265536e-02 -2.588608e-03 -0.068916396 -0.0073110346 #> NIR42  -2.984714e-02 -1.803429e-03 -0.066875767 -0.0058930953 #> NIR43  -2.941407e-02  1.944929e-03 -0.064192294 -0.0094845547 #> NIR44  -3.143770e-02  2.478976e-03 -0.065314906 -0.0123451695 #> NIR45  -3.351881e-02 -1.326440e-03 -0.069581823 -0.0108408723 #> NIR46  -3.428486e-02 -1.997008e-03 -0.072395354 -0.0120020038 #> NIR47  -3.366706e-02  5.099892e-03 -0.070835478 -0.0201267544 #> NIR48  -3.450930e-02  1.166034e-02 -0.068721263 -0.0287646505 #> NIR49  -3.838940e-02  1.221044e-02 -0.073091969 -0.0320795944 #> NIR50  -4.313153e-02  1.065212e-02 -0.081826871 -0.0342082384 #> NIR51  -4.565483e-02  4.180119e-03 -0.091100451 -0.0288728448 #> NIR52  -4.169298e-02 -1.720733e-02 -0.102892350  0.0033520365 #> NIR53  -3.224423e-02 -4.109102e-02 -0.111009318  0.0312488068 #> NIR54  -2.361946e-02 -4.916201e-02 -0.108675344  0.0452166366 #> NIR55  -1.654489e-02 -3.714856e-02 -0.096144163  0.0427179359 #> NIR56  -1.169685e-02 -1.126248e-02 -0.077475911  0.0110990005 #> NIR57  -1.014691e-02  1.205054e-02 -0.059610633 -0.0328958376 #> NIR58  -4.918889e-03  1.379837e-02 -0.053583705 -0.0340048642 #> NIR59   4.755685e-03  9.363066e-04 -0.051338427 -0.0050761772 #> NIR60   8.212777e-03 -1.132494e-02 -0.049392271  0.0310513967 #> NIR61   5.146947e-03 -2.045708e-02 -0.055677926  0.0616808751 #> NIR62   6.312422e-03 -2.203296e-02 -0.061318118  0.0749123900 #> NIR63   1.303421e-02 -1.611113e-02 -0.057347565  0.0731000696 #> NIR64   1.422116e-02 -1.106599e-02 -0.049990898  0.0622268747 #> NIR65   7.873790e-03 -5.394719e-03 -0.044993322  0.0356268993 #> NIR66   7.170677e-03  1.137927e-02 -0.044405978 -0.0022335031 #> NIR67   1.498220e-02  2.260739e-02 -0.037949291 -0.0196640746 #> NIR68   2.603544e-02  4.771798e-02 -0.042253436 -0.0362639904 #> NIR69   6.383787e-02  8.492879e-02 -0.029419805 -0.0440981976 #> NIR70   1.000377e-01  7.683935e-02  0.015756524  0.0322074785 #> NIR71   1.140048e-01  5.871186e-02  0.037834407  0.0656785598 #> NIR72   1.159581e-01  4.641634e-02  0.041084980  0.0804218607 #> NIR73   1.136673e-01  4.023444e-02  0.038877746  0.0870849094 #> NIR74   1.104668e-01  3.718318e-02  0.035795609  0.0885675815 #> NIR75   1.074530e-01  3.533359e-02  0.032300193  0.0878423805 #> NIR76   1.052701e-01  3.403376e-02  0.028759109  0.0863259121 #> NIR77   1.043708e-01  3.323780e-02  0.025196674  0.0849577160 #> NIR78   1.047859e-01  3.296461e-02  0.021159476  0.0839924398 #> NIR79   1.062758e-01  3.310066e-02  0.016048108  0.0838507526 #> NIR80   1.086711e-01  3.355627e-02  0.010651089  0.0832923225 #> NIR81   1.116293e-01  3.435968e-02  0.005122926  0.0814470373 #> NIR82   1.144054e-01  3.559394e-02 -0.002842356  0.0799478142 #> NIR83   1.162910e-01  3.718907e-02 -0.014626223  0.0784658950 #> NIR84   1.171046e-01  3.874999e-02 -0.030260015  0.0756533421 #> NIR85   1.168514e-01  3.970971e-02 -0.048030473  0.0728033513 #> NIR86   1.152502e-01  3.978679e-02 -0.067428446  0.0703528048 #> NIR87   1.128360e-01  3.919499e-02 -0.088907184  0.0658368362 #> NIR88   1.099585e-01  3.870950e-02 -0.109336951  0.0594282322 #> NIR89   1.061798e-01  3.918041e-02 -0.128356069  0.0570116722 #> NIR90   1.023012e-01  4.045748e-02 -0.144427214  0.0492969434 #> NIR91   9.972432e-02  4.182903e-02 -0.151108961  0.0310533687 #> NIR92   9.821457e-02  4.324393e-02 -0.153789402  0.0143836073 #> NIR93   9.695664e-02  4.495216e-02 -0.157315568  0.0018729507 #> NIR94   9.643888e-02  4.674486e-02 -0.160735779 -0.0047622602 #> NIR95   9.696313e-02  4.874639e-02 -0.166529740 -0.0056341168 #> NIR96   9.873766e-02  5.103590e-02 -0.169520543 -0.0034114349 #> NIR97   1.014125e-01  5.280361e-02 -0.168853034  0.0016049665 #> NIR98   1.036496e-01  5.364092e-02 -0.166881935  0.0066610016 #> NIR99   1.055234e-01  5.406348e-02 -0.158502231  0.0073974007 #> NIR100  1.076527e-01  5.431997e-02 -0.145161600  0.0053924823 #> NIR101  1.095304e-01  5.480715e-02 -0.133336801  0.0080037177 #> NIR102  1.104313e-01  5.550128e-02 -0.123542850  0.0140348117 #> NIR103  1.104275e-01  5.605672e-02 -0.114702394  0.0163248283 #> NIR104  1.101076e-01  5.672286e-02 -0.105386717  0.0174668109 #> NIR105  1.094454e-01  5.718261e-02 -0.094794469  0.0146807340 #> NIR106  1.081401e-01  5.747881e-02 -0.086857677  0.0090829702 #> NIR107  1.064748e-01  5.796668e-02 -0.082037612  0.0074065537 #> NIR108  1.046144e-01  5.847984e-02 -0.077351605  0.0054487896 #> NIR109  1.027069e-01  5.915674e-02 -0.072574421  0.0019643275 #> NIR110  1.012026e-01  6.010986e-02 -0.067458145 -0.0004461089 #> NIR111  9.991985e-02  6.119731e-02 -0.063152940 -0.0019100052 #> NIR112  9.855897e-02  6.247126e-02 -0.060846424 -0.0049773030 #> NIR113  9.720521e-02  6.404968e-02 -0.057631008 -0.0127890214 #> NIR114  9.578353e-02  6.602801e-02 -0.050312553 -0.0203587373 #> NIR115  9.407774e-02  6.845251e-02 -0.041758661 -0.0253913015 #> NIR116  9.260852e-02  7.099350e-02 -0.036711627 -0.0302888204 #> NIR117  9.194588e-02  7.370500e-02 -0.032396979 -0.0332279266 #> NIR118  9.171015e-02  7.667931e-02 -0.026681952 -0.0359895087 #> NIR119  9.138339e-02  7.944016e-02 -0.020316131 -0.0400471076 #> NIR120  9.086036e-02  8.186787e-02 -0.014125770 -0.0437547052 #> NIR121  9.024859e-02  8.407317e-02 -0.007268766 -0.0474658778 #> NIR122  8.948288e-02  8.595030e-02  0.000144654 -0.0492529617 #> NIR123  8.862589e-02  8.768225e-02  0.005843419 -0.0509385516 #> NIR124  8.799255e-02  8.993594e-02  0.010973947 -0.0535700717 #> NIR125  8.755197e-02  9.288096e-02  0.018132131 -0.0554048163 #> NIR126  8.712935e-02  9.559836e-02  0.026137437 -0.0571050401 #> NIR127  8.686731e-02  9.719827e-02  0.032801114 -0.0592570694 #> NIR128  8.624176e-02  9.769130e-02  0.040712505 -0.0588021837 #> NIR129  8.351762e-02  9.724070e-02  0.049869181 -0.0555330040 #> NIR130  7.827797e-02  9.584977e-02  0.055361227 -0.0537945825 #> NIR131  7.252987e-02  9.347109e-02  0.056763902 -0.0549473883 #> NIR132  6.777853e-02  8.983553e-02  0.056305098 -0.0556112304 #> NIR133  6.423042e-02  8.523301e-02  0.055025740 -0.0536194511 #> NIR134  6.144149e-02  8.065389e-02  0.053459576 -0.0513925219 #> NIR135  5.850488e-02  7.664893e-02  0.051546925 -0.0508126384 #> NIR136  5.469274e-02  7.274917e-02  0.049074120 -0.0510418495 #> NIR137  5.060985e-02  6.856976e-02  0.045762471 -0.0507534946 #> NIR138  4.764458e-02  6.440203e-02  0.042188012 -0.0497501262 #> NIR139  4.595081e-02  6.065337e-02  0.039452277 -0.0477682047 #> NIR140  4.455818e-02  5.675442e-02  0.037076397 -0.0442782448 #> NIR141  4.279654e-02  5.140861e-02  0.034715053 -0.0383298925 #> NIR142  3.997549e-02  4.374917e-02  0.033901300 -0.0301701687 #> NIR143  3.666373e-02  3.473691e-02  0.034526184 -0.0205316224 #> NIR144  3.619861e-02  2.754730e-02  0.032378853 -0.0123753158 #> NIR145  3.887940e-02  2.434911e-02  0.024815254 -0.0080509125 #> NIR146  3.964622e-02  2.407038e-02  0.016019080 -0.0064330623 #> NIR147  3.431430e-02  2.413091e-02  0.010130979 -0.0072798941 #> NIR148  2.297787e-02  2.241624e-02  0.004351753 -0.0116474971 #> NIR149  9.882733e-03  1.881219e-02 -0.004023871 -0.0175289455 #> NIR150  1.015366e-03  1.552048e-02 -0.012588764 -0.0215481617 #> NIR151 -5.956351e-04  1.412980e-02 -0.018059542 -0.0216838535 #> NIR152  3.095850e-03  1.275838e-02 -0.019839973 -0.0148010848 #> NIR153  7.383891e-03  1.065651e-02 -0.019763003 -0.0046064203 #> NIR154  9.604775e-03  1.023867e-02 -0.019405335  0.0012561331 #> NIR155  1.168321e-02  1.118619e-02 -0.018497799  0.0037248946 #> NIR156  1.538586e-02  1.114153e-02 -0.016208243  0.0080697437 #> NIR157  1.911424e-02  1.089016e-02 -0.012762796  0.0123855983 #> NIR158  2.072069e-02  1.197687e-02 -0.009766196  0.0131897788 #> NIR159  2.008720e-02  1.366036e-02 -0.008488977  0.0109448112 #> NIR160  1.800666e-02  1.477616e-02 -0.009105847  0.0080877299 #> NIR161  1.590361e-02  1.499982e-02 -0.010852986  0.0061108417 #> NIR162  1.607253e-02  1.413900e-02 -0.011583042  0.0069214812 #> NIR163  1.760846e-02  1.251786e-02 -0.009920632  0.0104142298 #> NIR164  1.698938e-02  1.101840e-02 -0.009082676  0.0124530089 #> NIR165  1.411756e-02  9.761127e-03 -0.011160606  0.0117093687 #> NIR166  1.108416e-02  8.574941e-03 -0.014399733  0.0103945249 #> NIR167  8.793373e-03  7.495023e-03 -0.017243291  0.0098252013 #> NIR168  7.042095e-03  6.571564e-03 -0.019282794  0.0095952645 #> NIR169  5.589539e-03  5.767249e-03 -0.020861677  0.0094821855 #> NIR170  4.362690e-03  5.047961e-03 -0.022367411  0.0096135325 #> NIR171  3.323070e-03  4.410634e-03 -0.023676003  0.0097059875 #> NIR172  2.462306e-03  3.866898e-03 -0.024689108  0.0096672744 #> NIR173  1.785351e-03  3.423101e-03 -0.025580229  0.0097140099 #> NIR174  1.229319e-03  3.044163e-03 -0.026357191  0.0097194158 #> NIR175  7.251181e-04  2.689458e-03 -0.026894566  0.0096281260 #> NIR176  2.650787e-04  2.363551e-03 -0.027424673  0.0096757240 #> NIR177 -1.696646e-04  2.078286e-03 -0.027962880  0.0097378822 #> NIR178 -6.058720e-04  1.818866e-03 -0.028371513  0.0095941394 #> NIR179 -1.009434e-03  1.583418e-03 -0.028781580  0.0094562276 #> NIR180 -1.351203e-03  1.389738e-03 -0.029243834  0.0094683509 #> NIR181 -1.644406e-03  1.245508e-03 -0.029568328  0.0093058851 #> NIR182 -1.870415e-03  1.147624e-03 -0.029777394  0.0090888707 #> NIR183 -2.000738e-03  1.081875e-03 -0.030059637  0.0091075219 #> NIR184 -2.080340e-03  9.915259e-04 -0.030216244  0.0091819066 #> NIR185 -2.155584e-03  8.521834e-04 -0.030236784  0.0092292950 #> NIR186 -2.217807e-03  7.121934e-04 -0.030359661  0.0093970598 #> NIR187 -2.271436e-03  6.259727e-04 -0.030491980  0.0094767326 #> NIR188 -2.321780e-03  5.882508e-04 -0.030528943  0.0093607609 #> NIR189 -2.317601e-03  5.695086e-04 -0.030574769  0.0093732713 #> NIR190 -2.240825e-03  5.383054e-04 -0.030639885  0.0095234849 #> NIR191 -2.129850e-03  4.697268e-04 -0.030518135  0.0096510729 #> NIR192 -1.992368e-03  3.587620e-04 -0.030381115  0.0098637546 #> NIR193 -1.827479e-03  2.327608e-04 -0.030369920  0.0102537832 #> NIR194 -1.647574e-03  1.446636e-04 -0.030261211  0.0104321921 #> NIR195 -1.424722e-03  1.558471e-04 -0.030055638  0.0103939954 #> NIR196 -1.145519e-03  2.691782e-04 -0.029879279  0.0104697444 #> NIR197 -8.754454e-04  3.971566e-04 -0.029633880  0.0105529140 #> NIR198 -7.013720e-04  4.800008e-04 -0.029276021  0.0105335209 #> NIR199 -7.346804e-04  5.226082e-04 -0.029065195  0.0105229560 #> NIR200 -1.144657e-03  4.958769e-04 -0.028995498  0.0103201202 #> NIR201 -1.994776e-03  3.441844e-04 -0.029071118  0.0097550282 #> NIR202 -3.181979e-03  8.727982e-05 -0.029537913  0.0090828959 #> NIR203 -4.586710e-03 -2.194379e-04 -0.030380408  0.0083440983 #> NIR204 -6.111049e-03 -5.184947e-04 -0.031356285  0.0071941252 #> NIR205 -7.624620e-03 -7.448019e-04 -0.032425929  0.0058920654 #> NIR206 -9.035376e-03 -9.386728e-04 -0.033623440  0.0047630819 #> NIR207 -1.036141e-02 -1.178173e-03 -0.034712018  0.0036843593 #> NIR208 -1.164530e-02 -1.413282e-03 -0.035668366  0.0025415421 #> NIR209 -1.289320e-02 -1.558695e-03 -0.036687612  0.0013965988 #> NIR210 -1.400392e-02 -1.635169e-03 -0.037825280  0.0001961030 #> NIR211 -1.471900e-02 -1.741658e-03 -0.039013056 -0.0006973855 #> NIR212 -1.489531e-02 -2.010503e-03 -0.040143930 -0.0007412380 #> NIR213 -1.471450e-02 -2.571973e-03 -0.040985598 -0.0001860462 #> NIR214 -1.448544e-02 -3.372924e-03 -0.041443918  0.0005043870 #> NIR215 -1.434284e-02 -4.250369e-03 -0.041926353  0.0013275375 #> NIR216 -1.427168e-02 -5.208370e-03 -0.042562107  0.0022344402 #> NIR217 -1.427435e-02 -6.478388e-03 -0.043224660  0.0033443663 #> NIR218 -1.437416e-02 -8.449011e-03 -0.044257841  0.0052085089 #> NIR219 -1.429078e-02 -1.134277e-02 -0.046049610  0.0084169469 #> NIR220 -1.316021e-02 -1.475193e-02 -0.048279340  0.0133349560 #> NIR221 -1.014430e-02 -1.785284e-02 -0.049770954  0.0196534220 #> NIR222 -5.677561e-03 -2.007768e-02 -0.049051965  0.0261994711 #> NIR223 -1.724310e-03 -2.138696e-02 -0.045686082  0.0313832588 #> NIR224 -8.615735e-05 -2.200911e-02 -0.041991127  0.0341138331 #> NIR225 -7.016698e-04 -2.200280e-02 -0.040335467  0.0346387987 #> NIR226 -2.808897e-03 -2.107052e-02 -0.040016773  0.0328013645 #> NIR227 -6.665507e-03 -1.830327e-02 -0.040100315  0.0269896462 #> NIR228 -1.236831e-02 -1.283891e-02 -0.041441445  0.0159587846 #> NIR229 -1.811204e-02 -5.622938e-03 -0.044088354  0.0018283297 #> NIR230 -2.095699e-02  9.552249e-04 -0.046087162 -0.0099942430 #> NIR231 -1.926906e-02  5.009288e-03 -0.045590012 -0.0147813697 #> NIR232 -1.420356e-02  6.048327e-03 -0.042251564 -0.0118345542 #> NIR233 -8.635851e-03  5.419253e-03 -0.037472176 -0.0057014629 #> NIR234 -4.862262e-03  4.728888e-03 -0.033061831 -0.0006465373 #> NIR235 -3.387811e-03  4.242864e-03 -0.030245509  0.0024738679 #> NIR236 -3.141614e-03  3.798996e-03 -0.029318866  0.0039181690 #> NIR237 -2.763360e-03  3.532957e-03 -0.029369914  0.0044793820 #> NIR238 -1.843574e-03  3.447565e-03 -0.029349372  0.0051375454 #> NIR239 -7.314476e-04  3.293330e-03 -0.028862743  0.0060830808 #> NIR240  3.511386e-04  2.767237e-03 -0.028215872  0.0075911227 #> NIR241  1.377964e-03  1.786167e-03 -0.027842190  0.0099476563 #> NIR242  2.336498e-03  7.202884e-04 -0.027699706  0.0124419365 #> NIR243  3.274575e-03 -7.117817e-05 -0.027390616  0.0143006269 #> NIR244  3.937034e-03 -6.891943e-04 -0.026814726  0.0157360414 #> NIR245  3.783073e-03 -1.240316e-03 -0.026413082  0.0165795870 #> NIR246  2.655571e-03 -1.448487e-03 -0.026445516  0.0161874811 #> NIR247  9.107471e-04 -1.052198e-03 -0.026943678  0.0144483729 #> NIR248 -1.020941e-03 -1.569609e-04 -0.027834756  0.0117750588 #> NIR249 -2.485476e-03  1.027827e-03 -0.028878924  0.0087910074 #> NIR250 -2.784939e-03  2.162468e-03 -0.029428840  0.0068429354 #> NIR251 -2.192507e-03  2.797800e-03 -0.029143282  0.0067483235 #> NIR252 -1.550832e-03  2.820878e-03 -0.028441419  0.0075937313 #> NIR253 -1.150048e-03  2.372312e-03 -0.027874761  0.0085097467 #> NIR254 -8.803887e-04  1.669410e-03 -0.027735229  0.0095857821 #> NIR255 -7.700849e-04  9.317159e-04 -0.027862985  0.0107138382 #> NIR256 -8.602223e-04  2.969347e-04 -0.028117601  0.0115600888 #> NIR257 -1.082589e-03 -2.006354e-04 -0.028629032  0.0122671783 #> NIR258 -1.413385e-03 -5.893277e-04 -0.029238941  0.0126753723 #> NIR259 -1.828582e-03 -8.688813e-04 -0.029746279  0.0125943651 #> NIR260 -2.226934e-03 -1.009854e-03 -0.030213772  0.0123566585 #> NIR261 -2.524898e-03 -1.092762e-03 -0.030681112  0.0122204618 #> NIR262 -2.749303e-03 -1.222047e-03 -0.030967404  0.0121156781 #> NIR263 -2.931166e-03 -1.353408e-03 -0.031168325  0.0120799644 #> NIR264 -3.061128e-03 -1.415451e-03 -0.031435724  0.0121735783 #> NIR265 -3.160593e-03 -1.429246e-03 -0.031593853  0.0121906510 #> NIR266 -3.227588e-03 -1.441294e-03 -0.031611122  0.0120667974 #> NIR267 -3.252319e-03 -1.467328e-03 -0.031650126  0.0120601568 #> NIR268 -3.255688e-03 -1.508291e-03 -0.031718130  0.0121695820"},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"Choosing best number components PCR PLSR models difficult usually done basis visual inspection validation plots. cases large numbers models built choice needs automated. function implements two proposals, one based randomization (permutation) testing, approach based standard error cross-validation residuals.","code":""},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"","code":"selectNcomp(   object,   method = c(\"randomization\", \"onesigma\"),   nperm = 999,   alpha = 0.01,   ncomp = object$ncomp,   plot = FALSE,   ... )"},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"object mvr object.  fitted model. contain validation element. method character string, indicating heuristic use. nperm number permutations \"randomization\" approach - used \"onesigma\" approach. alpha cutoff p values \"randomization\" approach - used \"onesigma\" approach. ncomp maximum number components consider determining global minimum cross-validation curve. plot whether show cross-validation plot. plot \"randomization\" approach shows models differ significantly global RMSEP minimum open circles; \"onesigma\" approach shows one-sigma bands around RMSEP values. cases, selection indicated blue dashed line. ... plotting arguments, e.g., add title plot, limit plotting range.","code":""},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"number indicating suggested number components model.","code":""},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"approaches results cross-validation used, model calculated form cross-validation. First, absolute minimum CV curve determined (considering first ncomp components), leading reference model. randomization test approach (Van der Voet, 1994) checks whether squared prediction errors models fewer components significantly larger reference model. leads model considered \\(p\\) value; smallest model significantly worse reference model returned selected one. approach \"onesigma\" simply returns first model optimal CV within one standard error absolute optimum (Hastie, Tibshirani Friedman, 2009). Note simply use standard deviation cross-validation residuals, line procedure used calculate error measure . packages implementing similar procedures (glmnet) calculate error measure validation segment separately use average final estimate. cases standard error across segments relevant measure spread. LOO, two procedures identical. forms validation, small differences occur.","code":""},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"Van der Voet, H. (1994) Comparing predictive accuracy models using simple randomization test. Chemom. Intell. Lab. Syst. 25 (2), 313-323 Hastie, T., Friedman, J. Tibshirani, R. Elements Statistical Learning: data mining, inference, prediction, Springer (2013), 10th printing corrections, paragraph 7.10.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"Ron Wehrens, Hilko van der Voet Gerie van der Heijden","code":""},{"path":"https://khliland.github.io/pls/reference/selectNcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Suggestions for the optimal number of components in PCR and PLSR models â€” selectNcomp","text":"","code":"data(yarn) yarn.pls <- plsr(density ~ NIR, data = yarn, scale = TRUE,                  ncomp = 20, validation = \"LOO\") selectNcomp(yarn.pls, \"onesigma\", plot = TRUE, ylim = c(0, 3))  #> [1] 9 selectNcomp(yarn.pls, \"randomization\", plot = TRUE)  #> [1] 8 selectNcomp(yarn.pls, \"randomization\", plot = TRUE,             ncomp = 10, ylim = c(0, 3))  #> [1] 7"},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Sijmen de Jong's SIMPLS â€” simpls.fit","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"Fits PLSR model SIMPLS algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"","code":"simpls.fit(   X,   Y,   ncomp,   center = TRUE,   orthScores = FALSE,   stripped = FALSE,   ... )"},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. orthScores logical.  TRUE scores orthogonalised increased numerical precision (default = FALSE, speed). stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. Yscores matrix Y-scores. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar Total variance X. stripped TRUE, components coefficients, Xmeans Ymeans returned.","code":""},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"function called directly, generic functions plsr mvr argument method=\"simpls\".  SIMPLS much faster NIPALS algorithm, especially number X variables increases, gives slightly different results case multivariate Y.  SIMPLS truly maximises covariance criterion.  According de Jong, standard PLS2 algorithms lie closer ordinary least-squares regression precise fit sought; SIMPLS lies closer PCR stable predictions.","code":""},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"de Jong, S. (1993) SIMPLS: alternative approach partial least squares regression.  Chemometrics Intelligent Laboratory Systems, 18, 251â€“263.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/simpls.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sijmen de Jong's SIMPLS â€” simpls.fit","text":"","code":"## Simulation of SIMPLS stability # The graphics produced, demonstrate the numeric instability of the original # SIMPLS without score orthogonalization. set.seed(42) N <- 100 p <- 2000 ncomp <- 40 simData <- data.frame(X = I(matrix(rnorm(N*p),N)), y = rnorm(N)) pls    <- plsr(y ~ X, data=simData, ncomp=ncomp) simps  <- plsr(y ~ X, data=simData, ncomp=ncomp, method=\"simpls\") simpsO <- plsr(y ~ X, data=simData, ncomp=ncomp, method=\"simpls\", orthScores=TRUE) normScores <- pls$scores for(i in 1:ncomp)   normScores[,i] <- normScores[,i]/sqrt(sum(normScores[,i]^2))  # Check number of equal digits eqDig <- function(x,y){   xy <- abs(x - y)   xy[xy == 0] <- 10^-16   -colMeans(log10(xy)) } eqDig_PLS_oSIMPLS    <- eqDig(normScores, simpsO$scores) eqDig_SIMPLS_PLS     <- eqDig(simps$scores, normScores) eqDig_SIMPLS_oSIMPLS <- eqDig(simps$scores, simpsO$scores) # Correlation between models cor_PLS_oSIMPLS    <- diag(cor(pls$scores,simps$scores)) cor_SIMPLS_oSIMPLS <- diag(cor(pls$scores,simpsO$scores)) cor_SIMPLS_PLS     <- diag(cor(simps$scores,simpsO$scores))  par.old <- par(mfrow=c(2,1), mar=c(4,4,1,1), las=1) matplot(2:ncomp,cbind(eqDig_PLS_oSIMPLS,eqDig_SIMPLS_PLS, eqDig_SIMPLS_oSIMPLS)[-1,],         type=\"l\", xlab=\"component\", ylab=\"equal digits\", ylim=c(0,17),         panel.first=grid()) legend(\"bottomleft\", legend=c(\"PLS, SIMPLS\", \"PLS, OrthSIMPLS\", \"SIMPLS, OrthSIMPLS\"),        col=1:3, lty=1:3) matplot(1:ncomp,cbind(cor_PLS_oSIMPLS,cor_SIMPLS_oSIMPLS,cor_SIMPLS_PLS), type=\"l\",         ylab=\"correlation\", xlab=\"component\", panel.first=grid()) legend(\"bottomleft\", legend=c(\"PLS, SIMPLS\", \"PLS, OrthSIMPLS\", \"SIMPLS, OrthSIMPLS\"),        col=1:3, lty=1:3)  par(par.old)"},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardization of Data Matrices â€” stdize","title":"Standardization of Data Matrices â€” stdize","text":"Performs standardization (centering scaling) data matrix.","code":""},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardization of Data Matrices â€” stdize","text":"","code":"stdize(x, center = TRUE, scale = TRUE)  # S3 method for class 'stdized' predict(object, newdata, ...)  # S3 method for class 'stdized' makepredictcall(var, call)"},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardization of Data Matrices â€” stdize","text":"x, newdata numeric matrices.  data standardize. center logical value numeric vector length equal number coloumns x. scale logical value numeric vector length equal number coloumns x. object object inheriting class \"stdized\", normally result call stdize. ... arguments.  Currently ignored. var variable. call term formula, call.","code":""},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardization of Data Matrices â€” stdize","text":"stdize predict.stdized return scaled /centered matrix, attributes \"stdized:center\" /\"stdized:scale\" vector used centering /scaling.  matrix given class c(\"stdized\", \"matrix\").","code":""},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standardization of Data Matrices â€” stdize","text":"makepredictcall.stdized internal utility function; meant interactive use.  See makepredictcall details. center TRUE, x centered subtracting coloumn mean coloumn.  center numeric vector, used place coloumn means. scale TRUE, x scaled dividing coloumn sample standard deviation.  scale numeric vector, used place standard deviations.","code":""},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Standardization of Data Matrices â€” stdize","text":"stdize similar scale.  difference scale = TRUE, stdize divides coloumns standard deviation, scale uses root-mean-square coloumns.  center TRUE, equivalent, general .","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Standardization of Data Matrices â€” stdize","text":"BjÃ¸rn-Helge Mevik Ron Wehrens","code":""},{"path":"https://khliland.github.io/pls/reference/stdize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardization of Data Matrices â€” stdize","text":"","code":"data(yarn) ## Direct standardization: Ztrain <- stdize(yarn$NIR[yarn$train,]) Ztest <- predict(Ztrain, yarn$NIR[!yarn$train,])  ## Used in formula: mod <- plsr(density ~ stdize(NIR), ncomp = 6, data = yarn[yarn$train,]) pred <- predict(mod, newdata = yarn[!yarn$train,]) # Automatically standardized"},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"Summary print methods mvr mvrVal objects.","code":""},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"","code":"# S3 method for class 'mvr' print(x, ...)  # S3 method for class 'mvr' summary(   object,   what = c(\"all\", \"validation\", \"training\"),   digits = 4,   print.gap = 2,   ... )  # S3 method for class 'mvrVal' print(x, digits = 4, print.gap = 2, ...)  # S3 method for class 'mvrVal' as.data.frame(x, row.names = NULL, optional = FALSE, shortAlgs = TRUE, ...)"},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"x, object mvr object ... arguments sent underlying methods. one \"\", \"validation\" \"training\" digits integer.  Minimum number significant digits output. Default 4. print.gap Integer.  Gap coloumns printed tables. row.names NULL character vector giving row names data frame. Missing values allowed. optional used, included match signature .data.frame. shortAlgs Logical.  Shorten algorithm names (default = TRUE).","code":""},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"print.mvr print.mvrVal return object invisibly.","code":""},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"\"training\", explained variances given; \"validation\", cross-validated RMSEPs (available) given; \"\", given.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/summary.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary and Print Methods for PLSR and PCR objects â€” print.mvr","text":"","code":"data(yarn) nir.mvr <- mvr(density ~ NIR, ncomp = 8, validation = \"LOO\", data = yarn) nir.mvr #> Partial least squares regression, fitted with the kernel algorithm. #> Cross-validated using 28 leave-one-out segments. #> Call: #> mvr(formula = density ~ NIR, ncomp = 8, data = yarn, validation = \"LOO\") summary(nir.mvr) #> Data: \tX dimension: 28 268  #> \tY dimension: 28 1 #> Fit method: kernelpls #> Number of components considered: 8 #>  #> VALIDATION: RMSEP #> Cross-validated using 28 leave-one-out segments. #>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps #> CV           27.46    4.600    3.900    2.090   0.7686   0.5004   0.4425 #> adjCV        27.46    4.454    3.973    2.084   0.7570   0.4967   0.4398 #>        7 comps  8 comps #> CV      0.2966   0.2643 #> adjCV   0.2926   0.2610 #>  #> TRAINING: % variance explained #>          1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps #> X          46.83    98.38    99.46    99.67    99.85    99.97    99.98    99.99 #> density    98.12    98.25    99.64    99.97    99.99    99.99   100.00   100.00 RMSEP(nir.mvr) #>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps #> CV           27.46    4.600    3.900    2.090   0.7686   0.5004   0.4425 #> adjCV        27.46    4.454    3.973    2.084   0.7570   0.4967   0.4398 #>        7 comps  8 comps #> CV      0.2966   0.2643 #> adjCV   0.2926   0.2610 # Extract MVR validation statistics as data.frame: as.data.frame(RMSEP(nir.mvr, estimate = \"CV\")) #>   estimate response comps validation method algorithm      value #> 1       CV  density     0        LOO    mvr    kernel 27.4569014 #> 2       CV  density     1        LOO    mvr    kernel  4.6000678 #> 3       CV  density     2        LOO    mvr    kernel  3.8997929 #> 4       CV  density     3        LOO    mvr    kernel  2.0898916 #> 5       CV  density     4        LOO    mvr    kernel  0.7686120 #> 6       CV  density     5        LOO    mvr    kernel  0.5003516 #> 7       CV  density     6        LOO    mvr    kernel  0.4424918 #> 8       CV  density     7        LOO    mvr    kernel  0.2965848 #> 9       CV  density     8        LOO    mvr    kernel  0.2642607 as.data.frame(R2(nir.mvr)) #>   estimate response comps validation method algorithm       value #> 1       CV  density     0        LOO    mvr    kernel -0.07544582 #> 2       CV  density     1        LOO    mvr    kernel  0.96981342 #> 3       CV  density     2        LOO    mvr    kernel  0.97830455 #> 4       CV  density     3        LOO    mvr    kernel  0.99376936 #> 5       CV  density     4        LOO    mvr    kernel  0.99915725 #> 6       CV  density     5        LOO    mvr    kernel  0.99964286 #> 7       CV  density     6        LOO    mvr    kernel  0.99972068 #> 8       CV  density     7        LOO    mvr    kernel  0.99987452 #> 9       CV  density     8        LOO    mvr    kernel  0.99990038"},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal Component Regression â€” svdpc.fit","title":"Principal Component Regression â€” svdpc.fit","text":"Fits PCR model using singular value decomposition.","code":""},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal Component Regression â€” svdpc.fit","text":"","code":"svdpc.fit(X, Y, ncomp, center = TRUE, stripped = FALSE, ...)"},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal Component Regression â€” svdpc.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal Component Regression â€” svdpc.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar Total variance X. stripped TRUE, components coefficients, Xmeans Ymeans returned.","code":""},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Principal Component Regression â€” svdpc.fit","text":"function called directly, generic functions pcr mvr argument method=\"svdpc\". singular value decomposition used calculate principal components.","code":""},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Principal Component Regression â€” svdpc.fit","text":"Martens, H., NÃ¦s, T. (1989) Multivariate calibration. Chichester: Wiley.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/svdpc.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Principal Component Regression â€” svdpc.fit","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Validation Plots â€” validationplot","title":"Validation Plots â€” validationplot","text":"Functions plot validation statistics, RMSEP \\(R^2\\), function number components.","code":""},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validation Plots â€” validationplot","text":"","code":"validationplot(   object,   val.type = c(\"RMSEP\", \"MSEP\", \"R2\"),   estimate,   newdata,   ncomp,   comps,   intercept,   ... )  # S3 method for class 'mvrVal' plot(   x,   nCols,   nRows,   type = \"l\",   lty = 1:nEst,   lwd = par(\"lwd\"),   pch = 1:nEst,   cex = 1,   col = 1:nEst,   legendpos,   xlab = \"number of components\",   ylab = x$type,   main,   ask = nRows * nCols < nResp && dev.interactive(),   ... )"},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validation Plots â€” validationplot","text":"object mvr object. val.type character.  type validation statistic plot. estimate character.  estimates statistic calculate. See RMSEP. newdata data frame.  Optional new data used calculate statistic. ncomp, comps integer vector.  model sizes compute statistic .  See RMSEP. intercept logical.  Whether estimates model zero components calculated well. ... arguments sent underlying plot functions. x mvrVal object.  Usually result RMSEP, MSEP R2 call. nCols, nRows integers.  number coloumns rows plots laid .  specified, plot.mvrVal tries intelligent. type character.  type plots create.  Defaults \"l\" (lines).  Alternative types include \"p\" (points) \"b\" ().  See plot complete list types. lty vector line types (recycled neccessary).  Line types can specified integers character strings (see par details). lwd vector positive numbers (recycled neccessary), giving width lines. pch plot character.  character string vector single characters integers (recycled neccessary).  See points alternatives. cex numeric vector character expansion sizes (recycled neccessary) plotted symbols. col character integer vector colors plotted lines symbols (recycled neccessary).  See par details. legendpos Legend position.  Optional.  present, legend drawn given position.  position can specified symbolically (e.g., legendpos = \"topright\").  requires >= 2.1.0.  Alternatively, position can specified explicitly (legendpos = t(c(x,y))) interactively (legendpos = locator()).  works well plots single-response models. xlab, ylab titles \\(x\\) \\(y\\) axes.  Typically character strings, can expressions (e.g., expression(R^2) lists.  See title details. main optional main title plot.  See Details. ask logical.  Whether ask user page plot.","code":""},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validation Plots â€” validationplot","text":"validationplot calls proper validation function (currently MSEP, RMSEP R2) plots results plot.mvrVal.  validationplot can called mvr plot method, specifying plottype = \"validation\". plot.mvrVal creates one plot response variable model, laid rectangle.  uses matplot performing actual plotting.  legendpos given, legend drawn given position. argument main can used specify main title plot. handled non-standard way.  (sub) plot, main used main title plot.  one (sub) plot, however, presence main produce corresponding â€˜globalâ€™ title page.  graphical parametres, e.g., cex.main, supplied coefplot affect â€˜ordinaryâ€™ plot titles, â€˜globalâ€™ one.  appearance can changed setting parameters par, affect titles.  (different settings two titles, one can override par settings arguments plot function.)","code":""},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validation Plots â€” validationplot","text":"legend many options.  want greater control appearance legend, omit legendpos argument call legend manually.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Validation Plots â€” validationplot","text":"Ron Wehrens BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/validationplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validation Plots â€” validationplot","text":"","code":"data(oliveoil) mod <- plsr(sensory ~ chemical, data = oliveoil, validation = \"LOO\") if (FALSE) { # \\dontrun{ ## These three are equivalent: validationplot(mod, estimate = \"all\") plot(mod, \"validation\", estimate = \"all\") plot(RMSEP(mod, estimate = \"all\")) ## Plot R2: plot(mod, \"validation\", val.type = \"R2\") ## Plot R2, with a legend: plot(mod, \"validation\", val.type = \"MSEP\", legendpos = \"top\") # R >= 2.1.0 } # }"},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":null,"dir":"Reference","previous_headings":"","what":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"Calculates jackknife variance covariance estimates regression coefficients. original (Tukey) jackknife variance estimator defined \\((g-1)/g \\sum_{=1}^g(\\tilde\\beta_{-} - \\bar\\beta)^2\\), \\(g\\) number segments, \\(\\tilde\\beta_{-}\\) estimated coefficient segment \\(\\) left (called jackknife replicates), \\(\\bar\\beta\\) mean \\(\\tilde\\beta_{-}\\).  common case delete-one jackknife, \\(g = n\\), number observations. definition var.jack uses default. However, Martens Martens (2000) defined estimator \\((g-1)/g \\sum_{=1}^g(\\tilde\\beta_{-} - \\hat\\beta)^2\\), \\(\\hat\\beta\\) coefficient estimate using entire data set.  .e., use original fitted coefficients instead mean jackknife replicates.  (?) jackknife implementations PLSR use estimator. var.jack can made use definition use.mean = FALSE.  practice, difference small number observations sufficiently large.  Note, however, theoretical results jackknife refer `proper' definition.  (Also note option might disappear future version.)","code":""},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"","code":"var.jack(object, ncomp = object$ncomp, covariance = FALSE, use.mean = TRUE)"},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"object mvr object.  cross-validated model fitted jackknife = TRUE. ncomp number components use estimating (co)variances covariance logical.  TRUE, covariances calculated; otherwise variances.  default FALSE. use.mean logical.  TRUE (default), mean coefficients used estimating (co)variances; otherwise coefficients model fitted entire data set.  See Details.","code":""},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"covariance FALSE, \\(p\\times q \\times c\\) array variance estimates, \\(p\\) number predictors, \\(q\\) number responses, \\(c\\) number components. covariance id TRUE, \\(pq\\times pq \\times c\\) array variance-covariance estimates.","code":""},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"Note Tukey jackknife variance estimator unbiased variance regression coefficients (Hinkley 1977).  bias depends \\(X\\) matrix.  ordinary least squares regression (OLSR), bias can calculated, depends number observations \\(n\\) number parameters \\(k\\) mode.  common case orthogonal design matrix \\(\\pm 1\\) levels, delete-one jackknife estimate equals \\((n-1)/(n-k)\\) times classical variance estimate regression coefficients OLSR. Similar expressions hold delete-d estimates.  Modifications proposed reduce eliminate bias OLSR case, however, depend number parameters used model.  See e.g. Hinkley (1977) Wu (1986). Thus, results var.jack used caution.","code":""},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"Tukey J.W. (1958) Bias Confidence -quite Large Samples. (Abstract Preliminary Report).  Annals Mathematical Statistics, 29(2), 614. Martens H. Martens M. (2000) Modified Jack-knife Estimation Parameter Uncertainty Bilinear Modelling Partial Least Squares Regression (PLSR).  Food Quality Preference, 11, 5â€“16. Hinkley D.V. (1977), Jackknifing Unbalanced Situations. Technometrics, 19(3), 285â€“292. Wu C.F.J. (1986) Jackknife, Bootstrap Resampling Methods Regression Analysis.  Te Annals Statistics, 14(4), 1261â€“1295.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/var.jack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jackknife Variance Estimates of Regression Coefficients â€” var.jack","text":"","code":"data(oliveoil) mod <- pcr(sensory ~ chemical, data = oliveoil, validation = \"LOO\",            jackknife = TRUE) var.jack(mod, ncomp = 2) #> , , 2 comps #>  #>                yellow        green        brown       glossy      transp #> Acidity  1024.4116919 1589.2686000 1.750141e+01 42.522264128 73.50823993 #> Peroxide    3.4451819    5.8716926 3.227187e-01  0.273051034  0.52181445 #> K232      583.6428901  961.3757680 2.190286e+01 22.819112503 69.31594523 #> K270        9.4454718   14.8484347 3.551073e-02  0.218596282  0.48383108 #> DK          0.1163998    0.1884952 9.368976e-04  0.005818676  0.01191753 #>                 syrup #> Acidity  8.6885127205 #> Peroxide 0.0171447602 #> K232     0.7877230726 #> K270     0.0352534553 #> DK       0.0004922534 #>"},{"path":"https://khliland.github.io/pls/reference/vcov.mvr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","title":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","text":"Returns variance-covariance matrix coefficients Principal Component Regression.","code":""},{"path":"https://khliland.github.io/pls/reference/vcov.mvr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","text":"","code":"# S3 method for class 'mvr' vcov(object, ncomp, ...)"},{"path":"https://khliland.github.io/pls/reference/vcov.mvr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","text":"object fitted PCR object class mvr. ncomp number principal components estimate vcov . ... additional arguments (used).","code":""},{"path":"https://khliland.github.io/pls/reference/vcov.mvr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","text":"matrix estimated covariances regression coefficients.","code":""},{"path":"https://khliland.github.io/pls/reference/vcov.mvr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Variance-Covariance Matrix for a Fitted Model Object â€” vcov.mvr","text":"","code":"data(yarn) yarn.pcr <- pcr(density ~ NIR, 6, data = yarn) vc <- vcov(yarn.pcr, 3)  # Standard error of coefficients se <- sqrt(diag(vc)) beta <- coef(yarn.pcr, ncomp = 3)  # Plot regression coefficients with two standard errors shading. plot(beta, type = 'l',      panel.first = polygon(x = c(1:268, 268:1),                            y = c(beta+2*se, rev(beta-2*se)),                            col = 'lightblue',                            border = NA))"},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"Fits PLSR model wide kernel algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"","code":"widekernelpls.fit(   X,   Y,   ncomp,   center = TRUE,   stripped = FALSE,   tol = .Machine$double.eps^0.5,   maxit = 100,   ... )"},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"X matrix observations.  NAs Infs allowed. Y vector matrix responses.  NAs Infs allowed. ncomp number components used modelling. center logical, determines \\(X\\) \\(Y\\) matrices mean centered . Default perform mean centering. stripped logical.  TRUE calculations stripped much possible speed; meant use cross-validation simulations coefficients needed.  Defaults FALSE. tol numeric.  tolerance used determining convergence algorithm. maxit positive integer.  maximal number iterations used internal Eigenvector calculation. ... arguments.  Currently ignored.","code":""},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"list containing following components returned: coefficients array regression coefficients 1, ..., ncomp components.  dimensions coefficients c(nvar, npred, ncomp) nvar number X variables npred number variables predicted Y. scores matrix scores. loadings matrix loadings. loading.weights matrix loading weights. Yscores matrix Y-scores. Yloadings matrix Y-loadings. projection projection matrix used convert X scores. Xmeans vector means X variables. Ymeans vector means Y variables. fitted.values array fitted values.  dimensions fitted.values c(nobj, npred, ncomp) nobj number samples npred number Y variables. residuals array regression residuals.  dimensions fitted.values. Xvar vector amount X-variance explained component. Xtotvar Total variance X. stripped TRUE, components coefficients, Xmeans Ymeans returned.","code":""},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"function called directly, generic functions plsr mvr argument method=\"widekernelpls\".  wide kernel PLS algorithm efficient number variables (much) larger number observations.  wide X, instance 12x18000, can twice fast kernelpls.fit simpls.fit. matrices, however, can much slower.  results equal results NIPALS algorithm.","code":""},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"current implementation undergone extensive testing yet, perhaps regarded experimental.  Specifically, internal Eigenvector calculation always converge extreme cases Eigenvalue close zero.  However, converge, always converges results kernelpls.fit, numerical inacurracies. algorithm also bit overhead, number observations moderately high, kernelpls.fit can faster even number predictors much higher.  relative speed algorithms can also depend greatly BLAS /LAPACK library linked .","code":""},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"RÃ¤nnar, S., Lindgren, F., Geladi, P. Wold, S. (1994) PLS Kernel Algorithm Data Sets Many Variables Fewer Objects.  Part 1: Theory Algorithm.  Journal Chemometrics, 8, 111â€“125.","code":""},{"path":[]},{"path":"https://khliland.github.io/pls/reference/widekernelpls.fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Wide Kernel PLS (RÃ¤nnar et al.) â€” widekernelpls.fit","text":"BjÃ¸rn-Helge Mevik","code":""},{"path":"https://khliland.github.io/pls/reference/yarn.html","id":null,"dir":"Reference","previous_headings":"","what":"NIR spectra and density measurements of PET yarns â€” yarn","title":"NIR spectra and density measurements of PET yarns â€” yarn","text":"training set consisting 21 NIR spectra PET yarns, measured 268 wavelengths, 21 corresponding densities.  test set 7 samples also provided.  Many thanks Erik Swierenga.","code":""},{"path":"https://khliland.github.io/pls/reference/yarn.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NIR spectra and density measurements of PET yarns â€” yarn","text":"data frame components NIR Numeric matrix NIR measurements density Numeric vector densities train Logical vector TRUE training samples FALSE test samples","code":""},{"path":"https://khliland.github.io/pls/reference/yarn.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NIR spectra and density measurements of PET yarns â€” yarn","text":"Swierenga H., de Weijer . P., van Wijk R. J., Buydens L. M. C. (1999) Strategy constructing robust multivariate calibration models Chemometrics Intelligent Laboratoryy Systems, 49(1), 1â€“17.","code":""}]
